{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('3.7.7')",
   "metadata": {
    "interpreter": {
     "hash": "8a5478e73ab4ac786b177a0e1da34e6fd874585dfdc4463791ac8c0c5c0e6e05"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由於 RCSMOTE 出現問題 所以改用 boderline 加 SMOTE 加 borderline 加 ADASYN\n",
    "import os\n",
    "path = \"/Users/emily/Desktop/Research/oversampling_python/data/\"\n",
    "folderName = 'yeast6-5-fold' #'abalone19-5-fold' #\n",
    "os.chdir(path+ folderName)\n",
    "dirs = os.listdir(path+ folderName)\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for i in dirs:\n",
    "    if(\"xlsx\" in i):\n",
    "        if(\"tra\" in i):\n",
    "            train.append(i)\n",
    "        elif(\"tst\" in i):\n",
    "            test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先用 train[0] 測試 先視覺化\n",
    "from collections import Counter\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = pd.read_excel(train[0],index_col=0)\n",
    "#data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "rows = data.shape[0]\n",
    "column = data.shape[1]\n",
    "inputdata = data.iloc[:,:column-1]\n",
    "output = data.iloc[:,column-1]\n",
    "inputdata.iloc[:,0] = le.fit_transform(inputdata.iloc[:,0])\n",
    "#output = LabelEncoder().fit_transform(output)\n",
    "#X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "#X.iloc[:,0] = le.fit_transform(X.iloc[:,0])\n",
    "#X = LabelEncoder().fit_transform(X)\n",
    "#y = LabelEncoder().fit_transform(y)\n",
    "adsn = SMOTE()\n",
    "new_X, new_y = adsn.fit_sample(inputdata,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = Counter(output)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data 數值化\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "inputdata.iloc[:,0] = le.fit_transform(inputdata.iloc[:,0]) \n",
    "\"\"\"\n",
    "for i in range(inputdata.shape[1]):\n",
    "    inputdata.iloc[:,i] = le.fit_transform(inputdata.iloc[:,i]) \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(output)\n",
    "for k,v in counter.items():\n",
    "\t    per = v / len(output) * 100\n",
    "\t    print(\"class\",k,\"數量：\",v,\"percentage\",'%.3f' %per,\"%\")\n",
    "\t\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "    \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from imblearn.over_sampling import ADASYN\n",
    "adsn = ADASYN()\n",
    "inputdata.iloc[:,0] = le.fit_transform(inputdata.iloc[:,0])\n",
    "new_X, new_y = adsn.fit_sample(inputdata,output)  # your imbalanced dataset is in X,y\n",
    "counterNew = Counter(new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([new_X,new_y],axis=1)\n",
    "df.index = range(1,len(df) + 1)\n",
    "df.to_excel(\"tt.xlsx\",index=1)\n"
   ]
  },
  {
   "source": [
    "ADASYN 0.8349723947550034"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADASYN\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn import cluster, datasets, metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy import mean\n",
    "import statistics\n",
    "accuracies=[]\n",
    "for ii,i in enumerate(train):\n",
    "    \n",
    "    randomIndex = []\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    #data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    l = data.shape[1] -1\n",
    "    output = data.iloc[:,l];\n",
    "    finaldata = data.iloc[:,:l]\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    tempover = []\n",
    "    adsn = ADASYN()\n",
    "    new_X, new_y = adsn.fit_sample(finaldata,output)  # your imbalanced dataset is in X,y\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(new_X, new_y)\n",
    "    #clf = clf.fit(finaldata,output)\n",
    "    newDataCount = len(new_X) - len(data)  # 新生成的 data 數量\n",
    "    # 把 X_smote 跟 y_smote 和在一起\n",
    "    \n",
    "    test_file = pd.read_excel(test[ii],index_col=0) #不然會有多出來的 unnamed column\n",
    "    test_data = pd.DataFrame(test_file);\n",
    "    #test_data.Class= test_data.Class.str.replace(\"\\n\", \"\").str.strip()   \n",
    "\n",
    "    test_X = test_data.iloc[:,:(test_data.shape[1])-1] \n",
    "    test_X.iloc[:,0] = le.fit_transform(test_X.iloc[:,0])\n",
    "\n",
    "    test_y_predicted = clf.predict(test_X)\n",
    "    test_y = test_data.iloc[:,test_data.shape[1]-1] \n",
    "    test_y = le.fit_transform(test_y)\n",
    "    test_y_predicted = le.fit_transform(test_y_predicted)\n",
    "    accuracy = roc_auc_score(test_y, test_y_predicted)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "\n",
    "mean = statistics.mean(accuracies)\n",
    "print(mean)\n",
    "\n",
    "#現在 randomSMOTE 存的是 random 的 SMOTE 生成 data\n"
   ]
  },
  {
   "source": [
    "SMOTE 0.8220151828847481"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE \n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import cluster, datasets, metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy import mean\n",
    "from matplotlib import pyplot\n",
    "import statistics\n",
    "accuracies=[]\n",
    "for ii,i in enumerate(train):\n",
    "    \n",
    "    randomIndex = []\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    #data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    l = data.shape[1] -1\n",
    "    output = data.iloc[:,l];\n",
    "    finaldata = data.iloc[:,:l]\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    tempover = []\n",
    "    smote = SMOTE()\n",
    "    new_X, new_y = smote.fit_sample(finaldata,output)  # your imbalanced dataset is in X,y\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(new_X, new_y)\n",
    "    newDataCount = len(new_X) - len(data)  # 新生成的 data 數量\n",
    "    # 把 X_smote 跟 y_smote 和在一起\n",
    "    \n",
    "    test_file = pd.read_excel(test[ii],index_col=0) #不然會有多出來的 unnamed column\n",
    "    test_data = pd.DataFrame(test_file);\n",
    "    #test_data.Class= test_data.Class.str.replace(\"\\n\", \"\").str.strip()   \n",
    "\n",
    "    test_X = test_data.iloc[:,:(test_data.shape[1])-1] \n",
    "    test_X.iloc[:,0] = le.fit_transform(test_X.iloc[:,0])\n",
    "\n",
    "    test_y_predicted = clf.predict(test_X)\n",
    "    test_y = test_data.iloc[:,test_data.shape[1]-1] \n",
    "    counter = Counter(test_y)\n",
    "    \n",
    "    counter = Counter(output)\n",
    "    \"\"\"\n",
    "    for k,v in counter.items():\n",
    "\t    per = v / len(output) * 100\n",
    "\t    print(\"class\",k,\"數量：\",v,\"percentage\",'%.3f' %per,\"%\")\n",
    "\t\n",
    "    pyplot.bar(counter.keys(), counter.values())\n",
    "    pyplot.show()\n",
    "    \"\"\"\n",
    "\n",
    "    test_y = le.fit_transform(test_y)\n",
    "    test_y_predicted = le.fit_transform(test_y_predicted)\n",
    "    #accuracy = metrics.accuracy_score(test_y, test_y_predicted)\n",
    "    accuracy = roc_auc_score(test_y, test_y_predicted)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    \n",
    "mean = statistics.mean(accuracies)\n",
    "print(mean)\n",
    "\n",
    "#現在 randomSMOTE 存的是 random 的 SMOTE 生成 data\n"
   ]
  },
  {
   "source": [
    "Borderline-1  0.7979468599033817"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borderline-1\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn import cluster, datasets, metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy import mean\n",
    "from matplotlib import pyplot\n",
    "import statistics\n",
    "accuracies=[]\n",
    "for ii,i in enumerate(train):\n",
    "    \n",
    "    randomIndex = []\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    l = data.shape[1] -1\n",
    "    output = data.iloc[:,l];\n",
    "    finaldata = data.iloc[:,:l]\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    tempover = []\n",
    "    adsn =  BorderlineSMOTE(random_state=42,kind=\"borderline-1\")\n",
    "    new_X, new_y = adsn.fit_sample(finaldata,output)  # your imbalanced dataset is in X,y\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(new_X, new_y)\n",
    "    newDataCount = len(new_X) - len(data)  # 新生成的 data 數量\n",
    "    # 把 X_smote 跟 y_smote 和在一起\n",
    "    \n",
    "    test_file = pd.read_excel(test[ii],index_col=0) #不然會有多出來的 unnamed column\n",
    "    test_data = pd.DataFrame(test_file);\n",
    "    test_data.Class= test_data.Class.str.replace(\"\\n\", \"\").str.strip()   \n",
    "\n",
    "    test_X = test_data.iloc[:,:(test_data.shape[1])-1] \n",
    "    test_X.iloc[:,0] = le.fit_transform(test_X.iloc[:,0])\n",
    "\n",
    "    test_y_predicted = clf.predict(test_X)\n",
    "    test_y = test_data.iloc[:,test_data.shape[1]-1] \n",
    "    counter = Counter(test_y)\n",
    "    \n",
    "    counter = Counter(output)\n",
    "    \"\"\"\n",
    "    for k,v in counter.items():\n",
    "\t    per = v / len(output) * 100\n",
    "\t    print(\"class\",k,\"數量：\",v,\"percentage\",'%.3f' %per,\"%\")\n",
    "\t\n",
    "    pyplot.bar(counter.keys(), counter.values())\n",
    "    pyplot.show()\n",
    "    \"\"\"\n",
    "\n",
    "    test_y = le.fit_transform(test_y)\n",
    "    test_y_predicted = le.fit_transform(test_y_predicted)\n",
    "    #accuracy = metrics.accuracy_score(test_y, test_y_predicted)\n",
    "    accuracy = roc_auc_score(test_y, test_y_predicted)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    \n",
    "mean = statistics.mean(accuracies)\n",
    "print(mean)\n",
    "\n",
    "#現在 randomSMOTE 存的是 random 的 SMOTE 生成 data\n"
   ]
  },
  {
   "source": [
    "Borderline-2 0.8260006901311249"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borderline-2\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn import cluster, datasets, metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy import mean\n",
    "from matplotlib import pyplot\n",
    "import statistics\n",
    "accuracies=[]\n",
    "for ii,i in enumerate(train):\n",
    "    \n",
    "    randomIndex = []\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    l = data.shape[1] -1\n",
    "    output = data.iloc[:,l];\n",
    "    finaldata = data.iloc[:,:l]\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    tempover = []\n",
    "    Border2 =  BorderlineSMOTE(random_state=42,kind=\"borderline-2\")\n",
    "    new_X, new_y = Border2.fit_sample(finaldata,output)  # your imbalanced dataset is in X,y\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(new_X, new_y)\n",
    "    newDataCount = len(new_X) - len(data)  # 新生成的 data 數量\n",
    "    # 把 X_smote 跟 y_smote 和在一起\n",
    "    \n",
    "    test_file = pd.read_excel(test[ii],index_col=0) #不然會有多出來的 unnamed column\n",
    "    test_data = pd.DataFrame(test_file);\n",
    "    test_data.Class= test_data.Class.str.replace(\"\\n\", \"\").str.strip()   \n",
    "\n",
    "    test_X = test_data.iloc[:,:(test_data.shape[1])-1] \n",
    "    test_X.iloc[:,0] = le.fit_transform(test_X.iloc[:,0])\n",
    "\n",
    "    test_y_predicted = clf.predict(test_X)\n",
    "    test_y = test_data.iloc[:,test_data.shape[1]-1] \n",
    "    counter = Counter(test_y)\n",
    "    \n",
    "    counter = Counter(output)\n",
    "    \n",
    "\n",
    "    test_y = le.fit_transform(test_y)\n",
    "    test_y_predicted = le.fit_transform(test_y_predicted)\n",
    "    # 精確度\n",
    "    accuracy = roc_auc_score(test_y, test_y_predicted)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    \n",
    "mean = statistics.mean(accuracies)\n",
    "print(mean)\n",
    "\n",
    "#現在 randomSMOTE 存的是 random 的 SMOTE 生成 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[3338,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maj(sample_class):\n",
    "    counter = Counter(sample_class);\n",
    "    maj = list(dict(counter.most_common(1)).keys())\n",
    "    maj = \"\".join(maj)\n",
    "    return  maj\n",
    "\n",
    "\n",
    "def classprocess(output):\n",
    "    c = Counter(output)\n",
    "    datagap = []\n",
    "    maj = find_maj(output)\n",
    "    maj_num = dict(c)[find_maj(output)]\n",
    "    for className, number in c.items(): \n",
    "        #print(className,\" \",number)\n",
    "        print(number)\n",
    "        temp = np.array([className,(maj_num - number)])\n",
    "        datagap.append(temp)\n",
    "    return datagap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1159\n",
      "28\n",
      "2318 x_smote\n",
      "0   226\n",
      "1159\n",
      "28\n",
      "2318 x_smote\n",
      "1   226\n",
      "1159\n",
      "28\n",
      "2318 x_smote\n",
      "2   226\n",
      "1160\n",
      "28\n",
      "2320 x_smote\n",
      "3   226\n",
      "1159\n",
      "28\n",
      "2318 x_smote\n",
      "4   226\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5, 226, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 453
    }
   ],
   "source": [
    "# random SMOTE 取 7 成\n",
    "alloverSMOTE = []\n",
    "overSMOTE = []\n",
    "randomSMOTE = []\n",
    "\n",
    "for ii,i in enumerate(train):\n",
    "    randomIndex = []\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    output = data.iloc[:,l];\n",
    "    classCount = classprocess(output)\n",
    "    finaldata = data.iloc[:,:l]\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    tempover = []\n",
    "    over = SMOTE()\n",
    "    X_smote,y_smote = over.fit_resample(finaldata,output)\n",
    "    newDataCount = len(X_smote) - len(data)  # 新生成的 data 數量\n",
    "    print(len(X_smote),\"x_smote\")\n",
    "    # 把 X_smote 跟 y_smote 和在一起\n",
    "    \"\"\"\n",
    "    for index,element in enumerate(X_smote):\n",
    "        temp = np.append(element,[y_smote[index]])\n",
    "        alloverSMOTE.append(temp)\n",
    "    overSMOTE.append(alloverSMOTE)\n",
    "    alloverSMOTE =[]\n",
    "    \"\"\"\n",
    "    alloverSMOTE = pd.concat([X_smote,y_smote],axis=1) # SMOTE 完後的數據\n",
    "    overSMOTE.append(alloverSMOTE)\n",
    "    for i in range(len(classCount)):\n",
    "        #print(classCount[i],\"ffksdl;\")\n",
    "        count = math.floor(int(classCount[i][1])*0.2); # 要產生多少數據  無條件捨去\n",
    "        randomIndex.extend([random.randint(len(data),len(X_smote)-1) for _ in range(count)]) \n",
    "    \n",
    "    randomtemp = []\n",
    "    #print(overSMOTE)\n",
    "    \n",
    "    \n",
    "    for index in randomIndex:\n",
    "        randomtemp.append(overSMOTE[ii].iloc[index,:])\n",
    "    #print(randomtemp)\n",
    "   \n",
    "    \n",
    "    randomSMOTE.append(randomtemp)\n",
    "    print(ii,\" \",len(randomtemp))\n",
    "    #print(np.array(randomSMOTE).shape)\n",
    "    #print(\"actual\",len(randomSMOTE[ii]))\n",
    "    \n",
    "    #print(\"we\",len(randomSMOTE[ii]))\n",
    "     \n",
    "np.array(randomSMOTE).shape\n",
    "\n",
    "\n",
    "#現在 randomSMOTE 存的是 random 的 SMOTE 生成 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1159\n",
      "28\n",
      "2323 x_smote\n",
      "0   566\n",
      "1159\n",
      "28\n",
      "2322 x_smote\n",
      "1   566\n",
      "1159\n",
      "28\n",
      "2321 x_smote\n",
      "2   566\n",
      "1160\n",
      "28\n",
      "2316 x_smote\n",
      "3   566\n",
      "1159\n",
      "28\n",
      "2320 x_smote\n",
      "4   566\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5, 566, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 454
    }
   ],
   "source": [
    "# random ADsyn 取 3 成\n",
    "from imblearn.over_sampling import ADASYN\n",
    "alloverAdsyn = []\n",
    "overAdsyn = []\n",
    "randomAdsyn = []\n",
    "\n",
    "for ii,i in enumerate(train):\n",
    "    randomIndex = []\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    output = data.iloc[:,l];\n",
    "    classCount = classprocess(output)\n",
    "    finaldata = data.iloc[:,:l]\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    tempover = []\n",
    "    over = ADASYN()\n",
    "    X_smote,y_smote = over.fit_resample(finaldata,output)\n",
    "    newDataCount = len(X_smote) - len(data)  # 新生成的 data 數量\n",
    "    print(len(X_smote),\"x_smote\")\n",
    "    # 把 X_smote 跟 y_smote 和在一起\n",
    "   \n",
    "    alloverAdsyn = pd.concat([X_smote,y_smote],axis=1) # SMOTE 完後的數據\n",
    "    overAdsyn.append(alloverAdsyn)\n",
    "    for i in range(len(classCount)):\n",
    "        #print(classCount[i],\"ffksdl;\")\n",
    "        count = math.ceil(int(classCount[i][1])*0.5); # 要產生多少數據  無條件捨去\n",
    "        randomIndex.extend([random.randint(len(data),len(X_smote)-1) for _ in range(count)]) \n",
    "    \n",
    "    randomtemp = []\n",
    "    #print(overSMOTE)\n",
    "    \n",
    "    \n",
    "    for index in randomIndex:\n",
    "        randomtemp.append(overAdsyn[ii].iloc[index,:])\n",
    "    #print(randomtemp)\n",
    "   \n",
    "    \n",
    "    randomAdsyn.append(randomtemp)\n",
    "    print(ii,\" \",len(randomtemp))\n",
    "    #print(np.array(randomSMOTE).shape)\n",
    "    #print(\"actual\",len(randomSMOTE[ii]))\n",
    "    \n",
    "    #print(\"we\",len(randomSMOTE[ii]))\n",
    "     \n",
    "np.array(randomAdsyn).shape\n",
    "\n",
    "\n",
    "#現在 randomSMOTE 存的是 random 的 SMOTE 生成 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1159\n",
      "28\n",
      "2318 x_smote\n",
      "0   340\n",
      "1159\n",
      "28\n",
      "2318 x_smote\n",
      "1   340\n",
      "1159\n",
      "28\n",
      "2318 x_smote\n",
      "2   340\n",
      "1160\n",
      "28\n",
      "2320 x_smote\n",
      "3   340\n",
      "1159\n",
      "28\n",
      "2318 x_smote\n",
      "4   340\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5, 340, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 455
    }
   ],
   "source": [
    "# random borderline2\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "alloverBorder2 = []\n",
    "overBorder2 = []\n",
    "randomBorder2 = []\n",
    "\n",
    "for ii,i in enumerate(train):\n",
    "    randomIndex = []\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    output = data.iloc[:,l];\n",
    "    classCount = classprocess(output)\n",
    "    finaldata = data.iloc[:,:l]\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    tempover = []\n",
    "    over = BorderlineSMOTE(random_state=42,kind=\"borderline-2\")\n",
    "    X_smote,y_smote = over.fit_resample(finaldata,output)\n",
    "    newDataCount = len(X_smote) - len(data)  # 新生成的 data 數量\n",
    "    print(len(X_smote),\"x_smote\")\n",
    "    # 把 X_smote 跟 y_smote 和在一起\n",
    "   \n",
    "    alloverBorder2 = pd.concat([X_smote,y_smote],axis=1) # SMOTE 完後的數據\n",
    "    overBorder2.append(alloverBorder2)\n",
    "    for i in range(len(classCount)):\n",
    "        #print(classCount[i],\"ffksdl;\")\n",
    "        count = math.ceil(int(classCount[i][1])*0.3); # 要產生多少數據  無條件捨去\n",
    "        randomIndex.extend([random.randint(len(data),len(X_smote)-1) for _ in range(count)]) \n",
    "    \n",
    "    randomtemp = []\n",
    "    #print(overSMOTE)\n",
    "    \n",
    "    \n",
    "    for index in randomIndex:\n",
    "        randomtemp.append(overBorder2[ii].iloc[index,:])\n",
    "    #print(randomtemp)\n",
    "   \n",
    "    \n",
    "    randomBorder2.append(randomtemp)\n",
    "    print(ii,\" \",len(randomtemp))\n",
    "    #print(np.array(randomSMOTE).shape)\n",
    "    #print(\"actual\",len(randomSMOTE[ii]))\n",
    "    \n",
    "    #print(\"we\",len(randomSMOTE[ii]))\n",
    "     \n",
    "np.array(randomBorder2).shape\n",
    "\n",
    "\n",
    "#現在 randomSMOTE 存的是 random 的 SMOTE 生成 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRandomHalf = []\n",
    "temp = []\n",
    "# 合併 Adsyn SMOTE\n",
    "for i in range(len(randomAdsyn)):\n",
    "    #temp = randomAdsyn[i] + randomSMOTE[i]\n",
    "    randomAdsynpd = pd.DataFrame(randomAdsyn[i])\n",
    "    randomSMOTEpd = pd.DataFrame(randomSMOTE[i])\n",
    "    RandomHalf = pd.concat([randomAdsynpd,randomSMOTEpd],axis=0)\n",
    "    allRandomHalf.append(RandomHalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRandomHalf = []\n",
    "temp = []\n",
    "# 合併 Adsyn Border2\n",
    "for i in range(len(randomAdsyn)):\n",
    "    #temp = randomAdsyn[i] + randomSMOTE[i]\n",
    "    randomAdsynpd = pd.DataFrame(randomAdsyn[i])\n",
    "    randomBorder2pd = pd.DataFrame(randomBorder2[i])\n",
    "    RandomHalf = pd.concat([randomAdsynpd,randomBorder2pd],axis=0)\n",
    "    allRandomHalf.append(RandomHalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random 合併三個\n",
    "allRandomHalf = []\n",
    "temp = []\n",
    "\n",
    "for i in range(len(randomAdsyn)):\n",
    "    #temp = randomAdsyn[i] + randomSMOTE[i]\n",
    "    randomAdsynpd = pd.DataFrame(randomAdsyn[i])\n",
    "    randomSMOTEpd = pd.DataFrame(randomSMOTE[i])\n",
    "    randomBorder2pd = pd.DataFrame(randomBorder2[i])\n",
    "    RandomHalf = pd.concat([randomAdsynpd,randomSMOTEpd],axis=0)\n",
    "    RandomHalf = pd.concat([RandomHalf,randomBorder2pd],axis=0)\n",
    "    allRandomHalf.append(RandomHalf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8143831285049516\n"
     ]
    }
   ],
   "source": [
    "# 跟原始資料合併\n",
    "mergeRandom = []\n",
    "for index,element in enumerate(train):\n",
    "    data = pd.read_excel(element,index_col =0);\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    l = data.shape[1]-1\n",
    "    \"\"\"\n",
    "    output = data.iloc[:,l];\n",
    "    finaldata = data.iloc[:,:l]\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    \"\"\"\n",
    "    data.iloc[:,0] = le.fit_transform(data.iloc[:,0])\n",
    "    #classCount = classprocess(output)\n",
    "    #data = data.T\n",
    "    mergeRandom = pd.concat([data,allRandomHalf[index]],axis=0)\n",
    "    #print(mergeRandom)\n",
    "    \n",
    "    output = mergeRandom.iloc[:,l];\n",
    "    finaldata = mergeRandom.iloc[:,:l]\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(finaldata, output)\n",
    "\n",
    "\n",
    "    test_file = pd.read_excel(test[index],index_col=0) #不然會有多出來的 unnamed column\n",
    "    test_data = pd.DataFrame(test_file);\n",
    "    test_data.Class= test_data.Class.str.replace(\"\\n\", \"\").str.strip()   \n",
    "\n",
    "    test_X = test_data.iloc[:,:(test_data.shape[1])-1] \n",
    "    test_X.iloc[:,0] = le.fit_transform(test_X.iloc[:,0])\n",
    "\n",
    "    test_y_predicted = clf.predict(test_X)\n",
    "    test_y = test_data.iloc[:,test_data.shape[1]-1] \n",
    "    test_y = le.fit_transform(test_y)\n",
    "    test_y_predicted = le.fit_transform(test_y_predicted)\n",
    "    accuracy = roc_auc_score(test_y, test_y_predicted)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "\n",
    "mean = statistics.mean(accuracies)\n",
    "print(mean)\n",
    "\n",
    "#len(mergeRandom[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(output)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allRandomHalf[0])"
   ]
  },
  {
   "source": [
    "SMOTE 0.7  ADASYN 0.3  準確度 0.7989130\n",
    "SMOTE 0.3  ADASYN 0.7  準確度 0.7989130\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跟原始資料合併\n",
    "mergeRandom = []\n",
    "for index,element in enumerate(train):\n",
    "    data = pd.read_excel(element,index_col =0);\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    l = data.shape[1]-1\n",
    "    \"\"\"\n",
    "    output = data.iloc[:,l];\n",
    "    finaldata = data.iloc[:,:l]\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    \"\"\"\n",
    "    data.iloc[:,0] = le.fit_transform(data.iloc[:,0])\n",
    "    #classCount = classprocess(output)\n",
    "    #data = data.T\n",
    "    mergeRandom = pd.concat([data,allRandomHalf[index]],axis=0)\n",
    "    #print(mergeRandom)\n",
    "    \n",
    "    output = mergeRandom.iloc[:,l];\n",
    "    finaldata = mergeRandom.iloc[:,:l]\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(finaldata, output)\n",
    "\n",
    "\n",
    "    test_file = pd.read_excel(test[index],index_col=0) #不然會有多出來的 unnamed column\n",
    "    test_data = pd.DataFrame(test_file);\n",
    "    test_data.Class= test_data.Class.str.replace(\"\\n\", \"\").str.strip()   \n",
    "\n",
    "    test_X = test_data.iloc[:,:(test_data.shape[1])-1] \n",
    "    test_X.iloc[:,0] = le.fit_transform(test_X.iloc[:,0])\n",
    "\n",
    "    test_y_predicted = clf.predict(test_X)\n",
    "    test_y = test_data.iloc[:,test_data.shape[1]-1] \n",
    "    test_y = le.fit_transform(test_y)\n",
    "    accuracy = roc_auc_score(test_y, test_y_predicted)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "\n",
    "mean = statistics.mean(accuracies)\n",
    "print(mean)\n",
    "\n",
    "#len(mergeRandom[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}