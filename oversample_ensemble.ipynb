{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os;\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/emily/Desktop/Research/oversampling_python\"\n",
    "dirs = os.listdir(path+\"/data/pima-5-fold\")\n",
    "os.chdir(path+\"/data/pima-5-fold\")\n",
    "# åˆ°æ™‚å€™ path é€™é‚Šä¹Ÿè¦ loop ä¸åŒè³‡æ–™é›†çš„è³‡æ–™å¤¾\n",
    "# è¾“å‡ºæ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹\n",
    "train = []\n",
    "test = []\n",
    "allfile = []\n",
    "for file in dirs:\n",
    "    if(\"xlsx\" in file):\n",
    "        allfile.append(file)\n",
    "        if(\"tra\" in file ):\n",
    "            train.append(file)\n",
    "        elif(\"tst\" in file):\n",
    "            test.append(file)\n",
    "allfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "noisy 231 \n",
      "border 191 \n",
      "safe 193 \n",
      "all 615\n",
      "191\n",
      "noisy 231 \n",
      "border 191 \n",
      "safe 193 \n",
      "all 615\n",
      "191\n",
      "noisy 231 \n",
      "border 191 \n",
      "safe 193 \n",
      "all 615\n",
      "noisy 231 \n",
      "border 191 \n",
      "safe 193 \n",
      "all 615\n",
      "noisy 231 \n",
      "border 191 \n",
      "safe 193 \n",
      "all 615\n",
      "215\n",
      "400\n",
      "noisy 241 \n",
      "border 161 \n",
      "safe 213 \n",
      "all 615\n",
      "161\n",
      "noisy 241 \n",
      "border 161 \n",
      "safe 213 \n",
      "all 615\n",
      "161\n",
      "noisy 241 \n",
      "border 161 \n",
      "safe 213 \n",
      "all 615\n",
      "noisy 241 \n",
      "border 161 \n",
      "safe 213 \n",
      "all 615\n",
      "noisy 241 \n",
      "border 161 \n",
      "safe 213 \n",
      "all 615\n",
      "215\n",
      "400\n",
      "noisy 239 \n",
      "border 172 \n",
      "safe 203 \n",
      "all 614\n",
      "172\n",
      "noisy 239 \n",
      "border 172 \n",
      "safe 203 \n",
      "all 614\n",
      "172\n",
      "noisy 239 \n",
      "border 172 \n",
      "safe 203 \n",
      "all 614\n",
      "noisy 239 \n",
      "border 172 \n",
      "safe 203 \n",
      "all 614\n",
      "noisy 239 \n",
      "border 172 \n",
      "safe 203 \n",
      "all 614\n",
      "214\n",
      "400\n",
      "noisy 238 \n",
      "border 181 \n",
      "safe 195 \n",
      "all 614\n",
      "181\n",
      "noisy 238 \n",
      "border 181 \n",
      "safe 195 \n",
      "all 614\n",
      "181\n",
      "noisy 238 \n",
      "border 181 \n",
      "safe 195 \n",
      "all 614\n",
      "noisy 238 \n",
      "border 181 \n",
      "safe 195 \n",
      "all 614\n",
      "noisy 238 \n",
      "border 181 \n",
      "safe 195 \n",
      "all 614\n",
      "214\n",
      "400\n",
      "noisy 225 \n",
      "border 183 \n",
      "safe 206 \n",
      "all 614\n",
      "183\n",
      "noisy 225 \n",
      "border 183 \n",
      "safe 206 \n",
      "all 614\n",
      "183\n",
      "noisy 225 \n",
      "border 183 \n",
      "safe 206 \n",
      "all 614\n",
      "noisy 225 \n",
      "border 183 \n",
      "safe 206 \n",
      "all 614\n",
      "noisy 225 \n",
      "border 183 \n",
      "safe 206 \n",
      "all 614\n",
      "214\n",
      "400\n",
      "0.9503267973856209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "import statistics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "os.chdir(\"/Users/emily/Desktop/Research/oversampling_python/data/pima-5-fold\")\n",
    "accuracies=[]\n",
    "oversampleRCSMOTE = [] # å…¨éƒ¨ 5 å€‹ train data æ‰€è¨“ç·´å‡ºä¾†çš„ oversample data\n",
    "for i in train:\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    #data = data.iloc[:,1:]\n",
    "\n",
    "    l = data.shape[1]-1\n",
    "    output = np.array(data.iloc[:,l]);\n",
    "    finaldata = np.array(data.iloc[:,:l])\n",
    "    BSnn = getBSnn_Majnn(3,finaldata,output,data)[0]\n",
    "    Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "    Range = range_value(3,finaldata,output,data)\n",
    "    P_max = range_value(3,finaldata,output,data)[0]\n",
    "    Range = range_value(3,finaldata,output,data)[2]\n",
    "    alldata = data.T\n",
    "    classCount = classprocess(output)\n",
    "    \n",
    "    tempover = []\n",
    "    for i in range(len(classCount)):\n",
    "        if(int(classCount[i][1]) > 0):\n",
    "            over = Populate(int(classCount[i][1]),BSnn,Majnn,Range,P_max,finaldata,classCount[i][0])\n",
    "            tempover.extend(over)\n",
    "            \n",
    "            length = alldata.shape[1]\n",
    "            for j in range(len(over)):\n",
    "                alldata[length+j] = over[j]\n",
    "    X = alldata.T.iloc[:,:alldata.shape[0]-1]\n",
    "    y = alldata.T.iloc[:,alldata.shape[0]-1]\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(X, y) # è¨“ç·´ model\n",
    "    oversampleRCSMOTE.append(tempover)\n",
    "    \"\"\" ç•«æ¨¹\n",
    "    dot_data = tree.export_graphviz(clf)\n",
    "    fig = pyplot.figure(figsize=(25,20))\n",
    "    _ = tree.plot_tree(clf)\n",
    "    tree.plot_tree(clf) \n",
    "    \"\"\"\n",
    "    test_file = pd.read_excel(test[i],index_col=0) #ä¸ç„¶æœƒæœ‰å¤šå‡ºä¾†çš„ unnamed column\n",
    "    test_data = pd.DataFrame(test_file);\n",
    "    test_data.Class= test_data.Class.str.replace(\"\\n\", \"\").str.strip()   \n",
    "\n",
    "    \"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in range(test_data.shape[1]):\n",
    "        test_data.iloc[:,i] = le.fit_transform(test_data.iloc[:,i]) \n",
    "    \"\"\"\n",
    "    test_X = test_data.iloc[:,:(test_data.shape[1])-1] \n",
    "\n",
    "    test_y_predicted = clf.predict(test_X)\n",
    "    test_y = test_data.iloc[:,test_data.shape[1]-1] \n",
    "   \n",
    "    accuracy = metrics.accuracy_score(test_y, test_y_predicted)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "\n",
    "mean = statistics.mean(accuracies)\n",
    "print(mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çŸ¥é“ array çš„å‘é‡ç¶­åº¦\n",
    "#np.array().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random é¸ RCSMOTE çš„\n",
    "import random\n",
    "randomRCSMOTE =[]\n",
    "randomindex = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(oversampleRCSMOTE[0],columns= data.columns)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "overSMOTE = []\n",
    "alloverSMOTE = []\n",
    "for i in train:\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    #data = data.iloc[:,1:]\n",
    "    tempover = []\n",
    "    l = data.shape[1]-1\n",
    "    output = np.array(data.iloc[:,l]);\n",
    "    finaldata = np.array(data.iloc[:,:l])\n",
    "    \n",
    "    over = SMOTE()\n",
    "    X_smote,y_smote = over.fit_resample(finaldata,output)\n",
    "    \n",
    "    for index,element in enumerate(X_smote):\n",
    "        temp = np.append(element,[y_smote[index]])\n",
    "        alloverSMOTE.append(temp)\n",
    "    \n",
    "    #tempover.extend([X_smote,y_smote])\n",
    "\n",
    "    overSMOTE.append(alloverSMOTE)\n",
    "    print(len(overSMOTE),\"len\")\n",
    "    alloverSMOTE = [] \n",
    "print(len(overSMOTE[0]))\n",
    "np.array(overSMOTE).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranodom half SMOTE \n",
    "alloverSMOTE = []\n",
    "overSMOTE = []\n",
    "randomSMOTE = []\n",
    "\n",
    "for ii,i in enumerate(train):\n",
    "    randomIndex = []\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    output = np.array(data.iloc[:,l]);\n",
    "    classCount = classprocess(output)\n",
    "    finaldata = np.array(data.iloc[:,:l])\n",
    "    tempover = []\n",
    "    over = SMOTE()\n",
    "    X_smote,y_smote = over.fit_resample(finaldata,output)\n",
    "    newDataCount = len(X_smote) - len(data)  # æ–°ç”Ÿæˆçš„ data æ•¸é‡\n",
    "    # æŠŠ X_smote è·Ÿ y_smote å’Œåœ¨ä¸€èµ·\n",
    "    for index,element in enumerate(X_smote):\n",
    "        temp = np.append(element,[y_smote[index]])\n",
    "        alloverSMOTE.append(temp)\n",
    "    overSMOTE.append(alloverSMOTE)\n",
    "    alloverSMOTE =[]\n",
    "    \n",
    "    for i in range(len(classCount)):\n",
    "        count = math.floor(int(classCount[i][1])/2); # è¦ç”¢ç”Ÿå¤šå°‘æ•¸æ“š  ç„¡æ¢ä»¶æ¨å»\n",
    "        randomIndex.extend([random.randint(len(data),len(X_smote)-1) for _ in range(count)]) \n",
    "    \n",
    "    randomtemp = []\n",
    "\n",
    "    \n",
    "    for index in randomIndex:\n",
    "       \n",
    "        randomtemp.append(overSMOTE[ii][index])\n",
    "        \n",
    "    randomSMOTE.append(randomtemp)\n",
    "    print(ii,\" \",len(randomtemp))\n",
    "    print(np.array(randomSMOTE).shape)\n",
    "    #print(\"actual\",len(randomSMOTE[ii]))\n",
    "    \n",
    "    #print(\"we\",len(randomSMOTE[ii]))\n",
    "np.array(randomSMOTE).shape\n",
    "\n",
    "#ç¾åœ¨ randomSMOTE å­˜çš„æ˜¯ random çš„ SMOTE ç”Ÿæˆ data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”¢ç”Ÿ random RCSMOTE\n",
    "randomRCSMOTE = []\n",
    "for ii,i in enumerate(train):\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    #data = data.iloc[:,1:]\n",
    "\n",
    "    l = data.shape[1]-1\n",
    "    output = np.array(data.iloc[:,l]);\n",
    "    finaldata = np.array(data.iloc[:,:l])\n",
    "    BSnn = getBSnn_Majnn(3,finaldata,output,data)[0]\n",
    "    Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "    Range = range_value(3,finaldata,output,data)\n",
    "    P_max = range_value(3,finaldata,output,data)[0]\n",
    "    Range = range_value(3,finaldata,output,data)[2]\n",
    "    alldata = data.T\n",
    "    classCount = classprocess(output)\n",
    "    randomIndex = []\n",
    "    tempover = []\n",
    "    for j in range(len(classCount)):\n",
    "        if(int(classCount[j][1]) > 0):\n",
    "            over = Populate(int(classCount[j][1]),BSnn,Majnn,Range,P_max,finaldata,classCount[j][0])\n",
    "            tempover.append(over)\n",
    "            #length = alldata.shape[1]\n",
    "    oversampleRCSMOTE.append(tempover)\n",
    " \n",
    "    \n",
    "    for a in range(len(classCount)): # ç”¢ç”Ÿ random index\n",
    "        count = math.ceil(int(classCount[a][1])/2); # è¦ç”¢ç”Ÿå¤šå°‘æ•¸æ“š  ç„¡æ¢ä»¶æ¨å»\n",
    "        randomIndex.extend([random.randint(0,len(oversampleRCSMOTE[ii])-1) for _ in range(count)]) \n",
    "    \n",
    "    randomtemp = []\n",
    "    #print(\"randomindex\",len(randomIndex))\n",
    "    \n",
    "    for index in randomIndex:\n",
    "        randomtemp.append(oversampleRCSMOTE[ii][index])\n",
    "    randomRCSMOTE.append(randomtemp)\n",
    "    #print(\"actual\",len(randomSMOTE[ii]))\n",
    " \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random SMOTE + RCSMOTE å„ä¸€åŠçš„çµæœ \n",
    "allRandomHalf = []\n",
    "temp = []\n",
    "for i in range(len(randomRCSMOTE)):\n",
    "    temp = randomRCSMOTE[i] + randomSMOTE[i]\n",
    "    allRandomHalf.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[17.241222527186938,\n",
       " 144.06180985203403,\n",
       " 67.77905029201011,\n",
       " 10.219548052911474,\n",
       " 16.298417153350194,\n",
       " 37.43439882782506,\n",
       " 13.198113983117274,\n",
       " 36.95063417049988,\n",
       " 'tested_positive']"
      ]
     },
     "metadata": {},
     "execution_count": 465
    }
   ],
   "source": [
    "allRandomHalf[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "execution_count": 513
    }
   ],
   "source": [
    "len(allRandomHalf[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "215\n",
      "400\n",
      "215\n",
      "400\n",
      "214\n",
      "400\n",
      "214\n",
      "400\n",
      "214\n",
      "400\n",
      "0.9071895424836601\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n    for i in range(len(classCount)):\\n    #print(int(classCount[i][1]))\\n        if(int(classCount[i][1]) > 0):\\n            #over = Populate(int(classCount[i][1]),BSnn,Majnn,Range,P_max,finaldata,classCount[i][0])\\n            length = alldata.shape[1]\\n            for j in range(len(over)):\\n                alldata[length+j] = over[j]\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 536
    }
   ],
   "source": [
    "# è·ŸåŸå§‹è³‡æ–™åˆä½µ\n",
    "mergeRandom = []\n",
    "for index,element in enumerate(train):\n",
    "    data = pd.read_excel(element,index_col =0);\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    l = data.shape[1]-1\n",
    "    output = np.array(data.iloc[:,l]);\n",
    "    finaldata = np.array(data.iloc[:,:l])\n",
    "    classCount = classprocess(output)\n",
    "    data = data.T\n",
    "    \n",
    "    \n",
    "    for i in range(len(allRandomHalf[index])): # 185\n",
    "        #for j in range(len(allRandomHalf[index][0])): #9\n",
    "            datalength = data.shape[1]\n",
    "            data[datalength+i+1] = allRandomHalf[index][j]\n",
    "    #print(data)  \n",
    "        #print(datalength)\n",
    "        #print(allRandomHalf[index][i],\"sl;d\")\n",
    "    mergeRandom = data.T\n",
    "    l = mergeRandom.shape[1]-1\n",
    "    output = np.array(mergeRandom.iloc[:,l]);\n",
    "    finaldata = np.array(mergeRandom.iloc[:,:l])\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(finaldata, output)\n",
    "\n",
    "\n",
    "    test_file = pd.read_excel(test[index],index_col=0) #ä¸ç„¶æœƒæœ‰å¤šå‡ºä¾†çš„ unnamed column\n",
    "    test_data = pd.DataFrame(test_file);\n",
    "    test_data.Class= test_data.Class.str.replace(\"\\n\", \"\").str.strip()   \n",
    "\n",
    "    test_X = test_data.iloc[:,:(test_data.shape[1])-1] \n",
    "\n",
    "    test_y_predicted = clf.predict(test_X)\n",
    "    test_y = test_data.iloc[:,test_data.shape[1]-1] \n",
    "   \n",
    "    accuracy = metrics.accuracy_score(test_y, test_y_predicted)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "\n",
    "mean = statistics.mean(accuracies)\n",
    "print(mean)\n",
    "\"\"\"\n",
    "    for i in range(len(classCount)):\n",
    "    #print(int(classCount[i][1]))\n",
    "        if(int(classCount[i][1]) > 0):\n",
    "            #over = Populate(int(classCount[i][1]),BSnn,Majnn,Range,P_max,finaldata,classCount[i][0])\n",
    "            length = alldata.shape[1]\n",
    "            for j in range(len(over)):\n",
    "                alldata[length+j] = over[j]\n",
    "\"\"\"\n",
    "#len(mergeRandom[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0]\n",
    "data = pd.read_excel(train[0],index_col=0)\n",
    "data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "data = pd.DataFrame(data,dtype=object)\n",
    "data = data.iloc[:5,:]\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas._testing import assert_frame_equal\n",
    "df3 = pd.DataFrame(overSMOTE[0],columns=data.columns,dtype=object)\n",
    "df3.index += 1\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas._testing import assert_frame_equal\n",
    "df1 = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "df2 = pd.DataFrame({'a': [1, 2], 'b': [3.0, 4.0]})\n",
    "a = assert_frame_equal(df1, df1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling SMOTE + RCSMOTE  Random é¸æ“‡ ä¸€åŠä¸€åŠ\n",
    "# æ²’æœ‰ä½œç”¨\n",
    "import random \n",
    "import math\n",
    "classCount = classprocess(output)\n",
    "randomSmote = []\n",
    "tempRCSMOTE = []\n",
    "tempSMOTE = []\n",
    "BSnn = getBSnn_Majnn(3,finaldata,output,data)[0]\n",
    "Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "Range = range_value(3,finaldata,output,data)\n",
    "P_max = range_value(3,finaldata,output,data)[0]\n",
    "Range = range_value(3,finaldata,output,data)[2]\n",
    "for i in range(len(classCount)):\n",
    "    count = math.ceil(int(classCount[i][1])/2); # è¦ç”¢ç”Ÿå¤šå°‘æ•¸æ“š  ç„¡æ¢ä»¶æ¨å»\n",
    "    randomSmote.append([random.randint(0, len(output)-1) for _ in range(count)])\n",
    "print(randomSmote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape[1] # è¡Œæ•¸    data.shape[0] åˆ—æ•¸\n",
    "os.chdir(\"/Users/emily/Desktop/Research/oversampling_python/data/\");\n",
    "#print(os.getcwd());\n",
    "\n",
    "data = pd.read_excel(\"pima.xlsx\")\n",
    "data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "\n",
    "data = data.iloc[:,1:]\n",
    "data.shape[1]\n",
    "l = data.shape[1]-1\n",
    "\n",
    "output = np.array(data.iloc[:,l]);\n",
    "finaldata = np.array(data.iloc[:,:l])\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(output)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tedata = data\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in range(tedata.shape[1]):\n",
    "    tedata.iloc[:,i] = le.fit_transform(tedata.iloc[:,i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†ä½ˆ\n",
    "counter = Counter(output)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(output) * 100\n",
    "\tprint(\"class\",k,\"æ•¸é‡ï¼š\",v,\"percentage\",'%.3f' %per,\"%\")\n",
    "\t#print('Class=%s, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()\n",
    "ir = 500/268;\n",
    "print(\"IR \",ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¾å‡º knn\n",
    "def knn(n_nu,sample):\n",
    "     # n_nu è‡ªå·±è¨­å®šå¤šå°‘é„°è¿‘å€‹é»\n",
    "     # input sample æ²’æœ‰åŒ…å« class label\n",
    "        nnarray = []\n",
    "        neighbors=NearestNeighbors(n_neighbors=n_nu+1).fit(sample)\n",
    "        for i in range(len(sample)):\n",
    "            temp = neighbors.kneighbors(sample[i].reshape(1,-1),return_distance=False)[0]\n",
    "            temp = np.delete(temp,0)\n",
    "            # æœ‰ array å­˜æ”¾ å„å€‹é»çš„é„°è¿‘é» \n",
    "            nnarray.append(temp)\n",
    "        return nnarray # å›å‚³ç›¸è¿‘çš„é» åˆ†åˆ¥æ˜¯åœ¨ç¬¬å¹¾å€‹ \n",
    "karray = knn(3,finaldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¾å‡ºå¤§é¡\n",
    "def find_maj(sample_class):\n",
    "    counter = Counter(sample_class);\n",
    "    maj = list(dict(counter.most_common(1)).keys())\n",
    "    maj = \"\".join(maj)\n",
    "    return  maj\n",
    "\n",
    "find_maj(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ¤æ–·è©²é»ç‚ºä»€éº¼é¡å‹çš„é» \n",
    "# æ­¤ index æ˜¯ 0 é–‹å§‹ æ‰€ä»¥å°ç…§åˆ° excel çš„è¦\n",
    "# inminority æ˜¯å¦æ˜¯è¦æ±‚åœ¨å°é¡ä¸­çš„ å¦‚æœæ˜¯å‰‡æ”¾ true\n",
    "def check_point_type(n_nu,sample,sample_class,data,inminority):\n",
    "    # ä½¿ç”¨ find_maj(find_maj(sample_class)\n",
    "    # ä½¿ç”¨ knn æ‰¾åˆ°é„°è¿‘çš„å¹¾å€‹é» \n",
    "    point_type = [] # æ”¾å€‹é»æ˜¯å±¬æ–¼ä»€éº¼é¡å‹çš„ border safe noisy\n",
    "    n = 0\n",
    "    b = 0\n",
    "    s = 0\n",
    "    maj = find_maj(sample_class) # å¤§é¡\n",
    "    point = knn(n_nu,sample) # å›å‚³æ‰€æœ‰é»é„°è¿‘ n_nu å€‹é»\n",
    "    #maj = \"\".join(maj) # maj åŸæœ¬æ˜¯ list è½‰æˆ str\n",
    "    for index,i in enumerate(point):\n",
    "        maj_nu =0;\n",
    "        if(data.iloc[index,data.shape[1]-1] == maj and inminority == True): # å¦‚æœè©²é»æœ¬èº«æ˜¯å¤§é¡å‰‡ä¸è¨ˆç®—\n",
    "            continue; # å¦‚æœä½¿ç”¨æ­¤ å‰‡æœƒè·Ÿè«–æ–‡çš„ data ä¸€æ¨£\n",
    "        for j in point[index]: # æ¯å€‹é»é„°è¿‘å€‹é»çš„ loop ä¾‹å¦‚ç¬¬ä¸€å€‹é»æ˜¯ [1,2,3,4,5] å‰‡ loop è£¡é¢çš„æ•¸å€¼\n",
    "            if(data.iloc[j,data.shape[1]-1] == maj ): \n",
    "                maj_nu = maj_nu + 1 # è¨ˆç®—é„°è¿‘é»ç‚ºå¤§é¡çš„æœ‰å¤šå°‘å€‹\n",
    "        if(maj_nu == n_nu ):\n",
    "            point_type.append(\"noisy\");\n",
    "            n = n+1\n",
    "        elif(n_nu/2 < maj_nu and maj_nu < n_nu ):\n",
    "            point_type.append(\"border\");\n",
    "            b = b+1\n",
    "        else:\n",
    "            point_type.append(\"safe\");\n",
    "            s = s+1\n",
    "    print(\"noisy\",n,\"\\nborder\",b,\"\\nsafe\",s,\"\\nall\",n+b+s)\n",
    "    return point_type;\n",
    "point_type = check_point_type(3,finaldata,output,data,True) # è«–æ–‡ä½¿ç”¨ knn ç‚º 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è³‡æ–™é›†è®Šç‚ºå°é¡çš„ border è·Ÿ safe ä»¥åŠ å¤§é¡ å»é™¤ å°é¡ä¸”ç‚º noisy çš„\n",
    "\"\"\"\n",
    "find the maximum value that existed for that attribute among\n",
    "the minority samples of the ğµğ‘† set, and also, find the minimum value that existed for\n",
    "the given attribute among the majority samples set\n",
    "\"\"\"\n",
    "# å…ˆæ˜¯å°é¡å»æ‰ noisy å†ä¾†æ˜¯ å¤§é¡ \n",
    "def split_BS_Majdata(point_type,sample,sample_class):\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # å¤§é¡\n",
    "    #maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(sample[i])\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(sample[i])\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "  \n",
    "    return return_sample\n",
    "point_type = check_point_type(3,finaldata,output,data,False)\n",
    "split_BS_Majdata(point_type,finaldata,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_split_BS_Majdata(point_type,sample,sample_class): # maj ä»¥åŠ BS set åœ¨åŸæœ¬ data çš„ index\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # å¤§é¡\n",
    "    #maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(i)\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(i)\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "    \n",
    "    return return_sample\n",
    "point_type = check_point_type(3,finaldata,output,data,False)\n",
    "index_split_BS_Majdata(point_type,finaldata,output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = Counter(output)\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classprocess(output):\n",
    "    c = Counter(output)\n",
    "    datagap = []\n",
    "    maj = find_maj(output)\n",
    "    maj_num = dict(c)[find_maj(output)]\n",
    "    for className, number in c.items(): \n",
    "        #print(className,\" \",number)\n",
    "        print(number)\n",
    "        temp = np.array([className,(maj_num - number)])\n",
    "        datagap.append(temp)\n",
    "    return datagap\n",
    "\n",
    "classprocess(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The obtained ranges for\n",
    "all features (attributes) are used to control the location of the new synthetic samples in\n",
    "data space.\n",
    "\n",
    "The set of these ranges is denoted by ğ‘…ğ‘ğ‘›ğ‘”ğ‘’ =\n",
    "(ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’1 ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’2 ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’3 â€¦ ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ) array where ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ is the number of\n",
    "attributes in the dataset\n",
    "\n",
    "å¦‚ä½•ç”¢ç”Ÿ Range array\n",
    "1. we find the maximum value that existed for that attribute among\n",
    "the minority samples of the ğµğ‘† set  ğ‘ƒ _ğ‘šğ‘ğ‘¥ = (ğ‘ğ‘šğ‘ğ‘¥1 ğ‘ğ‘šğ‘ğ‘¥2\n",
    "â€¦ğ‘ğ‘šğ‘ğ‘¥ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ) array\n",
    "\n",
    "2. find the minimum value that existed for\n",
    "the given attribute among the majority samples set  ğ‘ _ğ‘šğ‘–ğ‘› = (ğ‘›ğ‘šğ‘–ğ‘›1 ğ‘›ğ‘šğ‘–ğ‘›2 â€¦ğ‘›ğ‘šğ‘–ğ‘›ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ)array\n",
    "\n",
    "3. Then, the desired ğ‘…ğ‘ğ‘›ğ‘”ğ‘’ vector is obtained as the average of ğ‘_ğ‘šğ‘–ğ‘› and\n",
    "ğ‘ƒ _ğ‘šğ‘ğ‘¥ arrays\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# dataframe[0] è¡Œæ•¸  dataframe[1] åˆ—æ•¸\n",
    "# è©²å±¬æ€§ä¸­ åœ¨ bs set çš„æœ€å¤§å€¼ ä»¥åŠ å¤§é¡ä¸­çš„æœ€å°å€¼\n",
    "# range ç‚ºå…©å€‹ç›¸åŠ é™¤ä»¥ 2\n",
    "# index_split_BS_Majdata å›å‚³ [0] BS set [1] å›å‚³ Maj set\n",
    "def range_value(n_nu,sample,sample_class,data):\n",
    "    point_type = check_point_type(n_nu,sample,sample_class,data,False)\n",
    "    index = index_split_BS_Majdata(point_type,sample,sample_class)\n",
    "    BS_max = []\n",
    "    Maj_min = []\n",
    "    all_value = []\n",
    "    for i in range(len(sample[0])): # loop å±¬æ€§\n",
    "        for j in range(2): # loop data\n",
    "            if(j==0): # BS set çš„ index\n",
    "                BS_index = index[j]\n",
    "                max_value = np.max(sample[BS_index][i]);\n",
    "                BS_max.append(max_value)\n",
    "            else:\n",
    "                Maj_index = index[j]\n",
    "                min_value = np.min(sample[Maj_index][i]);\n",
    "                Maj_min.append(min_value)\n",
    "    # temp = np.array([BS_max,Maj_min]) \n",
    "    range_value = [(BS_max[i] - Maj_min[i])/2 for i in range(len(BS_max))]\n",
    "    all_value = np.array([BS_max,Maj_min,range_value])\n",
    "    return all_value\n",
    "range_value(3,finaldata,output,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bğ‘›ğ‘¢ğ‘š: Number of samples in ğµğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ å±¬æ–¼ border çš„è³‡æ–™æ•¸\n",
    "# compute its(border sample) k nearest neighbors in BS, and save them in BSnn å­˜æ”¾ \n",
    "# compute its(border sample) k nearest neighbors in Maj set, and save them in Majnn\n",
    "def getBSnn_Majnn(n_nu,sample,sample_class,data):     \n",
    "    point_type = check_point_type(n_nu,sample,sample_class,data,False) # å¾—çŸ¥æ‰€æœ‰ sample ä¸­å±¬æ–¼ border çš„  \n",
    "    index = index_split_BS_Majdata(point_type,sample,sample_class) \n",
    "    k = knn(n_nu,sample)\n",
    "    BSnn = []\n",
    "    Majnn = []\n",
    "    # ç”¨ border sample çš„ index \n",
    "    for i,element in enumerate(point_type):\n",
    "        if(element == \"border\"):\n",
    "            for j in range(2):\n",
    "                for w in index[j]:\n",
    "                    if(j == 0 and i == w ):\n",
    "                        BSnn.append(k[w])\n",
    "                    elif(j==1 and i == w):\n",
    "                        Majnn.append(k[w])\n",
    "        \n",
    "    temp = np.array([BSnn,Majnn]);\n",
    "    print(len(temp[0]+temp[1]))\n",
    "    return temp\n",
    "    \n",
    "len(getBSnn_Majnn(3,finaldata,output,data)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆè³‡æ–™\n",
    "\n",
    "def Populate(r,BSnn,Majnn,Range,P_max,sample,classbelong):\n",
    "    # r ä»£è¡¨è¦ç”¢ç”Ÿçš„è³‡æ–™çš„æ•¸é‡ è«–æ–‡å®šç¾©è©²æ•¸é‡ç‚ºå¢åŠ å°é¡è‡³è·Ÿå¤§é¡ç›¸åŒçš„æ•¸é‡ é”æˆ 50% (å¤§é¡æ¸›å°é¡çš„æ•¸é‡)\n",
    "    Bl = len(BSnn)-1\n",
    "    nn_nu = len(BSnn[0])-1\n",
    "    Ml = len(Majnn)-1\n",
    "    Synthetic = []\n",
    "    while(r > 0):\n",
    "\n",
    "        s1row = random.randint(0,Bl)\n",
    "        s1col = random.randint(0,nn_nu)\n",
    "        s1 = BSnn[s1row][s1col]\n",
    "        s2row = random.randint(0,Ml)\n",
    "        s2col = random.randint(0,nn_nu)\n",
    "        s2 = Majnn[s2row][s2col]\n",
    "        min_attr = []\n",
    "        for i in range(len(sample[0])):\n",
    "        \n",
    "            if(sample[s1][i] < sample[s2][i]):\n",
    "                min_attr.append(sample[s1][i])\n",
    "            else:\n",
    "                min_attr.append(sample[s2][i])\n",
    "        diff = [(P_max[i] - min_attr[i]) for i in range(len(P_max))]\n",
    "        #print(\"diff\",diff)\n",
    "        gap = random.uniform(0,0.5)\n",
    "        var = [(diff[i] * gap ) for i in range(len(diff))]\n",
    "        temp = []\n",
    "        for i in range(len(sample[0])):\n",
    "            if(min_attr[i]+var[i] <= Range[i]):\n",
    "                temp.append(min_attr[i]+var[i])\n",
    "            else:\n",
    "                temp.append(P_max[i]-var[i])\n",
    "        temp.append(classbelong)\n",
    "        Synthetic.append(temp)   \n",
    "        r = r-1\n",
    "    return Synthetic\n",
    "    \n",
    "needToGenerate = 232\n",
    "BSnn = getBSnn_Majnn(3,finaldata,output,data)[0]\n",
    "Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "Range = range_value(3,finaldata,output,data)\n",
    "P_max = range_value(3,finaldata,output,data)[0]\n",
    "Range = range_value(3,finaldata,output,data)[2]\n",
    "#Populate(needToGenerate,BSnn,Majnn,Range,P_max,finaldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   1                2                3                4    \\\n",
       "Preg              14.0              4.0             15.0              5.0   \n",
       "Plas             175.0            146.0            136.0            116.0   \n",
       "Pres              62.0             78.0             70.0             74.0   \n",
       "Skin              30.0              0.0             32.0             29.0   \n",
       "Insu               0.0              0.0            110.0              0.0   \n",
       "Mass              33.6             38.5             37.1             32.3   \n",
       "Pedi             0.212             0.52            0.153             0.66   \n",
       "Age               38.0             67.0             43.0             35.0   \n",
       "Class  tested_positive  tested_positive  tested_positive  tested_positive   \n",
       "\n",
       "                   5                6                7                8    \\\n",
       "Preg               6.0              3.0              3.0              4.0   \n",
       "Plas               0.0            173.0            162.0            146.0   \n",
       "Pres              68.0             78.0             52.0             92.0   \n",
       "Skin              41.0             39.0             38.0              0.0   \n",
       "Insu               0.0            185.0              0.0              0.0   \n",
       "Mass              39.0             33.8             37.2             31.2   \n",
       "Pedi             0.727             0.97            0.652            0.539   \n",
       "Age               41.0             31.0             24.0             61.0   \n",
       "Class  tested_positive  tested_positive  tested_positive  tested_positive   \n",
       "\n",
       "                   9                10   ...              605  \\\n",
       "Preg               2.0              9.0  ...              1.0   \n",
       "Plas             155.0            145.0  ...            103.0   \n",
       "Pres              52.0             80.0  ...             80.0   \n",
       "Skin              27.0             46.0  ...             11.0   \n",
       "Insu             540.0            130.0  ...             82.0   \n",
       "Mass              38.7             37.9  ...             19.4   \n",
       "Pedi              0.24            0.637  ...            0.491   \n",
       "Age               25.0             40.0  ...             22.0   \n",
       "Class  tested_positive  tested_positive  ...  tested_negative   \n",
       "\n",
       "                   606              607              608              609  \\\n",
       "Preg               2.0              4.0              1.0              2.0   \n",
       "Plas             141.0            147.0            109.0            100.0   \n",
       "Pres              58.0             74.0             60.0             68.0   \n",
       "Skin              34.0             25.0              8.0             25.0   \n",
       "Insu             128.0            293.0            182.0             71.0   \n",
       "Mass              25.4             34.9             25.4             38.5   \n",
       "Pedi             0.699            0.385            0.947            0.324   \n",
       "Age               24.0             30.0             21.0             26.0   \n",
       "Class  tested_negative  tested_negative  tested_negative  tested_negative   \n",
       "\n",
       "                   610              611              612              613  \\\n",
       "Preg               6.0              6.0              5.0              7.0   \n",
       "Plas             114.0             92.0            117.0            119.0   \n",
       "Pres              88.0             92.0             92.0              0.0   \n",
       "Skin               0.0              0.0              0.0              0.0   \n",
       "Insu               0.0              0.0              0.0              0.0   \n",
       "Mass              27.8             19.9             34.1             25.2   \n",
       "Pedi             0.247            0.188            0.337            0.209   \n",
       "Age               66.0             28.0             38.0             37.0   \n",
       "Class  tested_negative  tested_negative  tested_negative  tested_negative   \n",
       "\n",
       "                   614  \n",
       "Preg               1.0  \n",
       "Plas             181.0  \n",
       "Pres              64.0  \n",
       "Skin              30.0  \n",
       "Insu             180.0  \n",
       "Mass              34.1  \n",
       "Pedi             0.328  \n",
       "Age               38.0  \n",
       "Class  tested_positive  \n",
       "\n",
       "[9 rows x 614 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>605</th>\n      <th>606</th>\n      <th>607</th>\n      <th>608</th>\n      <th>609</th>\n      <th>610</th>\n      <th>611</th>\n      <th>612</th>\n      <th>613</th>\n      <th>614</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Preg</th>\n      <td>14.0</td>\n      <td>4.0</td>\n      <td>15.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Plas</th>\n      <td>175.0</td>\n      <td>146.0</td>\n      <td>136.0</td>\n      <td>116.0</td>\n      <td>0.0</td>\n      <td>173.0</td>\n      <td>162.0</td>\n      <td>146.0</td>\n      <td>155.0</td>\n      <td>145.0</td>\n      <td>...</td>\n      <td>103.0</td>\n      <td>141.0</td>\n      <td>147.0</td>\n      <td>109.0</td>\n      <td>100.0</td>\n      <td>114.0</td>\n      <td>92.0</td>\n      <td>117.0</td>\n      <td>119.0</td>\n      <td>181.0</td>\n    </tr>\n    <tr>\n      <th>Pres</th>\n      <td>62.0</td>\n      <td>78.0</td>\n      <td>70.0</td>\n      <td>74.0</td>\n      <td>68.0</td>\n      <td>78.0</td>\n      <td>52.0</td>\n      <td>92.0</td>\n      <td>52.0</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>80.0</td>\n      <td>58.0</td>\n      <td>74.0</td>\n      <td>60.0</td>\n      <td>68.0</td>\n      <td>88.0</td>\n      <td>92.0</td>\n      <td>92.0</td>\n      <td>0.0</td>\n      <td>64.0</td>\n    </tr>\n    <tr>\n      <th>Skin</th>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>32.0</td>\n      <td>29.0</td>\n      <td>41.0</td>\n      <td>39.0</td>\n      <td>38.0</td>\n      <td>0.0</td>\n      <td>27.0</td>\n      <td>46.0</td>\n      <td>...</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>25.0</td>\n      <td>8.0</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>30.0</td>\n    </tr>\n    <tr>\n      <th>Insu</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>110.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>185.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>540.0</td>\n      <td>130.0</td>\n      <td>...</td>\n      <td>82.0</td>\n      <td>128.0</td>\n      <td>293.0</td>\n      <td>182.0</td>\n      <td>71.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>180.0</td>\n    </tr>\n    <tr>\n      <th>Mass</th>\n      <td>33.6</td>\n      <td>38.5</td>\n      <td>37.1</td>\n      <td>32.3</td>\n      <td>39.0</td>\n      <td>33.8</td>\n      <td>37.2</td>\n      <td>31.2</td>\n      <td>38.7</td>\n      <td>37.9</td>\n      <td>...</td>\n      <td>19.4</td>\n      <td>25.4</td>\n      <td>34.9</td>\n      <td>25.4</td>\n      <td>38.5</td>\n      <td>27.8</td>\n      <td>19.9</td>\n      <td>34.1</td>\n      <td>25.2</td>\n      <td>34.1</td>\n    </tr>\n    <tr>\n      <th>Pedi</th>\n      <td>0.212</td>\n      <td>0.52</td>\n      <td>0.153</td>\n      <td>0.66</td>\n      <td>0.727</td>\n      <td>0.97</td>\n      <td>0.652</td>\n      <td>0.539</td>\n      <td>0.24</td>\n      <td>0.637</td>\n      <td>...</td>\n      <td>0.491</td>\n      <td>0.699</td>\n      <td>0.385</td>\n      <td>0.947</td>\n      <td>0.324</td>\n      <td>0.247</td>\n      <td>0.188</td>\n      <td>0.337</td>\n      <td>0.209</td>\n      <td>0.328</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>38.0</td>\n      <td>67.0</td>\n      <td>43.0</td>\n      <td>35.0</td>\n      <td>41.0</td>\n      <td>31.0</td>\n      <td>24.0</td>\n      <td>61.0</td>\n      <td>25.0</td>\n      <td>40.0</td>\n      <td>...</td>\n      <td>22.0</td>\n      <td>24.0</td>\n      <td>30.0</td>\n      <td>21.0</td>\n      <td>26.0</td>\n      <td>66.0</td>\n      <td>28.0</td>\n      <td>38.0</td>\n      <td>37.0</td>\n      <td>38.0</td>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>...</td>\n      <td>tested_negative</td>\n      <td>tested_negative</td>\n      <td>tested_negative</td>\n      <td>tested_negative</td>\n      <td>tested_negative</td>\n      <td>tested_negative</td>\n      <td>tested_negative</td>\n      <td>tested_negative</td>\n      <td>tested_negative</td>\n      <td>tested_positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>9 rows Ã— 614 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 470
    }
   ],
   "source": [
    "alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¯å€‹é¡åˆ¥éƒ½è¦ é€²è¡Œ populate é‡å°å¤šé¡åˆ¥\n",
    "alldata = data.T\n",
    "classCount = classprocess(output)\n",
    "index = 1\n",
    "for i in range(len(classCount)):\n",
    "    #print(int(classCount[i][1]))\n",
    "    if(int(classCount[i][1]) > 0):\n",
    "        over = Populate(int(classCount[i][1]),BSnn,Majnn,Range,P_max,finaldata,classCount[i][0])\n",
    "        length = alldata.shape[1]\n",
    "        for j in range(len(over)):\n",
    "            alldata[length+j] = over[j]\n",
    "alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = alldata.T.iloc[:,:alldata.shape[0]]\n",
    "y = alldata.T.iloc[:,alldata.shape[0]-1]\n",
    "overc = Counter(y)\n",
    "for i,v in overc.items():\n",
    "    print(\"class\",i,\"number\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸€èˆ¬ SMOTE\n",
    "print(\"SMOTE\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "modelD = DecisionTreeClassifier()\n",
    "modelR = RandomForestClassifier(n_estimators=1000)\n",
    "#clf = clf.fit(X, Y) # \n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scoresRandomForest = cross_val_score(modelR, finaldata, output, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "scoresDecisionTree = cross_val_score(modelD, finaldata, output, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC for RandomForest: %.3f' % mean(scoresRandomForest))\n",
    "print('Mean ROC AUC for DecisionTree: %.3f' % mean(scoresDecisionTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RCSMOTE\n",
    "print(\"RCSMOTE\")\n",
    "X = alldata.T.iloc[:,:alldata.shape[0]-1]\n",
    "y = alldata.T.iloc[:,alldata.shape[0]-1]\n",
    "modelD = DecisionTreeClassifier()\n",
    "modelR = RandomForestClassifier(n_estimators=1000)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scoresRandomForest = cross_val_score(modelR, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "scoresDecisionTree = cross_val_score(modelD, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC for RandomForest: %.3f' % mean(scoresRandomForest))\n",
    "print('Mean ROC AUC for DecisionTree: %.3f' % mean(scoresDecisionTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borderline\n",
    "print(\"Borderline\")\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "stepR = [('border_line', BorderlineSMOTE(random_state=42,kind=\"borderline-1\")), ('model', RandomForestClassifier(n_estimators=1000))] # RandomForestClassifier(n_estimators=1000)\n",
    "stepD = [('border_line', BorderlineSMOTE(random_state=42,kind=\"borderline-1\")), ('model', DecisionTreeClassifier())] \n",
    "pipelineD = Pipeline(steps=stepD)\n",
    "pipelineR = Pipeline(steps=stepR)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scoresDecisionTree = cross_val_score(pipelineD, finaldata, output, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "scoresRandomForest = cross_val_score(pipelineR, finaldata, output, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC for RandomForest: %.3f' % mean(scoresRandomForest))\n",
    "print('Mean ROC AUC for DecisionTree: %.3f' % mean(scoresDecisionTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}