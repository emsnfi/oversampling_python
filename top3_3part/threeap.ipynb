{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "440c858d28a36c9981deb3f0b3542b13a925970b1503e694b09cf153c81eca91"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smote_variants as sv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import statistics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.cluster import KMeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "path = \"/Users/emily/Desktop/Research/oversampling_python/data/\"\n",
    "folderName = 'abalone19-5-fold' # yeast6-5-fold'#'haberman-5-fold' #'abalone19-5-fold' \n",
    "os.chdir(path+ folderName)\n",
    "dirs = os.listdir(path+ folderName)\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for i in dirs:\n",
    "    #print(i.split(\"-\")[-1])\n",
    "    if(\"xlsx\" in i):\n",
    "        if(\"tra\" in i):\n",
    "            train.append(i)\n",
    "\n",
    "        elif(\"tst\" in i):\n",
    "            test.append(i)\n",
    "train = sorted(train)\n",
    "test = sorted(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maj(sample_class):\n",
    "    counter = Counter(sample_class);\n",
    "    maj = list(dict(counter.most_common(1)).keys())\n",
    "    maj = \"\".join(maj)\n",
    "    print(maj)\n",
    "    return  maj\n",
    "\n",
    "\n",
    "def classprocess(output):\n",
    "    c = Counter(output)\n",
    "    datagap = []\n",
    "    maj = find_maj(output)\n",
    "    maj_num = dict(c)[find_maj(output)]\n",
    "    for className, number in c.items(): \n",
    "        #print(className,\" \",number)\n",
    "        print(number)\n",
    "        temp = np.array([className,(maj_num - number)])\n",
    "        datagap.append(temp)\n",
    "    return datagap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-07 16:01:53,639:INFO:SMOTE_IPF: Running sampling via ('SMOTE_IPF', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_folds': 9, 'k': 3, 'p': 0.01, 'voting': 'majority', 'n_jobs': 1, 'classifier': DecisionTreeClassifier(random_state=2), 'random_state': None}\")\n",
      "2021-04-07 16:01:53,640:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from '/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/numpy/random/__init__.py'>}\")\n",
      "2021-04-07 16:01:53,971:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:01:54,287:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:01:54,609:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:01:55,622:INFO:SMOTE_IPF: Running sampling via ('SMOTE_IPF', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_folds': 9, 'k': 3, 'p': 0.01, 'voting': 'majority', 'n_jobs': 1, 'classifier': DecisionTreeClassifier(random_state=2), 'random_state': None}\")\n",
      "2021-04-07 16:01:55,622:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from '/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/numpy/random/__init__.py'>}\")\n",
      "2021-04-07 16:01:56,037:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:01:56,429:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:01:56,833:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:01:57,999:INFO:SMOTE_IPF: Running sampling via ('SMOTE_IPF', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_folds': 9, 'k': 3, 'p': 0.01, 'voting': 'majority', 'n_jobs': 1, 'classifier': DecisionTreeClassifier(random_state=2), 'random_state': None}\")\n",
      "2021-04-07 16:01:58,000:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from '/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/numpy/random/__init__.py'>}\")\n",
      "2021-04-07 16:01:58,368:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:01:58,719:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:01:59,058:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:02:00,211:INFO:SMOTE_IPF: Running sampling via ('SMOTE_IPF', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_folds': 9, 'k': 3, 'p': 0.01, 'voting': 'majority', 'n_jobs': 1, 'classifier': DecisionTreeClassifier(random_state=2), 'random_state': None}\")\n",
      "2021-04-07 16:02:00,212:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from '/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/numpy/random/__init__.py'>}\")\n",
      "2021-04-07 16:02:00,613:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:02:00,986:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:02:01,392:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:02:02,590:INFO:SMOTE_IPF: Running sampling via ('SMOTE_IPF', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_folds': 9, 'k': 3, 'p': 0.01, 'voting': 'majority', 'n_jobs': 1, 'classifier': DecisionTreeClassifier(random_state=2), 'random_state': None}\")\n",
      "2021-04-07 16:02:02,591:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from '/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/numpy/random/__init__.py'>}\")\n",
      "2021-04-07 16:02:02,995:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:02:03,378:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:02:03,756:INFO:SMOTE_IPF: Removing 0 elements\n",
      "0.6217310553178806\n"
     ]
    }
   ],
   "source": [
    "# 純 polynom_fit_SMOTE\n",
    "\n",
    "alloverSMOTE = []\n",
    "overSMOTE = []\n",
    "accuracies=[]\n",
    "#print(os.getcwd())\n",
    "for ii,i in enumerate(train):\n",
    "    randomIndex = []\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    l = data.shape[1] -1\n",
    "    output = data.iloc[:,l];\n",
    "    \n",
    "    finaldata = data.iloc[:,:l]\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    output = le.fit_transform(output)\n",
    "    \n",
    "    tempover = []\n",
    "    \n",
    "    #over = SMOTE()  # SMOTE\n",
    "    #over = sv.polynom_fit_SMOTE() #  polynom_fit_SMOTE\n",
    "    over = sv.SMOTE_IPF() # SMOTE_IPF()\n",
    "    #over = sv.ProWSyn() # ProWSyn()\n",
    "    finaldata = np.array(finaldata)\n",
    "    output = np.array(output)\n",
    "    #X_polynom,y_polynom = over.fit_resample(finaldata,output)\n",
    "    X_polynom,y_polynom = over.sample(finaldata,output)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(X_polynom,y_polynom)\n",
    "    #clf = clf.fit(finaldata,output)\n",
    "    #newDataCount = len(X_smote) - len(data)  # 新生成的 data 數量\n",
    "    \n",
    "   \n",
    "    test_file = pd.read_excel(test[ii],index_col=0) #不然會有多出來的 unnamed column\n",
    "    test_data = pd.DataFrame(test_file);\n",
    "    test_data.Class= test_data.Class.str.replace(\"\\n\", \"\").str.strip()   \n",
    "\n",
    "    \"\"\"\n",
    "    # le = preprocessing.LabelEncoder()\n",
    "    # for i in range(test_data.shape[1]):\n",
    "    #     test_data.iloc[:,i] = le.fit_transform(test_data.iloc[:,i]) \n",
    "    \"\"\"\n",
    "    test_X = test_data.iloc[:,:(test_data.shape[1])-1] # 劃分\n",
    "    test_X.iloc[:,0] = le.fit_transform(test_X.iloc[:,0])\n",
    "    test_y_predicted = clf.predict(test_X)\n",
    "    test_y = test_data.iloc[:,test_data.shape[1]-1] \n",
    "   \n",
    "    test_y = le.fit_transform(test_y)\n",
    "    test_y_predicted = le.fit_transform(test_y_predicted)\n",
    "    \n",
    "    accuracy = roc_auc_score(test_y, test_y_predicted)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "\n",
    "mean = statistics.mean(accuracies)\n",
    "print(mean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Cluster "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-07 12:08:29,519:INFO:polynom_fit_SMOTE: Running sampling via ('polynom_fit_SMOTE', \"{'proportion': 1.0, 'topology': 'star', 'random_state': None}\")\n",
      "3313\n",
      "26\n",
      "2021-04-07 12:08:32,432:INFO:polynom_fit_SMOTE: Running sampling via ('polynom_fit_SMOTE', \"{'proportion': 1.0, 'topology': 'star', 'random_state': None}\")\n",
      "3313\n",
      "26\n",
      "2021-04-07 12:08:35,713:INFO:polynom_fit_SMOTE: Running sampling via ('polynom_fit_SMOTE', \"{'proportion': 1.0, 'topology': 'star', 'random_state': None}\")\n",
      "3314\n",
      "25\n",
      "2021-04-07 12:08:38,908:INFO:polynom_fit_SMOTE: Running sampling via ('polynom_fit_SMOTE', \"{'proportion': 1.0, 'topology': 'star', 'random_state': None}\")\n",
      "3314\n",
      "25\n",
      "2021-04-07 12:08:41,836:INFO:polynom_fit_SMOTE: Running sampling via ('polynom_fit_SMOTE', \"{'proportion': 1.0, 'topology': 'star', 'random_state': None}\")\n",
      "3314\n",
      "26\n",
      "2629\n"
     ]
    }
   ],
   "source": [
    "# Cluster\n",
    "# polynom_fit_SMOTE\n",
    "alloverpolynom = []\n",
    "overpolynom = []\n",
    "\n",
    "centerpolynom = []\n",
    "countfor = 0;\n",
    "for ii,i in enumerate(train):\n",
    "    randomIndex = []\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    originlen = data.shape[0]\n",
    "    output = data.iloc[:,data.shape[1]-1];\n",
    "    classCount = classprocess(output)\n",
    "    finaldata = data.iloc[:,:data.shape[1]-1]\n",
    "\n",
    "    output = le.fit_transform(output)\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    \n",
    "    #output.iloc[:] = le.fit_transform(output.iloc[:])\n",
    "\n",
    "    tempover = []\n",
    "   \n",
    "    finaldata = np.array(finaldata)\n",
    "    output = np.array(output)\n",
    "    over = sv.polynom_fit_SMOTE()\n",
    "    \n",
    "    X_polynom,y_polynom = over.sample(finaldata,output)\n",
    "    newDataCount = len(X_polynom) - len(data)  # 新生成的 data 數量\n",
    "    # 把 X_polynom 跟 y_polynom 和在一起\n",
    "    X_polynom = pd.DataFrame(X_polynom)\n",
    "    y_polynom = pd.DataFrame(y_polynom)\n",
    "    alloverpolynom = pd.concat([X_polynom,y_polynom],axis=1) # SMOTE 完後的數據\n",
    "    \n",
    "    overpolynom.append(alloverpolynom)\n",
    "\n",
    "    for i in range(len(classCount)):\n",
    "        countfor = math.floor(int(classCount[i][1])*0.8); # 要產生多少數據  無條件捨去\n",
    "        #randomIndex.extend([random.randint(len(data),len(X_smote)-1) for _ in range(count)]) \n",
    "        \n",
    "        if(countfor>0):\n",
    "            kmeans = KMeans(n_clusters=1)\n",
    "            dtemp = pd.DataFrame(overpolynom[ii])\n",
    "            X = dtemp.iloc[originlen:,:dtemp.shape[1]-1] # 後來生成的\n",
    "            \n",
    "            kmeans.fit(X)\n",
    "            y_kmeans = kmeans.predict(X)\n",
    "            centers = kmeans.cluster_centers_\n",
    "            \n",
    "            distance = []\n",
    "            X = X.astype('float64')\n",
    "            centers = centers.astype('float64')\n",
    "            tempindata = {}\n",
    "            distancesortemp = []\n",
    "            for i in range(X.shape[0]-1): # 列\n",
    "                \n",
    "                distance = []\n",
    "                temp = 0;\n",
    "                for j in range(X.shape[1]-1):#9 行\n",
    "                    temp = pow((centers[0][j]-X.iloc[i][j]),2)  \n",
    "                    tempindata[i] = temp\n",
    "            \n",
    "            distancesortemp = sorted(tempindata.items(), key=lambda item:item[1])\n",
    "    \n",
    "     \n",
    "            centerpolynom.append(distancesortemp[:countfor])\n",
    "\n",
    "    \n",
    "\n",
    "print(len(centerpolynom[0])) # 第一份資料中的群中心數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centerpolynom 只是 index ，value 是取出值\n",
    "centerpolynomvalue =[]\n",
    "for tr in train:\n",
    "    data = pd.read_excel(tr,index_col=0)\n",
    "    originlen = len(data)\n",
    "    for i in range(len(centerpolynom)):\n",
    "        alltemp = []\n",
    "        for j in range(len(centerpolynom[i])):\n",
    "            indexpolynom = centerpolynom[i][j][0] + originlen\n",
    "            #tempSMOTE = list(overSMOTE[i][indexSMOTE])\n",
    "            alltemp.append(list(overpolynom[i].iloc[indexpolynom]))\n",
    "        centerpolynomvalue.append(alltemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-07 16:47:39,342:INFO:ProWSyn: Running sampling via ('ProWSyn', \"{'proportion': 1.0, 'n_neighbors': 5, 'L': 5, 'theta': 1.0, 'n_jobs': 1, 'random_state': None}\")\n",
      "negative\n",
      "negative\n",
      "3313\n",
      "26\n",
      "origin Counter({0: 3313, 1: 26})\n",
      "Counter({0: 3313, 1: 3313})\n",
      "2021-04-07 16:47:42,478:INFO:ProWSyn: Running sampling via ('ProWSyn', \"{'proportion': 1.0, 'n_neighbors': 5, 'L': 5, 'theta': 1.0, 'n_jobs': 1, 'random_state': None}\")\n",
      "negative\n",
      "negative\n",
      "3313\n",
      "26\n",
      "origin Counter({0: 3313, 1: 26})\n",
      "Counter({0: 3313, 1: 3313})\n",
      "2021-04-07 16:47:45,865:INFO:ProWSyn: Running sampling via ('ProWSyn', \"{'proportion': 1.0, 'n_neighbors': 5, 'L': 5, 'theta': 1.0, 'n_jobs': 1, 'random_state': None}\")\n",
      "negative\n",
      "negative\n",
      "3314\n",
      "25\n",
      "origin Counter({0: 3314, 1: 25})\n",
      "Counter({0: 3314, 1: 3314})\n",
      "2021-04-07 16:47:49,176:INFO:ProWSyn: Running sampling via ('ProWSyn', \"{'proportion': 1.0, 'n_neighbors': 5, 'L': 5, 'theta': 1.0, 'n_jobs': 1, 'random_state': None}\")\n",
      "negative\n",
      "negative\n",
      "3314\n",
      "25\n",
      "origin Counter({0: 3314, 1: 25})\n",
      "Counter({0: 3314, 1: 3314})\n",
      "2021-04-07 16:47:52,289:INFO:ProWSyn: Running sampling via ('ProWSyn', \"{'proportion': 1.0, 'n_neighbors': 5, 'L': 5, 'theta': 1.0, 'n_jobs': 1, 'random_state': None}\")\n",
      "negative\n",
      "negative\n",
      "3314\n",
      "26\n",
      "origin Counter({0: 3314, 1: 26})\n",
      "Counter({0: 3314, 1: 3314})\n",
      "2629\n"
     ]
    }
   ],
   "source": [
    "# Cluster\n",
    "# ProWSyn\n",
    "alloverProWSyn = []\n",
    "overProWSyn = []\n",
    "\n",
    "centerProWSyn = []\n",
    "countfor = 0;\n",
    "for ii,i in enumerate(train):\n",
    "    randomIndex = []\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    originlen = data.shape[0]\n",
    "    output = data.iloc[:,data.shape[1]-1];\n",
    "    classCount = classprocess(output)\n",
    "    finaldata = data.iloc[:,:data.shape[1]-1]\n",
    "\n",
    "    output = le.fit_transform(output)\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    \n",
    "    #output.iloc[:] = le.fit_transform(output.iloc[:])\n",
    "\n",
    "    tempover = []\n",
    "    print(\"origin\",Counter(output))\n",
    "    finaldata = np.array(finaldata)\n",
    "    output = np.array(output)\n",
    "    over = sv.ProWSyn()\n",
    "    \n",
    "    X_ProWSyn,y_ProWSyn = over.sample(finaldata,output)\n",
    "    print(Counter(y_ProWSyn))\n",
    "    newDataCount = len(X_polynom) - len(data)  # 新生成的 data 數量\n",
    "    # 把 X_polynom 跟 y_polynom 和在一起\n",
    "    X_ProWSyn = pd.DataFrame(X_ProWSyn)\n",
    "    y_ProWSyn = pd.DataFrame(y_ProWSyn)\n",
    "    alloverProWSyn = pd.concat([X_ProWSyn,y_ProWSyn],axis=1) # SMOTE 完後的數據\n",
    "    \n",
    "    overProWSyn.append(alloverProWSyn)\n",
    "\n",
    "    for i in range(len(classCount)):\n",
    "        countfor = math.floor(int(classCount[i][1])*0.8); # 要產生多少數據  無條件捨去\n",
    "        #randomIndex.extend([random.randint(len(data),len(X_smote)-1) for _ in range(count)]) \n",
    "        \n",
    "        if(countfor>0):\n",
    "            kmeans = KMeans(n_clusters=1)\n",
    "            dtemp = pd.DataFrame(overProWSyn[ii])\n",
    "            X = dtemp.iloc[originlen:,:dtemp.shape[1]-1] # 後來生成的\n",
    "            \n",
    "            kmeans.fit(X)\n",
    "            y_kmeans = kmeans.predict(X)\n",
    "            centers = kmeans.cluster_centers_\n",
    "            \n",
    "            distance = []\n",
    "            X = X.astype('float64')\n",
    "            centers = centers.astype('float64')\n",
    "            tempindata = {}\n",
    "            distancesortemp = []\n",
    "            for i in range(X.shape[0]-1): # 列\n",
    "                \n",
    "                distance = []\n",
    "                temp = 0;\n",
    "                for j in range(X.shape[1]-1):#9 行\n",
    "                    temp = pow((centers[0][j]-X.iloc[i][j]),2)  \n",
    "                    tempindata[i] = temp\n",
    "            \n",
    "            distancesortemp = sorted(tempindata.items(), key=lambda item:item[1])\n",
    "    \n",
    "     \n",
    "            centerProWSyn.append(distancesortemp[:countfor])\n",
    "\n",
    "    \n",
    "\n",
    "print(len(centerProWSyn[0])) # 第一份資料中的群中心數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centerProWSyn\n",
    "centerProWSynvalue =[]\n",
    "for tr in train:\n",
    "    data = pd.read_excel(tr,index_col=0)\n",
    "    originlen = len(data)\n",
    "    for i in range(len(centerProWSyn)):\n",
    "        alltemp = []\n",
    "        for j in range(len(centerProWSyn[i])):\n",
    "            indexProWSyn = centerProWSyn[i][j][0] + originlen\n",
    "            #tempSMOTE = list(overSMOTE[i][indexSMOTE])\n",
    "            alltemp.append(list(overProWSyn[i].iloc[indexProWSyn]))\n",
    "        centerProWSynvalue.append(alltemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3286"
      ]
     },
     "metadata": {},
     "execution_count": 306
    }
   ],
   "source": [
    "# 合併 小類 center polynom + ProWSyn \n",
    "allCenterHalf = []\n",
    "temp = []\n",
    "for i in range(len(centerpolynom)):\n",
    "    temp = centerpolynomvalue[i] + centerProWSynvalue[i]\n",
    "    temp = pd.DataFrame(temp,columns=data.columns)\n",
    "    allCenterHalf.append(temp)\n",
    "\n",
    "len(allCenterHalf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-07 16:48:26,977:INFO:SMOTE_IPF: Running sampling via ('SMOTE_IPF', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_folds': 9, 'k': 3, 'p': 0.01, 'voting': 'majority', 'n_jobs': 1, 'classifier': DecisionTreeClassifier(random_state=2), 'random_state': None}\")\n",
      "2021-04-07 16:48:26,978:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from '/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/numpy/random/__init__.py'>}\")\n",
      "negative\n",
      "negative\n",
      "3313\n",
      "26\n",
      "2021-04-07 16:48:27,317:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:27,639:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:27,964:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:30,870:INFO:SMOTE_IPF: Running sampling via ('SMOTE_IPF', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_folds': 9, 'k': 3, 'p': 0.01, 'voting': 'majority', 'n_jobs': 1, 'classifier': DecisionTreeClassifier(random_state=2), 'random_state': None}\")\n",
      "2021-04-07 16:48:30,871:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from '/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/numpy/random/__init__.py'>}\")\n",
      "negative\n",
      "negative\n",
      "3313\n",
      "26\n",
      "2021-04-07 16:48:31,272:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:31,658:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:32,043:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:34,973:INFO:SMOTE_IPF: Running sampling via ('SMOTE_IPF', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_folds': 9, 'k': 3, 'p': 0.01, 'voting': 'majority', 'n_jobs': 1, 'classifier': DecisionTreeClassifier(random_state=2), 'random_state': None}\")\n",
      "2021-04-07 16:48:34,974:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from '/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/numpy/random/__init__.py'>}\")\n",
      "negative\n",
      "negative\n",
      "3314\n",
      "25\n",
      "2021-04-07 16:48:35,316:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:35,645:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:35,973:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:38,848:INFO:SMOTE_IPF: Running sampling via ('SMOTE_IPF', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_folds': 9, 'k': 3, 'p': 0.01, 'voting': 'majority', 'n_jobs': 1, 'classifier': DecisionTreeClassifier(random_state=2), 'random_state': None}\")\n",
      "2021-04-07 16:48:38,849:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from '/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/numpy/random/__init__.py'>}\")\n",
      "negative\n",
      "negative\n",
      "3314\n",
      "25\n",
      "2021-04-07 16:48:39,245:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:39,623:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:40,001:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:42,856:INFO:SMOTE_IPF: Running sampling via ('SMOTE_IPF', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_folds': 9, 'k': 3, 'p': 0.01, 'voting': 'majority', 'n_jobs': 1, 'classifier': DecisionTreeClassifier(random_state=2), 'random_state': None}\")\n",
      "2021-04-07 16:48:42,857:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': <module 'numpy.random' from '/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/numpy/random/__init__.py'>}\")\n",
      "negative\n",
      "negative\n",
      "3314\n",
      "26\n",
      "2021-04-07 16:48:43,242:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:43,625:INFO:SMOTE_IPF: Removing 0 elements\n",
      "2021-04-07 16:48:43,998:INFO:SMOTE_IPF: Removing 0 elements\n",
      "657\n"
     ]
    }
   ],
   "source": [
    "# Cluster\n",
    "# SMOTE-IPF\n",
    "alloverSMOTEIPF = []\n",
    "overSMOTEIPF = []\n",
    "\n",
    "centerSMOTEIPF = []\n",
    "countfor = 0;\n",
    "for ii,i in enumerate(train):\n",
    "    randomIndex = []\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    data = pd.read_excel(i,index_col=0)\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    originlen = data.shape[0]\n",
    "    output = data.iloc[:,data.shape[1]-1];\n",
    "    classCount = classprocess(output)\n",
    "    finaldata = data.iloc[:,:data.shape[1]-1]\n",
    "\n",
    "    output = le.fit_transform(output)\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    \n",
    "    #output.iloc[:] = le.fit_transform(output.iloc[:])\n",
    "\n",
    "    tempover = []\n",
    "   \n",
    "    finaldata = np.array(finaldata)\n",
    "    output = np.array(output)\n",
    "  #output.iloc[:] = le.fit_transform(output.iloc[:])\n",
    "\n",
    "    tempover = []\n",
    "   \n",
    "    finaldata = np.array(finaldata)\n",
    "    output = np.array(output)\n",
    "    over = sv.SMOTE_IPF()\n",
    "    \n",
    "    X_SMOTEIPF,y_SMOTEIPF = over.sample(finaldata,output)\n",
    "    newDataCount = len(X_polynom) - len(data)  # 新生成的 data 數量\n",
    "    # 把 X_polynom 跟 y_polynom 和在一起\n",
    "    X_SMOTEIPF = pd.DataFrame(X_SMOTEIPF)\n",
    "    y_SMOTEIPF = pd.DataFrame(y_SMOTEIPF)\n",
    "    alloverSMOTEIPF = pd.concat([X_SMOTEIPF,y_SMOTEIPF],axis=1) # SMOTE 完後的數據\n",
    "    \n",
    "    overSMOTEIPF.append(alloverSMOTEIPF)\n",
    "\n",
    "    for i in range(len(classCount)):\n",
    "        countfor = math.floor(int(classCount[i][1])*0.2); # 要產生多少數據  無條件捨去\n",
    "        #randomIndex.extend([random.randint(len(data),len(X_smote)-1) for _ in range(count)]) \n",
    "        \n",
    "        if(countfor>0):\n",
    "            kmeans = KMeans(n_clusters=1)\n",
    "            dtemp = pd.DataFrame(overSMOTEIPF[ii])\n",
    "            X = dtemp.iloc[originlen:,:dtemp.shape[1]-1] # 後來生成的\n",
    "            \n",
    "            kmeans.fit(X)\n",
    "            y_kmeans = kmeans.predict(X)\n",
    "            centers = kmeans.cluster_centers_\n",
    "            \n",
    "            distance = []\n",
    "            X = X.astype('float64')\n",
    "            centers = centers.astype('float64')\n",
    "            tempindata = {}\n",
    "            distancesortemp = []\n",
    "            for i in range(X.shape[0]-1): # 列\n",
    "                \n",
    "                distance = []\n",
    "                temp = 0;\n",
    "                for j in range(X.shape[1]-1):#9 行\n",
    "                    temp = pow((centers[0][j]-X.iloc[i][j]),2)  \n",
    "                    tempindata[i] = temp\n",
    "            \n",
    "            distancesortemp = sorted(tempindata.items(), key=lambda item:item[1])\n",
    "    \n",
    "     \n",
    "            centerSMOTEIPF.append(distancesortemp[:countfor])\n",
    "\n",
    "    \n",
    "\n",
    "print(len(centerSMOTEIPF[0])) # 第一份資料中的群中心數量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centerSMOTEIPF 只是 index ，value 是取出值\n",
    "centerSMOTEIPFvalue =[]\n",
    "for tr in train:\n",
    "    data = pd.read_excel(tr,index_col=0)\n",
    "    originlen = len(data)\n",
    "    for i in range(len(centerSMOTEIPF)):\n",
    "        alltemp = []\n",
    "        for j in range(len(centerSMOTEIPF[i])):\n",
    "            indexSMOTEIPF = centerSMOTEIPF[i][j][0] + originlen\n",
    "            #tempSMOTE = list(overSMOTE[i][indexSMOTE])\n",
    "            alltemp.append(list(overSMOTEIPF[i].iloc[indexSMOTEIPF]))\n",
    "        centerSMOTEIPFvalue.append(alltemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5258"
      ]
     },
     "metadata": {},
     "execution_count": 325
    }
   ],
   "source": [
    "# 合併 小類 center polynom-fit-SMOTE + SMOTE-IPF\n",
    "\n",
    "allCenterHalf = []\n",
    "temp = []\n",
    "for i in range(len(centerpolynom)):\n",
    "    temp = centerpolynomvalue[i] + centerSMOTEIPFvalue[i]\n",
    "    temp = pd.DataFrame(temp,columns=data.columns)\n",
    "    allCenterHalf.append(temp)\n",
    "\n",
    "len(allCenterHalf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3286"
      ]
     },
     "metadata": {},
     "execution_count": 348
    }
   ],
   "source": [
    "\n",
    "# 合併 小類 center ProWSyn  + SMOTE-IPF\n",
    "\n",
    "allCenterHalf = []\n",
    "temp = []\n",
    "for i in range(len(centerProWSyn )):\n",
    "    temp = centerProWSynvalue[i] + centerSMOTEIPFvalue[i]\n",
    "    temp = pd.DataFrame(temp,columns=data.columns)\n",
    "    allCenterHalf.append(temp)\n",
    "\n",
    "len(allCenterHalf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Sex    Length  Diameter    Height  Whole_weight  Shucked_weight  \\\n",
       "0     0.000000  0.579899  0.466552  0.176643      1.136011        0.354768   \n",
       "1     1.685518  0.553648  0.441290  0.167359      1.024590        0.341796   \n",
       "2     0.863842  0.621127  0.470329  0.171362      1.259383        0.447606   \n",
       "3     2.000000  0.691683  0.529634  0.160268      1.686329        0.613607   \n",
       "4     2.000000  0.699639  0.534781  0.160064      1.723809        0.629356   \n",
       "...        ...       ...       ...       ...           ...             ...   \n",
       "3281  2.000000  0.511925  0.387155  0.159770      0.718194        0.274801   \n",
       "3282  2.000000  0.511585  0.386951  0.159634      0.716533        0.274536   \n",
       "3283  2.000000  0.511399  0.386840  0.159560      0.715630        0.274392   \n",
       "3284  2.000000  0.511334  0.386801  0.159534      0.715312        0.274341   \n",
       "3285  2.000000  0.503371  0.383558  0.155187      0.670692        0.269844   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Class  \n",
       "0           0.263476      0.359758    1.0  \n",
       "1           0.263512      0.340724    1.0  \n",
       "2           0.263378      0.366010    1.0  \n",
       "3           0.263661      0.528463    1.0  \n",
       "4           0.263272      0.539665    1.0  \n",
       "...              ...           ...    ...  \n",
       "3281        0.138408      0.248390    1.0  \n",
       "3282        0.138354      0.247437    1.0  \n",
       "3283        0.138324      0.246919    1.0  \n",
       "3284        0.138314      0.246736    1.0  \n",
       "3285        0.138279      0.217060    1.0  \n",
       "\n",
       "[3286 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Length</th>\n      <th>Diameter</th>\n      <th>Height</th>\n      <th>Whole_weight</th>\n      <th>Shucked_weight</th>\n      <th>Viscera_weight</th>\n      <th>Shell_weight</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.579899</td>\n      <td>0.466552</td>\n      <td>0.176643</td>\n      <td>1.136011</td>\n      <td>0.354768</td>\n      <td>0.263476</td>\n      <td>0.359758</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.685518</td>\n      <td>0.553648</td>\n      <td>0.441290</td>\n      <td>0.167359</td>\n      <td>1.024590</td>\n      <td>0.341796</td>\n      <td>0.263512</td>\n      <td>0.340724</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.863842</td>\n      <td>0.621127</td>\n      <td>0.470329</td>\n      <td>0.171362</td>\n      <td>1.259383</td>\n      <td>0.447606</td>\n      <td>0.263378</td>\n      <td>0.366010</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.000000</td>\n      <td>0.691683</td>\n      <td>0.529634</td>\n      <td>0.160268</td>\n      <td>1.686329</td>\n      <td>0.613607</td>\n      <td>0.263661</td>\n      <td>0.528463</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.000000</td>\n      <td>0.699639</td>\n      <td>0.534781</td>\n      <td>0.160064</td>\n      <td>1.723809</td>\n      <td>0.629356</td>\n      <td>0.263272</td>\n      <td>0.539665</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3281</th>\n      <td>2.000000</td>\n      <td>0.511925</td>\n      <td>0.387155</td>\n      <td>0.159770</td>\n      <td>0.718194</td>\n      <td>0.274801</td>\n      <td>0.138408</td>\n      <td>0.248390</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3282</th>\n      <td>2.000000</td>\n      <td>0.511585</td>\n      <td>0.386951</td>\n      <td>0.159634</td>\n      <td>0.716533</td>\n      <td>0.274536</td>\n      <td>0.138354</td>\n      <td>0.247437</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3283</th>\n      <td>2.000000</td>\n      <td>0.511399</td>\n      <td>0.386840</td>\n      <td>0.159560</td>\n      <td>0.715630</td>\n      <td>0.274392</td>\n      <td>0.138324</td>\n      <td>0.246919</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3284</th>\n      <td>2.000000</td>\n      <td>0.511334</td>\n      <td>0.386801</td>\n      <td>0.159534</td>\n      <td>0.715312</td>\n      <td>0.274341</td>\n      <td>0.138314</td>\n      <td>0.246736</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3285</th>\n      <td>2.000000</td>\n      <td>0.503371</td>\n      <td>0.383558</td>\n      <td>0.155187</td>\n      <td>0.670692</td>\n      <td>0.269844</td>\n      <td>0.138279</td>\n      <td>0.217060</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3286 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 330
    }
   ],
   "source": [
    "allCenterHalf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({0.0: 3313, 1.0: 3312})\n",
      "Counter({0.0: 3313, 1.0: 3312})\n",
      "Counter({0.0: 3314, 1.0: 3313})\n",
      "Counter({0.0: 3314, 1.0: 3313})\n",
      "Counter({0.0: 3315, 1.0: 3312})\n",
      "0.5450087140501206\n"
     ]
    }
   ],
   "source": [
    "# # 跟原始資料合併\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "mergeRandom = []\n",
    "for index,element in enumerate(train):\n",
    "    data = pd.read_excel(element,index_col =0);\n",
    "    data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "    l = data.shape[1]-1\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    data.iloc[:,l] = le.fit_transform(data.iloc[:,l])\n",
    "    data.iloc[:,0] = le.fit_transform(data.iloc[:,0])\n",
    "    \n",
    "    \"\"\"\n",
    "    output = data.iloc[:,l];\n",
    "    finaldata = data.iloc[:,:l]\n",
    "    finaldata.iloc[:,0] = le.fit_transform(finaldata.iloc[:,0])\n",
    "    \"\"\"\n",
    "    #data.iloc[:,0] = le.fit_transform(data.iloc[:,0])\n",
    "    #classCount = classprocess(output)\n",
    "    #data = data.T\n",
    "\n",
    "    #allCenterminHalf[index] = pd.DataFrame(allCenterminHalf[index],columns=data.columns)\n",
    "    mergeRandom = pd.concat([data,allCenterHalf[index]],axis=0)\n",
    "    \n",
    "    finaldata = mergeRandom.iloc[:,:l]\n",
    "    output = mergeRandom.iloc[:,l]\n",
    "    print(Counter(output))\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(finaldata, output)\n",
    "\n",
    "\n",
    "    test_file = pd.read_excel(test[index],index_col=0) #不然會有多出來的 unnamed column\n",
    "    test_data = pd.DataFrame(test_file);\n",
    "    #test_data.Class= test_data.Class.str.replace(\"\\n\", \"\").str.strip()   \n",
    "\n",
    "    test_X = test_data.iloc[:,:(test_data.shape[1])-1] \n",
    "   \n",
    "    test_X.iloc[:,0] = le.fit_transform(test_X.iloc[:,0])\n",
    "    \n",
    "    \n",
    "    #output.iloc[:] = le.fit_transform(output.iloc[:])\n",
    "\n",
    "    test_y_predicted = clf.predict(test_X)\n",
    "\n",
    "    test_y = test_data.iloc[:,test_data.shape[1]-1] \n",
    "\n",
    "    test_y = le.fit_transform(test_y)\n",
    "    test_y_predicted = le.fit_transform(test_y_predicted)\n",
    "\n",
    "    accuracy = roc_auc_score(test_y, test_y_predicted)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "\n",
    "mean = statistics.mean(accuracies)\n",
    "print(mean)\n",
    "\n",
    "#len(mergeRandom[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}