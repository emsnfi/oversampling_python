{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os;\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Ë®àÁÆóÊØèÂÄãÈªûÈÑ∞ËøëÁöÑ k ÁöÑÈªû Áî® k ÂÄãÈªûÊâÄÂú®ÁöÑÂÄãÊï∏ Âà§Âà•Ë©≤Èªû(ÈùûÈÑ∞ËøëÁöÑÈªû) Â±¨Êñº‰ªÄÈ∫ºÈ°ûÂûãÁöÑÈªû (safe noisy border)\n",
    "# ÂÖàÁî®‰∏ÄÂÄã‰∫åÂàÜÈ°ûÁöÑË≥áÊñô\n",
    "\n",
    "# Ê≠§ function Áî®‰æÜÂà§Âà•ÊòØÂê¶ÁÇ∫ safe danger(border) or noisy\n",
    "\n",
    "def _in_danger_noise(\n",
    "        self, nn_estimator, samples, target_class, y, kind=\"danger\"\n",
    "    ):\n",
    "    '''\n",
    "        Estimate if a set of sample are in danger or noise.\n",
    "        Used by BorderlineSMOTE and SVMSMOTE.\n",
    "        Parameters\n",
    "        ----------\n",
    "        nn_estimator : estimator object\n",
    "            An estimator that inherits from\n",
    "            :class:`~sklearn.neighbors.base.KNeighborsMixin` use to determine if\n",
    "            a sample is in danger/noise.\n",
    "        samples : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            The samples to check if either they are in danger or not.\n",
    "        target_class : int or str\n",
    "            The target corresponding class being over-sampled.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The true label in order to check the neighbour labels.\n",
    "        kind : {'danger', 'noise'}, default='danger'\n",
    "            The type of classification to use. Can be either:\n",
    "            - If 'danger', check if samples are in danger,\n",
    "            - If 'noise', check if samples are noise.\n",
    "        Returns\n",
    "        -------\n",
    "        output : ndarray of shape (n_samples,)\n",
    "            A boolean array where True refer to samples in danger or noise.\n",
    "  \n",
    "\n",
    "        x = nn_estimator.kneighbors(samples, return_distance=False)[:, 1:]\n",
    "        nn_label = (y[x] != target_class).astype(int)\n",
    "        n_maj = np.sum(nn_label, axis=1)\n",
    "\n",
    "        if kind == \"danger\": \n",
    "            # Samples are in danger / border for m/2 <= m' < m\n",
    "            return np.bitwise_and(\n",
    "                n_maj >= (nn_estimator.n_neighbors - 1) / 2,\n",
    "                n_maj < nn_estimator.n_neighbors - 1,\n",
    "            )\n",
    "        elif kind == \"noise\":\n",
    "            # Samples are noise for m = m'\n",
    "            return n_maj == nn_estimator.n_neighbors - 1\n",
    "        else: # safe sample\n",
    "            raise NotImplementedError\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "class Smote:\n",
    "    def __init__(self,samples,N=10,k=5):\n",
    "        self.n_samples,self.n_attrs=samples.shape\n",
    "        self.N=N\n",
    "        self.k=k\n",
    "        self.samples=samples\n",
    "        self.newindex=0\n",
    "       # self.synthetic=np.zeros((self.n_samples*N,self.n_attrs))\n",
    "\n",
    "    def over_sampling(self):\n",
    "        N=int(self.N/100)\n",
    "        self.synthetic = np.zeros((self.n_samples * N, self.n_attrs))\n",
    "        neighbors=NearestNeighbors(n_neighbors=self.k).fit(self.samples)\n",
    "        print 'neighbors',neighbors\n",
    "        for i in range(len(self.samples)):\n",
    "            nnarray=neighbors.kneighbors(self.samples[i].reshape(1,-1),return_distance=False)[0]\n",
    "            #print nnarray\n",
    "            self._populate(N,i,nnarray)\n",
    "        return self.synthetic\n",
    "\n",
    "\n",
    "    # for each minority class samples,choose N of the k nearest neighbors and generate N synthetic samples.\n",
    "    def _populate(self,N,i,nnarray):\n",
    "        for j in range(N):\n",
    "            nn=random.randint(0,self.k-1)\n",
    "            dif=self.samples[nnarray[nn]]-self.samples[i]\n",
    "            gap=random.random()\n",
    "            self.synthetic[self.newindex]=self.samples[i]+gap*dif\n",
    "            self.newindex+=1\n",
    "a=np.array([[1,2,3],[4,5,6],[2,3,1],[2,1,2],[2,3,4],[2,3,4]])\n",
    "s=Smote(a,N=100)\n",
    "print s.over_sampling()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "output = np.array(data.iloc[:,6)\n",
    "finaldata = np.array(data.iloc[:,:6)\n",
    "\n",
    "output = np.array(data.iloc[:,data.shape[1]-1])\n",
    "finaldata = np.array(data.iloc[:,:data.shape[1]-1]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape[1] # Ë°åÊï∏    data.shape[0] ÂàóÊï∏\n",
    "import os;\n",
    "import numpy as np;\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier;\n",
    "from sklearn.cluster import MiniBatchKMeans;\n",
    "import collections \n",
    "\n",
    "os.chdir(\"/Users/emily/Desktop/Research/oversampling_python/data\");\n",
    "print(os.getcwd());\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_excel(\"pima.xlsx\")\n",
    "data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "data = data.iloc[:,1:]\n",
    "data.shape[1]\n",
    "l = data.shape[1]-1\n",
    "\n",
    "output = np.array(data.iloc[:,l]);\n",
    "finaldata = np.array(data.iloc[:,:l])\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂàÜ‰Ωà\n",
    "counter = Counter(output)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(output) * 100\n",
    "\tprint(\"class\",k,\" percentage \",per,\"%\")\n",
    "   \n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê∏¨Ë©¶ Ëá™Âª∫\n",
    "\"\"\"\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X, y = make_classification(n_classes=3, class_sep=2,\n",
    "                           weights=[0.3,0.5,0.2], n_informative=3, n_redundant=0, flip_y=0,\n",
    "                           n_features=3, n_clusters_per_class=1, n_samples=100, random_state=9)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÊâæÂá∫ knn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "def knn(n_nu,sample):\n",
    "     # n_nu Ëá™Â∑±Ë®≠ÂÆöÂ§öÂ∞ëÈÑ∞ËøëÂÄãÈªû\n",
    "     # input sample Ê≤íÊúâÂåÖÂê´ class label\n",
    "        nnarray = []\n",
    "        neighbors=NearestNeighbors(n_neighbors=n_nu+1).fit(sample)\n",
    "        for i in range(len(sample)):\n",
    "            temp = neighbors.kneighbors(sample[i].reshape(1,-1),return_distance=False)[0]\n",
    "            temp = np.delete(temp,0)\n",
    "            # Êúâ array Â≠òÊîæ ÂêÑÂÄãÈªûÁöÑÈÑ∞ËøëÈªû \n",
    "            nnarray.append(temp)\n",
    "        return nnarray # ÂõûÂÇ≥Áõ∏ËøëÁöÑÈªû ÂàÜÂà•ÊòØÂú®Á¨¨ÂπæÂÄã \n",
    "karray = knn(5,finaldata)\n",
    "karray[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÊâæÂá∫Â§ßÈ°û\n",
    "import collections \n",
    "from collections import Counter\n",
    "counter = Counter(output);\n",
    "\n",
    "print(counter)\n",
    "def find_maj(sample_class):\n",
    "    counter = Counter(sample_class);\n",
    "    print(counter)\n",
    "    return  list(dict(counter.most_common(1)).keys())\n",
    "\n",
    "find_maj(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# finaldata ÊòØ‰ΩøÁî® bupa.xlsx ÁöÑ\n",
    "# ËÆäÊàê class\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "class RCSMOTE(self,n_nu,sample):\n",
    "    def __init__(self):\n",
    "            \n",
    "    def knn(self,n_nu,sample):\n",
    "        self.n_nu = n_nu;\n",
    "        self.sample = sample;\n",
    "        neighbors=NearestNeighbors(n_neighbors=n_nu+1).fit(sample)\n",
    "\n",
    "        nnarray=neighbors.kneighbors(sample[100].reshape(1,-1),return_distance=False)[0]\n",
    "        return nnarray # ÂõûÂÇ≥Áõ∏ËøëÁöÑÈªû ÂàÜÂà•ÊòØÂú®Á¨¨ÂπæÂÄã \n",
    "te = RCSMOTE();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(finaldata[:, 0], finaldata[:, 1], c=output)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âà§Êñ∑Ë©≤ÈªûÁÇ∫‰ªÄÈ∫ºÈ°ûÂûãÁöÑÈªû Â¶ÇÊûúÂÖ∂\n",
    "# Ê≠§ index ÊòØ 0 ÈñãÂßã ÊâÄ‰ª•Â∞çÁÖßÂà∞ excel ÁöÑË¶Å\n",
    "# inminority ÊòØÂê¶ÊòØË¶ÅÊ±ÇÂú®Â∞èÈ°û‰∏≠ÁöÑ Â¶ÇÊûúÊòØÂâáÊîæ true\n",
    "def check_point_type(n_nu,sample,sample_class,data,inminority):\n",
    "    # ‰ΩøÁî® find_maj(find_maj(sample_class)\n",
    "    # ‰ΩøÁî® knn ÊâæÂà∞ÈÑ∞ËøëÁöÑÂπæÂÄãÈªû \n",
    "    point_type = [] # ÊîæÂÄãÈªûÊòØÂ±¨Êñº‰ªÄÈ∫ºÈ°ûÂûãÁöÑ border safe noisy\n",
    "    n = 0\n",
    "    b = 0\n",
    "    s = 0\n",
    "    maj = find_maj(sample_class) # Â§ßÈ°û\n",
    "    point = knn(n_nu,sample) # ÂõûÂÇ≥ÊâÄÊúâÈªûÈÑ∞Ëøë n_nu ÂÄãÈªû\n",
    "    maj = \"\".join(maj) # maj ÂéüÊú¨ÊòØ list ËΩâÊàê str\n",
    "    for index,i in enumerate(point):\n",
    "        maj_nu =0;\n",
    "        if(data.iloc[index,data.shape[1]-1] == maj and inminority == True): # Â¶ÇÊûúË©≤ÈªûÊú¨Ë∫´ÊòØÂ§ßÈ°ûÂâá‰∏çË®àÁÆó\n",
    "            continue; # Â¶ÇÊûú‰ΩøÁî®Ê≠§ ÂâáÊúÉË∑üË´ñÊñáÁöÑ data ‰∏ÄÊ®£\n",
    "        for j in point[index]: # ÊØèÂÄãÈªûÈÑ∞ËøëÂÄãÈªûÁöÑ loop ‰æãÂ¶ÇÁ¨¨‰∏ÄÂÄãÈªûÊòØ [1,2,3,4,5] Ââá loop Ë£°Èù¢ÁöÑÊï∏ÂÄº\n",
    "            if(data.iloc[j,data.shape[1]-1] == maj ): \n",
    "                maj_nu = maj_nu + 1 # Ë®àÁÆóÈÑ∞ËøëÈªûÁÇ∫Â§ßÈ°ûÁöÑÊúâÂ§öÂ∞ëÂÄã\n",
    "        if(maj_nu == n_nu ):\n",
    "            point_type.append(\"noisy\");\n",
    "            n = n+1\n",
    "        elif(n_nu/2 < maj_nu and maj_nu < n_nu ):\n",
    "            point_type.append(\"border\");\n",
    "            b = b+1\n",
    "        else:\n",
    "            point_type.append(\"safe\");\n",
    "            s = s+1\n",
    "    print(\"noisy\",n,\"\\nborder\",b,\"\\nsafe\",s,\"\\nall\",n+b+s)\n",
    "    return point_type;\n",
    "point_type = check_point_type(3,finaldata,output,data,True) # Ë´ñÊñá‰ΩøÁî® knn ÁÇ∫ 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ë≥áÊñôÈõÜËÆäÁÇ∫Â∞èÈ°ûÁöÑ border Ë∑ü safe ‰ª•Âèä Â§ßÈ°û ÂéªÈô§ Â∞èÈ°û‰∏îÁÇ∫ noisy ÁöÑ\n",
    "\"\"\"\n",
    "find the maximum value that existed for that attribute among\n",
    "the minority samples of the ùêµùëÜ set, and also, find the minimum value that existed for\n",
    "the given attribute among the majority samples set\n",
    "\"\"\"\n",
    "# ÂÖàÊòØÂ∞èÈ°ûÂéªÊéâ noisy ÂÜç‰æÜÊòØ Â§ßÈ°û \n",
    "def split_BS_Majdata(point_type,sample,sample_class):\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # Â§ßÈ°û\n",
    "    maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(sample[i])\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(sample[i])\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "    print(BS_sample)\n",
    "    return return_sample\n",
    "\n",
    "print(split_BS_Majdata(point_type,finaldata,output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_split_BS_Majdata(point_type,sample,sample_class): # maj ‰ª•Âèä BS set Âú®ÂéüÊú¨ data ÁöÑ index\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # Â§ßÈ°û\n",
    "    maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(i)\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(i)\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "    \n",
    "    return return_sample\n",
    "\n",
    "index_split_BS_Majdata(point_type,finaldata,output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The obtained ranges for\n",
    "all features (attributes) are used to control the location of the new synthetic samples in\n",
    "data space.\n",
    "\n",
    "The set of these ranges is denoted by ùëÖùëéùëõùëîùëí =\n",
    "(ùëüùëéùëõùëîùëí1 ùëüùëéùëõùëîùëí2 ùëüùëéùëõùëîùëí3 ‚Ä¶ ùëüùëéùëõùëîùëíùëõùëéùë°ùë°ùëü) array where ùëõùëéùë°ùë°ùëü is the number of\n",
    "attributes in the dataset\n",
    "\n",
    "Â¶Ç‰ΩïÁî¢Áîü Range array\n",
    "1. we find the maximum value that existed for that attribute among\n",
    "the minority samples of the ùêµùëÜ set  ùëÉ _ùëöùëéùë• = (ùëùùëöùëéùë•1 ùëùùëöùëéùë•2\n",
    "‚Ä¶ùëùùëöùëéùë•ùëõùëéùë°ùë°ùëü) array\n",
    "\n",
    "2. find the minimum value that existed for\n",
    "the given attribute among the majority samples set  ùëÅ _ùëöùëñùëõ = (ùëõùëöùëñùëõ1 ùëõùëöùëñùëõ2 ‚Ä¶ùëõùëöùëñùëõùëõùëéùë°ùë°ùëü)array\n",
    "\n",
    "3. Then, the desired ùëÖùëéùëõùëîùëí vector is obtained as the average of ùëÅ_ùëöùëñùëõ and\n",
    "ùëÉ _ùëöùëéùë• arrays\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# dataframe[0] Ë°åÊï∏  dataframe[1] ÂàóÊï∏\n",
    "# Ë©≤Â±¨ÊÄß‰∏≠ Âú® bs set ÁöÑÊúÄÂ§ßÂÄº ‰ª•Âèä Â§ßÈ°û‰∏≠ÁöÑÊúÄÂ∞èÂÄº\n",
    "# range ÁÇ∫ÂÖ©ÂÄãÁõ∏Âä†Èô§‰ª• 2\n",
    "# index_split_BS_Majdata ÂõûÂÇ≥ [0] BS set [1] ÂõûÂÇ≥ Maj set\n",
    "def range_value(n_nu,sample,sample_class,data):\n",
    "    point_type = check_point_type(n_nu,sample,sample_class,data,False)\n",
    "    index = index_split_BS_Majdata(point_type,sample,sample_class)\n",
    "    BS_max = []\n",
    "    Maj_min = []\n",
    "    all_value = []\n",
    "    for i in range(len(sample[0])): # loop Â±¨ÊÄß\n",
    "        for j in range(2): # loop data\n",
    "            if(j==0): # BS set ÁöÑ index\n",
    "                BS_index = index[j]\n",
    "                max_value = np.max(sample[BS_index][i]);\n",
    "                BS_max.append(max_value)\n",
    "            else:\n",
    "                Maj_index = index[j]\n",
    "                min_value = np.min(sample[Maj_index][i]);\n",
    "                Maj_min.append(min_value)\n",
    "    # temp = np.array([BS_max,Maj_min]) \n",
    "    range_value = [(BS_max[i] - Maj_min[i])/2 for i in range(len(BS_max))]\n",
    "    all_value = np.array([BS_max,Maj_min,range_value])\n",
    "    return all_value\n",
    "range_value(3,finaldata,output,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bùëõùë¢ùëö: Number of samples in ùêµùëúùëüùëëùëíùëü Â±¨Êñº border ÁöÑË≥áÊñôÊï∏\n",
    "# compute its(border sample) k nearest neighbors in BS, and save them in BSnn Â≠òÊîæ \n",
    "# compute its(border sample) k nearest neighbors in Maj set, and save them in Majnn\n",
    "def getBSnn_Majnn(n_nu,sample,sample_class,data):     \n",
    "    point_type = check_point_type(n_nu,sample,sample_class,data,False) # ÂæóÁü•ÊâÄÊúâ sample ‰∏≠Â±¨Êñº border ÁöÑ  \n",
    "    index = index_split_BS_Majdata(point_type,sample,sample_class) \n",
    "    k = knn(n_nu,sample)\n",
    "    BSnn = []\n",
    "    Majnn = []\n",
    "    # Áî® border sample ÁöÑ index \n",
    "    for i,element in enumerate(point_type):\n",
    "        if(element == \"border\"):\n",
    "            for j in range(2):\n",
    "                for w in index[j]:\n",
    "                    if(j == 0 and i == w ):\n",
    "                        BSnn.append(k[w])\n",
    "                    elif(j==1 and i == w):\n",
    "                        Majnn.append(k[w])\n",
    "        \n",
    "    temp = np.array([BSnn,Majnn]);\n",
    "    print(len(temp[0]+temp[1]))\n",
    "    return temp\n",
    "    \n",
    "len(getBSnn_Majnn(3,finaldata,output,data)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "s1col = random.randint(0,1-1)\n",
    "print(s1col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÁîüÊàêË≥áÊñô\n",
    "\n",
    "\n",
    "def Populate(r,BSnn,Majnn,Range,P_max,sample):\n",
    "    # r ‰ª£Ë°®Ë¶ÅÁî¢ÁîüÁöÑË≥áÊñôÁöÑÊï∏Èáè Ë´ñÊñáÂÆöÁæ©Ë©≤Êï∏ÈáèÁÇ∫Â¢ûÂä†Â∞èÈ°ûËá≥Ë∑üÂ§ßÈ°ûÁõ∏ÂêåÁöÑÊï∏Èáè ÈÅîÊàê 50% (Â§ßÈ°ûÊ∏õÂ∞èÈ°ûÁöÑÊï∏Èáè)\n",
    "    Bl = len(BSnn)-1\n",
    "    nn_nu = len(BSnn[0])-1\n",
    "    Synthetic = []\n",
    "    while(r > 0):\n",
    "\n",
    "        s1row = random.randint(0,Bl)\n",
    "        s1col = random.randint(0,nn_nu)\n",
    "        s1 = BSnn[s1row][s1col]\n",
    "        s2row = random.randint(0,Bl)\n",
    "        s2col = random.randint(0,nn_nu)\n",
    "        s2 = Majnn[s2row][s2col]\n",
    "        min_attr = []\n",
    "        for i in range(len(sample[0])):\n",
    "        \n",
    "            if(sample[s1][i] < sample[s2][i]):\n",
    "                min_attr.append(sample[s1][i])\n",
    "            else:\n",
    "                min_attr.append(sample[s2][i])\n",
    "        diff = [(P_max[i] - min_attr[i]) for i in range(len(P_max))]\n",
    "        #print(\"diff\",diff)\n",
    "        gap = random.uniform(0,0.5)\n",
    "        var = [(diff[i] * gap ) for i in range(len(diff))]\n",
    "        temp = []\n",
    "        for i in range(len(sample[0])):\n",
    "            if(min_attr[i]+var[i] <= Range[i]):\n",
    "                temp.append(min_attr[i]+var[i])\n",
    "            else:\n",
    "                temp.append(P_max[i]-var[i])\n",
    "        temp.append(\"tested_positive\")\n",
    "        Synthetic.append(temp)   \n",
    "        r = r-1\n",
    "    return Synthetic\n",
    "    \n",
    "needToGenerate = 232\n",
    "BSnn = getBSnn_Majnn(3,finaldata,output,data)[0]\n",
    "Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "Range = range_value(3,finaldata,output,data)\n",
    "P_max = range_value(3,finaldata,output,data)[0]\n",
    "Range = range_value(3,finaldata,output,data)[2]\n",
    "Populate(needToGenerate,BSnn,Majnn,Range,P_max,finaldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   0                1                2                3    \\\n",
       "Preg                14                4               15                3   \n",
       "Plas               175              146              136              107   \n",
       "Pres                62               78               70               62   \n",
       "Skin                30                0               32               13   \n",
       "Insu                 0                0              110               48   \n",
       "Mass              33.6             38.5             37.1             22.9   \n",
       "Pedi             0.212             0.52            0.153            0.678   \n",
       "Age                 38               67               43               23   \n",
       "Class  tested_positive  tested_positive  tested_positive  tested_positive   \n",
       "\n",
       "                   4                5                6                7    \\\n",
       "Preg                 3                5                6                3   \n",
       "Plas               169              116                0              173   \n",
       "Pres                74               74               68               78   \n",
       "Skin                19               29               41               39   \n",
       "Insu               125                0                0              185   \n",
       "Mass              29.9             32.3             39.0             33.8   \n",
       "Pedi             0.268             0.66            0.727             0.97   \n",
       "Age                 31               35               41               31   \n",
       "Class  tested_positive  tested_positive  tested_positive  tested_positive   \n",
       "\n",
       "                   8                9    ...              990  \\\n",
       "Preg                 3                4  ...        47.753408   \n",
       "Plas               162              146  ...       136.946337   \n",
       "Pres                52               92  ...       118.898637   \n",
       "Skin                38                0  ...        42.501917   \n",
       "Insu                 0                0  ...        29.172914   \n",
       "Mass              37.2             31.2  ...        57.437393   \n",
       "Pedi             0.652            0.539  ...        46.633553   \n",
       "Age                 24               61  ...        63.196764   \n",
       "Class  tested_positive  tested_positive  ...  tested_positive   \n",
       "\n",
       "                   991              992              993              994  \\\n",
       "Preg         90.302505        77.039973        83.631083        22.624032   \n",
       "Plas        131.636097       128.649717       124.155001       142.065318   \n",
       "Pres        102.319125       109.974576         95.15935        129.31104   \n",
       "Skin         85.293119       108.707767        80.256626        16.624032   \n",
       "Insu         57.455611         50.31582        55.087389        11.410578   \n",
       "Mass         51.654869        55.074039        47.199762        33.737948   \n",
       "Pedi         91.758471        80.407003        87.954658        18.424215   \n",
       "Age          96.124171        104.31031        97.414786        44.787717   \n",
       "Class  tested_positive  tested_positive  tested_positive  tested_positive   \n",
       "\n",
       "                   995              996              997              998  \\\n",
       "Preg          7.843911        52.289659         8.843583        54.793363   \n",
       "Plas        145.189284       131.597821       143.372193         45.13696   \n",
       "Pres        133.702972       117.361886       132.462567       114.977306   \n",
       "Skin          5.708791        47.724867         8.540374        76.427073   \n",
       "Insu           3.91846        32.757897         5.862032        35.862242   \n",
       "Mass         32.443098        58.483266         66.47385        56.870339   \n",
       "Pedi          6.498553        52.460632         9.596741        57.462831   \n",
       "Age          30.594057        62.970602        28.125401        65.282016   \n",
       "Class  tested_positive  tested_positive  tested_positive  tested_positive   \n",
       "\n",
       "                   999  \n",
       "Preg         64.837713  \n",
       "Plas        139.240254  \n",
       "Pres         113.23033  \n",
       "Skin         67.212624  \n",
       "Insu        119.557761  \n",
       "Mass         54.943017  \n",
       "Pedi         66.036326  \n",
       "Age          75.673997  \n",
       "Class  tested_positive  \n",
       "\n",
       "[9 rows x 1000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>990</th>\n      <th>991</th>\n      <th>992</th>\n      <th>993</th>\n      <th>994</th>\n      <th>995</th>\n      <th>996</th>\n      <th>997</th>\n      <th>998</th>\n      <th>999</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Preg</th>\n      <td>14</td>\n      <td>4</td>\n      <td>15</td>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>6</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>47.753408</td>\n      <td>90.302505</td>\n      <td>77.039973</td>\n      <td>83.631083</td>\n      <td>22.624032</td>\n      <td>7.843911</td>\n      <td>52.289659</td>\n      <td>8.843583</td>\n      <td>54.793363</td>\n      <td>64.837713</td>\n    </tr>\n    <tr>\n      <th>Plas</th>\n      <td>175</td>\n      <td>146</td>\n      <td>136</td>\n      <td>107</td>\n      <td>169</td>\n      <td>116</td>\n      <td>0</td>\n      <td>173</td>\n      <td>162</td>\n      <td>146</td>\n      <td>...</td>\n      <td>136.946337</td>\n      <td>131.636097</td>\n      <td>128.649717</td>\n      <td>124.155001</td>\n      <td>142.065318</td>\n      <td>145.189284</td>\n      <td>131.597821</td>\n      <td>143.372193</td>\n      <td>45.13696</td>\n      <td>139.240254</td>\n    </tr>\n    <tr>\n      <th>Pres</th>\n      <td>62</td>\n      <td>78</td>\n      <td>70</td>\n      <td>62</td>\n      <td>74</td>\n      <td>74</td>\n      <td>68</td>\n      <td>78</td>\n      <td>52</td>\n      <td>92</td>\n      <td>...</td>\n      <td>118.898637</td>\n      <td>102.319125</td>\n      <td>109.974576</td>\n      <td>95.15935</td>\n      <td>129.31104</td>\n      <td>133.702972</td>\n      <td>117.361886</td>\n      <td>132.462567</td>\n      <td>114.977306</td>\n      <td>113.23033</td>\n    </tr>\n    <tr>\n      <th>Skin</th>\n      <td>30</td>\n      <td>0</td>\n      <td>32</td>\n      <td>13</td>\n      <td>19</td>\n      <td>29</td>\n      <td>41</td>\n      <td>39</td>\n      <td>38</td>\n      <td>0</td>\n      <td>...</td>\n      <td>42.501917</td>\n      <td>85.293119</td>\n      <td>108.707767</td>\n      <td>80.256626</td>\n      <td>16.624032</td>\n      <td>5.708791</td>\n      <td>47.724867</td>\n      <td>8.540374</td>\n      <td>76.427073</td>\n      <td>67.212624</td>\n    </tr>\n    <tr>\n      <th>Insu</th>\n      <td>0</td>\n      <td>0</td>\n      <td>110</td>\n      <td>48</td>\n      <td>125</td>\n      <td>0</td>\n      <td>0</td>\n      <td>185</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>29.172914</td>\n      <td>57.455611</td>\n      <td>50.31582</td>\n      <td>55.087389</td>\n      <td>11.410578</td>\n      <td>3.91846</td>\n      <td>32.757897</td>\n      <td>5.862032</td>\n      <td>35.862242</td>\n      <td>119.557761</td>\n    </tr>\n    <tr>\n      <th>Mass</th>\n      <td>33.6</td>\n      <td>38.5</td>\n      <td>37.1</td>\n      <td>22.9</td>\n      <td>29.9</td>\n      <td>32.3</td>\n      <td>39.0</td>\n      <td>33.8</td>\n      <td>37.2</td>\n      <td>31.2</td>\n      <td>...</td>\n      <td>57.437393</td>\n      <td>51.654869</td>\n      <td>55.074039</td>\n      <td>47.199762</td>\n      <td>33.737948</td>\n      <td>32.443098</td>\n      <td>58.483266</td>\n      <td>66.47385</td>\n      <td>56.870339</td>\n      <td>54.943017</td>\n    </tr>\n    <tr>\n      <th>Pedi</th>\n      <td>0.212</td>\n      <td>0.52</td>\n      <td>0.153</td>\n      <td>0.678</td>\n      <td>0.268</td>\n      <td>0.66</td>\n      <td>0.727</td>\n      <td>0.97</td>\n      <td>0.652</td>\n      <td>0.539</td>\n      <td>...</td>\n      <td>46.633553</td>\n      <td>91.758471</td>\n      <td>80.407003</td>\n      <td>87.954658</td>\n      <td>18.424215</td>\n      <td>6.498553</td>\n      <td>52.460632</td>\n      <td>9.596741</td>\n      <td>57.462831</td>\n      <td>66.036326</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>38</td>\n      <td>67</td>\n      <td>43</td>\n      <td>23</td>\n      <td>31</td>\n      <td>35</td>\n      <td>41</td>\n      <td>31</td>\n      <td>24</td>\n      <td>61</td>\n      <td>...</td>\n      <td>63.196764</td>\n      <td>96.124171</td>\n      <td>104.31031</td>\n      <td>97.414786</td>\n      <td>44.787717</td>\n      <td>30.594057</td>\n      <td>62.970602</td>\n      <td>28.125401</td>\n      <td>65.282016</td>\n      <td>75.673997</td>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>...</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>9 rows √ó 1000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 208
    }
   ],
   "source": [
    "over = Populate(needToGenerate,BSnn,Majnn,Range,P_max,finaldata)\n",
    "alldata = data.T\n",
    "alldata\n",
    "\n",
    "for i in range(len(over)):\n",
    "    alldata[len(data)+i] = over[i]\n",
    "alldata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean ROC AUC: 0.676\n"
     ]
    }
   ],
   "source": [
    "# ‰∏ÄËà¨ SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, finaldata, output, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean ROC AUC: 0.775\n"
     ]
    }
   ],
   "source": [
    "# RCSMOTE\n",
    "X = alldata.T.iloc[:,:8]\n",
    "y = alldata.T.iloc[:,8]\n",
    "model = DecisionTreeClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean ROC AUC: 0.669\n"
     ]
    }
   ],
   "source": [
    "# Borderline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "steps = [('border_line', BorderlineSMOTE(random_state=42,kind=\"borderline-1\")), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, finaldata, output, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}