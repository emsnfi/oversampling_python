{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os;\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 計算每個點鄰近的 k 的點 用 k 個點所在的個數 判別該點(非鄰近的點) 屬於什麼類型的點 (safe noisy border)\n",
    "# 先用一個二分類的資料\n",
    "\n",
    "# 此 function 用來判別是否為 safe danger(border) or noisy\n",
    "\n",
    "def _in_danger_noise(\n",
    "        self, nn_estimator, samples, target_class, y, kind=\"danger\"\n",
    "    ):\n",
    "    '''\n",
    "        Estimate if a set of sample are in danger or noise.\n",
    "        Used by BorderlineSMOTE and SVMSMOTE.\n",
    "        Parameters\n",
    "        ----------\n",
    "        nn_estimator : estimator object\n",
    "            An estimator that inherits from\n",
    "            :class:`~sklearn.neighbors.base.KNeighborsMixin` use to determine if\n",
    "            a sample is in danger/noise.\n",
    "        samples : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            The samples to check if either they are in danger or not.\n",
    "        target_class : int or str\n",
    "            The target corresponding class being over-sampled.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The true label in order to check the neighbour labels.\n",
    "        kind : {'danger', 'noise'}, default='danger'\n",
    "            The type of classification to use. Can be either:\n",
    "            - If 'danger', check if samples are in danger,\n",
    "            - If 'noise', check if samples are noise.\n",
    "        Returns\n",
    "        -------\n",
    "        output : ndarray of shape (n_samples,)\n",
    "            A boolean array where True refer to samples in danger or noise.\n",
    "  \n",
    "\n",
    "        x = nn_estimator.kneighbors(samples, return_distance=False)[:, 1:]\n",
    "        nn_label = (y[x] != target_class).astype(int)\n",
    "        n_maj = np.sum(nn_label, axis=1)\n",
    "\n",
    "        if kind == \"danger\": \n",
    "            # Samples are in danger / border for m/2 <= m' < m\n",
    "            return np.bitwise_and(\n",
    "                n_maj >= (nn_estimator.n_neighbors - 1) / 2,\n",
    "                n_maj < nn_estimator.n_neighbors - 1,\n",
    "            )\n",
    "        elif kind == \"noise\":\n",
    "            # Samples are noise for m = m'\n",
    "            return n_maj == nn_estimator.n_neighbors - 1\n",
    "        else: # safe sample\n",
    "            raise NotImplementedError\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "class Smote:\n",
    "    def __init__(self,samples,N=10,k=5):\n",
    "        self.n_samples,self.n_attrs=samples.shape\n",
    "        self.N=N\n",
    "        self.k=k\n",
    "        self.samples=samples\n",
    "        self.newindex=0\n",
    "       # self.synthetic=np.zeros((self.n_samples*N,self.n_attrs))\n",
    "\n",
    "    def over_sampling(self):\n",
    "        N=int(self.N/100)\n",
    "        self.synthetic = np.zeros((self.n_samples * N, self.n_attrs))\n",
    "        neighbors=NearestNeighbors(n_neighbors=self.k).fit(self.samples)\n",
    "        print 'neighbors',neighbors\n",
    "        for i in range(len(self.samples)):\n",
    "            nnarray=neighbors.kneighbors(self.samples[i].reshape(1,-1),return_distance=False)[0]\n",
    "            #print nnarray\n",
    "            self._populate(N,i,nnarray)\n",
    "        return self.synthetic\n",
    "\n",
    "\n",
    "    # for each minority class samples,choose N of the k nearest neighbors and generate N synthetic samples.\n",
    "    def _populate(self,N,i,nnarray):\n",
    "        for j in range(N):\n",
    "            nn=random.randint(0,self.k-1)\n",
    "            dif=self.samples[nnarray[nn]]-self.samples[i]\n",
    "            gap=random.random()\n",
    "            self.synthetic[self.newindex]=self.samples[i]+gap*dif\n",
    "            self.newindex+=1\n",
    "a=np.array([[1,2,3],[4,5,6],[2,3,1],[2,1,2],[2,3,4],[2,3,4]])\n",
    "s=Smote(a,N=100)\n",
    "print s.over_sampling()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "output = np.array(data.iloc[:,6)\n",
    "finaldata = np.array(data.iloc[:,:6)\n",
    "\n",
    "output = np.array(data.iloc[:,data.shape[1]-1])\n",
    "finaldata = np.array(data.iloc[:,:data.shape[1]-1]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape[1] # 行數    data.shape[0] 列數\n",
    "import os;\n",
    "import numpy as np;\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier;\n",
    "from sklearn.cluster import MiniBatchKMeans;\n",
    "import collections \n",
    "\n",
    "os.chdir(\"/Users/emily/Desktop/Research/oversampling_python/data\");\n",
    "print(os.getcwd());\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_excel(\"pima.xlsx\")\n",
    "data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "data = data.iloc[:,1:]\n",
    "data.shape[1]\n",
    "l = data.shape[1]-1\n",
    "\n",
    "output = np.array(data.iloc[:,l]);\n",
    "finaldata = np.array(data.iloc[:,:l])\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分佈\n",
    "counter = Counter(output)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(output) * 100\n",
    "\tprint(\"class\",k,\" percentage \",per,\"%\")\n",
    "   \n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試 自建\n",
    "\"\"\"\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X, y = make_classification(n_classes=3, class_sep=2,\n",
    "                           weights=[0.3,0.5,0.2], n_informative=3, n_redundant=0, flip_y=0,\n",
    "                           n_features=3, n_clusters_per_class=1, n_samples=100, random_state=9)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出 knn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "def knn(n_nu,sample):\n",
    "     # n_nu 自己設定多少鄰近個點\n",
    "     # input sample 沒有包含 class label\n",
    "        nnarray = []\n",
    "        neighbors=NearestNeighbors(n_neighbors=n_nu+1).fit(sample)\n",
    "        for i in range(len(sample)):\n",
    "            temp = neighbors.kneighbors(sample[i].reshape(1,-1),return_distance=False)[0]\n",
    "            temp = np.delete(temp,0)\n",
    "            # 有 array 存放 各個點的鄰近點 \n",
    "            nnarray.append(temp)\n",
    "        return nnarray # 回傳相近的點 分別是在第幾個 \n",
    "karray = knn(5,finaldata)\n",
    "karray[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出大類\n",
    "import collections \n",
    "from collections import Counter\n",
    "counter = Counter(output);\n",
    "\n",
    "print(counter)\n",
    "def find_maj(sample_class):\n",
    "    counter = Counter(sample_class);\n",
    "    print(counter)\n",
    "    return  list(dict(counter.most_common(1)).keys())\n",
    "\n",
    "find_maj(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# finaldata 是使用 bupa.xlsx 的\n",
    "# 變成 class\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "class RCSMOTE(self,n_nu,sample):\n",
    "    def __init__(self):\n",
    "            \n",
    "    def knn(self,n_nu,sample):\n",
    "        self.n_nu = n_nu;\n",
    "        self.sample = sample;\n",
    "        neighbors=NearestNeighbors(n_neighbors=n_nu+1).fit(sample)\n",
    "\n",
    "        nnarray=neighbors.kneighbors(sample[100].reshape(1,-1),return_distance=False)[0]\n",
    "        return nnarray # 回傳相近的點 分別是在第幾個 \n",
    "te = RCSMOTE();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(finaldata[:, 0], finaldata[:, 1], c=output)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判斷該點為什麼類型的點 如果其\n",
    "# 此 index 是 0 開始 所以對照到 excel 的要\n",
    "# inminority 是否是要求在小類中的 如果是則放 true\n",
    "def check_point_type(n_nu,sample,sample_class,data,inminority):\n",
    "    # 使用 find_maj(find_maj(sample_class)\n",
    "    # 使用 knn 找到鄰近的幾個點 \n",
    "    point_type = [] # 放個點是屬於什麼類型的 border safe noisy\n",
    "    n = 0\n",
    "    b = 0\n",
    "    s = 0\n",
    "    maj = find_maj(sample_class) # 大類\n",
    "    point = knn(n_nu,sample) # 回傳所有點鄰近 n_nu 個點\n",
    "    maj = \"\".join(maj) # maj 原本是 list 轉成 str\n",
    "    for index,i in enumerate(point):\n",
    "        maj_nu =0;\n",
    "        if(data.iloc[index,data.shape[1]-1] == maj and inminority == True): # 如果該點本身是大類則不計算\n",
    "            continue; # 如果使用此 則會跟論文的 data 一樣\n",
    "        for j in point[index]: # 每個點鄰近個點的 loop 例如第一個點是 [1,2,3,4,5] 則 loop 裡面的數值\n",
    "            if(data.iloc[j,data.shape[1]-1] == maj ): \n",
    "                maj_nu = maj_nu + 1 # 計算鄰近點為大類的有多少個\n",
    "        if(maj_nu == n_nu ):\n",
    "            point_type.append(\"noisy\");\n",
    "            n = n+1\n",
    "        elif(n_nu/2 < maj_nu and maj_nu < n_nu ):\n",
    "            point_type.append(\"border\");\n",
    "            b = b+1\n",
    "        else:\n",
    "            point_type.append(\"safe\");\n",
    "            s = s+1\n",
    "    print(\"noisy\",n,\"\\nborder\",b,\"\\nsafe\",s,\"\\nall\",n+b+s)\n",
    "    return point_type;\n",
    "point_type = check_point_type(3,finaldata,output,data,True) # 論文使用 knn 為 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料集變為小類的 border 跟 safe 以及 大類 去除 小類且為 noisy 的\n",
    "\"\"\"\n",
    "find the maximum value that existed for that attribute among\n",
    "the minority samples of the 𝐵𝑆 set, and also, find the minimum value that existed for\n",
    "the given attribute among the majority samples set\n",
    "\"\"\"\n",
    "# 先是小類去掉 noisy 再來是 大類 \n",
    "def split_BS_Majdata(point_type,sample,sample_class):\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # 大類\n",
    "    maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(sample[i])\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(sample[i])\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "    print(BS_sample)\n",
    "    return return_sample\n",
    "\n",
    "print(split_BS_Majdata(point_type,finaldata,output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_split_BS_Majdata(point_type,sample,sample_class): # maj 以及 BS set 在原本 data 的 index\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # 大類\n",
    "    maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(i)\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(i)\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "    \n",
    "    return return_sample\n",
    "\n",
    "index_split_BS_Majdata(point_type,finaldata,output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The obtained ranges for\n",
    "all features (attributes) are used to control the location of the new synthetic samples in\n",
    "data space.\n",
    "\n",
    "The set of these ranges is denoted by 𝑅𝑎𝑛𝑔𝑒 =\n",
    "(𝑟𝑎𝑛𝑔𝑒1 𝑟𝑎𝑛𝑔𝑒2 𝑟𝑎𝑛𝑔𝑒3 … 𝑟𝑎𝑛𝑔𝑒𝑛𝑎𝑡𝑡𝑟) array where 𝑛𝑎𝑡𝑡𝑟 is the number of\n",
    "attributes in the dataset\n",
    "\n",
    "如何產生 Range array\n",
    "1. we find the maximum value that existed for that attribute among\n",
    "the minority samples of the 𝐵𝑆 set  𝑃 _𝑚𝑎𝑥 = (𝑝𝑚𝑎𝑥1 𝑝𝑚𝑎𝑥2\n",
    "…𝑝𝑚𝑎𝑥𝑛𝑎𝑡𝑡𝑟) array\n",
    "\n",
    "2. find the minimum value that existed for\n",
    "the given attribute among the majority samples set  𝑁 _𝑚𝑖𝑛 = (𝑛𝑚𝑖𝑛1 𝑛𝑚𝑖𝑛2 …𝑛𝑚𝑖𝑛𝑛𝑎𝑡𝑡𝑟)array\n",
    "\n",
    "3. Then, the desired 𝑅𝑎𝑛𝑔𝑒 vector is obtained as the average of 𝑁_𝑚𝑖𝑛 and\n",
    "𝑃 _𝑚𝑎𝑥 arrays\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# dataframe[0] 行數  dataframe[1] 列數\n",
    "# 該屬性中 在 bs set 的最大值 以及 大類中的最小值\n",
    "# range 為兩個相加除以 2\n",
    "# index_split_BS_Majdata 回傳 [0] BS set [1] 回傳 Maj set\n",
    "def range_value(n_nu,sample,sample_class,data):\n",
    "    point_type = check_point_type(n_nu,sample,sample_class,data,False)\n",
    "    index = index_split_BS_Majdata(point_type,sample,sample_class)\n",
    "    BS_max = []\n",
    "    Maj_min = []\n",
    "    all_value = []\n",
    "    for i in range(len(sample[0])): # loop 屬性\n",
    "        for j in range(2): # loop data\n",
    "            if(j==0): # BS set 的 index\n",
    "                BS_index = index[j]\n",
    "                max_value = np.max(sample[BS_index][i]);\n",
    "                BS_max.append(max_value)\n",
    "            else:\n",
    "                Maj_index = index[j]\n",
    "                min_value = np.min(sample[Maj_index][i]);\n",
    "                Maj_min.append(min_value)\n",
    "    # temp = np.array([BS_max,Maj_min]) \n",
    "    range_value = [(BS_max[i] - Maj_min[i])/2 for i in range(len(BS_max))]\n",
    "    all_value = np.array([BS_max,Maj_min,range_value])\n",
    "    return all_value\n",
    "range_value(3,finaldata,output,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b𝑛𝑢𝑚: Number of samples in 𝐵𝑜𝑟𝑑𝑒𝑟 屬於 border 的資料數\n",
    "# compute its(border sample) k nearest neighbors in BS, and save them in BSnn 存放 \n",
    "# compute its(border sample) k nearest neighbors in Maj set, and save them in Majnn\n",
    "def getBSnn_Majnn(n_nu,sample,sample_class,data):     \n",
    "    point_type = check_point_type(n_nu,sample,sample_class,data,False) # 得知所有 sample 中屬於 border 的  \n",
    "    index = index_split_BS_Majdata(point_type,sample,sample_class) \n",
    "    k = knn(n_nu,sample)\n",
    "    BSnn = []\n",
    "    Majnn = []\n",
    "    # 用 border sample 的 index \n",
    "    for i,element in enumerate(point_type):\n",
    "        if(element == \"border\"):\n",
    "            for j in range(2):\n",
    "                for w in index[j]:\n",
    "                    if(j == 0 and i == w ):\n",
    "                        BSnn.append(k[w])\n",
    "                    elif(j==1 and i == w):\n",
    "                        Majnn.append(k[w])\n",
    "        \n",
    "    temp = np.array([BSnn,Majnn]);\n",
    "    print(len(temp[0]+temp[1]))\n",
    "    return temp\n",
    "    \n",
    "len(getBSnn_Majnn(3,finaldata,output,data)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "s1col = random.randint(0,1-1)\n",
    "print(s1col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成資料\n",
    "\n",
    "\n",
    "def Populate(r,BSnn,Majnn,Range,P_max,sample):\n",
    "    # r 代表要產生的資料的數量 論文定義該數量為增加小類至跟大類相同的數量 達成 50% (大類減小類的數量)\n",
    "    Bl = len(BSnn)-1\n",
    "    nn_nu = len(BSnn[0])-1\n",
    "    Synthetic = []\n",
    "    while(r > 0):\n",
    "\n",
    "        s1row = random.randint(0,Bl)\n",
    "        s1col = random.randint(0,nn_nu)\n",
    "        s1 = BSnn[s1row][s1col]\n",
    "        s2row = random.randint(0,Bl)\n",
    "        s2col = random.randint(0,nn_nu)\n",
    "        s2 = Majnn[s2row][s2col]\n",
    "        min_attr = []\n",
    "        for i in range(len(sample[0])):\n",
    "        \n",
    "            if(sample[s1][i] < sample[s2][i]):\n",
    "                min_attr.append(sample[s1][i])\n",
    "            else:\n",
    "                min_attr.append(sample[s2][i])\n",
    "        diff = [(P_max[i] - min_attr[i]) for i in range(len(P_max))]\n",
    "        #print(\"diff\",diff)\n",
    "        gap = random.uniform(0,0.5)\n",
    "        var = [(diff[i] * gap ) for i in range(len(diff))]\n",
    "        temp = []\n",
    "        for i in range(len(sample[0])):\n",
    "            if(min_attr[i]+var[i] <= Range[i]):\n",
    "                temp.append(min_attr[i]+var[i])\n",
    "            else:\n",
    "                temp.append(P_max[i]-var[i])\n",
    "        temp.append(\"tested_positive\")\n",
    "        Synthetic.append(temp)   \n",
    "        r = r-1\n",
    "    return Synthetic\n",
    "    \n",
    "needToGenerate = 232\n",
    "BSnn = getBSnn_Majnn(3,finaldata,output,data)[0]\n",
    "Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "Range = range_value(3,finaldata,output,data)\n",
    "P_max = range_value(3,finaldata,output,data)[0]\n",
    "Range = range_value(3,finaldata,output,data)[2]\n",
    "Populate(needToGenerate,BSnn,Majnn,Range,P_max,finaldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   0                1                2                3    \\\n",
       "Preg                14                4               15                3   \n",
       "Plas               175              146              136              107   \n",
       "Pres                62               78               70               62   \n",
       "Skin                30                0               32               13   \n",
       "Insu                 0                0              110               48   \n",
       "Mass              33.6             38.5             37.1             22.9   \n",
       "Pedi             0.212             0.52            0.153            0.678   \n",
       "Age                 38               67               43               23   \n",
       "Class  tested_positive  tested_positive  tested_positive  tested_positive   \n",
       "\n",
       "                   4                5                6                7    \\\n",
       "Preg                 3                5                6                3   \n",
       "Plas               169              116                0              173   \n",
       "Pres                74               74               68               78   \n",
       "Skin                19               29               41               39   \n",
       "Insu               125                0                0              185   \n",
       "Mass              29.9             32.3             39.0             33.8   \n",
       "Pedi             0.268             0.66            0.727             0.97   \n",
       "Age                 31               35               41               31   \n",
       "Class  tested_positive  tested_positive  tested_positive  tested_positive   \n",
       "\n",
       "                   8                9    ...              990  \\\n",
       "Preg                 3                4  ...        47.753408   \n",
       "Plas               162              146  ...       136.946337   \n",
       "Pres                52               92  ...       118.898637   \n",
       "Skin                38                0  ...        42.501917   \n",
       "Insu                 0                0  ...        29.172914   \n",
       "Mass              37.2             31.2  ...        57.437393   \n",
       "Pedi             0.652            0.539  ...        46.633553   \n",
       "Age                 24               61  ...        63.196764   \n",
       "Class  tested_positive  tested_positive  ...  tested_positive   \n",
       "\n",
       "                   991              992              993              994  \\\n",
       "Preg         90.302505        77.039973        83.631083        22.624032   \n",
       "Plas        131.636097       128.649717       124.155001       142.065318   \n",
       "Pres        102.319125       109.974576         95.15935        129.31104   \n",
       "Skin         85.293119       108.707767        80.256626        16.624032   \n",
       "Insu         57.455611         50.31582        55.087389        11.410578   \n",
       "Mass         51.654869        55.074039        47.199762        33.737948   \n",
       "Pedi         91.758471        80.407003        87.954658        18.424215   \n",
       "Age          96.124171        104.31031        97.414786        44.787717   \n",
       "Class  tested_positive  tested_positive  tested_positive  tested_positive   \n",
       "\n",
       "                   995              996              997              998  \\\n",
       "Preg          7.843911        52.289659         8.843583        54.793363   \n",
       "Plas        145.189284       131.597821       143.372193         45.13696   \n",
       "Pres        133.702972       117.361886       132.462567       114.977306   \n",
       "Skin          5.708791        47.724867         8.540374        76.427073   \n",
       "Insu           3.91846        32.757897         5.862032        35.862242   \n",
       "Mass         32.443098        58.483266         66.47385        56.870339   \n",
       "Pedi          6.498553        52.460632         9.596741        57.462831   \n",
       "Age          30.594057        62.970602        28.125401        65.282016   \n",
       "Class  tested_positive  tested_positive  tested_positive  tested_positive   \n",
       "\n",
       "                   999  \n",
       "Preg         64.837713  \n",
       "Plas        139.240254  \n",
       "Pres         113.23033  \n",
       "Skin         67.212624  \n",
       "Insu        119.557761  \n",
       "Mass         54.943017  \n",
       "Pedi         66.036326  \n",
       "Age          75.673997  \n",
       "Class  tested_positive  \n",
       "\n",
       "[9 rows x 1000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>990</th>\n      <th>991</th>\n      <th>992</th>\n      <th>993</th>\n      <th>994</th>\n      <th>995</th>\n      <th>996</th>\n      <th>997</th>\n      <th>998</th>\n      <th>999</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Preg</th>\n      <td>14</td>\n      <td>4</td>\n      <td>15</td>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n      <td>6</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>47.753408</td>\n      <td>90.302505</td>\n      <td>77.039973</td>\n      <td>83.631083</td>\n      <td>22.624032</td>\n      <td>7.843911</td>\n      <td>52.289659</td>\n      <td>8.843583</td>\n      <td>54.793363</td>\n      <td>64.837713</td>\n    </tr>\n    <tr>\n      <th>Plas</th>\n      <td>175</td>\n      <td>146</td>\n      <td>136</td>\n      <td>107</td>\n      <td>169</td>\n      <td>116</td>\n      <td>0</td>\n      <td>173</td>\n      <td>162</td>\n      <td>146</td>\n      <td>...</td>\n      <td>136.946337</td>\n      <td>131.636097</td>\n      <td>128.649717</td>\n      <td>124.155001</td>\n      <td>142.065318</td>\n      <td>145.189284</td>\n      <td>131.597821</td>\n      <td>143.372193</td>\n      <td>45.13696</td>\n      <td>139.240254</td>\n    </tr>\n    <tr>\n      <th>Pres</th>\n      <td>62</td>\n      <td>78</td>\n      <td>70</td>\n      <td>62</td>\n      <td>74</td>\n      <td>74</td>\n      <td>68</td>\n      <td>78</td>\n      <td>52</td>\n      <td>92</td>\n      <td>...</td>\n      <td>118.898637</td>\n      <td>102.319125</td>\n      <td>109.974576</td>\n      <td>95.15935</td>\n      <td>129.31104</td>\n      <td>133.702972</td>\n      <td>117.361886</td>\n      <td>132.462567</td>\n      <td>114.977306</td>\n      <td>113.23033</td>\n    </tr>\n    <tr>\n      <th>Skin</th>\n      <td>30</td>\n      <td>0</td>\n      <td>32</td>\n      <td>13</td>\n      <td>19</td>\n      <td>29</td>\n      <td>41</td>\n      <td>39</td>\n      <td>38</td>\n      <td>0</td>\n      <td>...</td>\n      <td>42.501917</td>\n      <td>85.293119</td>\n      <td>108.707767</td>\n      <td>80.256626</td>\n      <td>16.624032</td>\n      <td>5.708791</td>\n      <td>47.724867</td>\n      <td>8.540374</td>\n      <td>76.427073</td>\n      <td>67.212624</td>\n    </tr>\n    <tr>\n      <th>Insu</th>\n      <td>0</td>\n      <td>0</td>\n      <td>110</td>\n      <td>48</td>\n      <td>125</td>\n      <td>0</td>\n      <td>0</td>\n      <td>185</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>29.172914</td>\n      <td>57.455611</td>\n      <td>50.31582</td>\n      <td>55.087389</td>\n      <td>11.410578</td>\n      <td>3.91846</td>\n      <td>32.757897</td>\n      <td>5.862032</td>\n      <td>35.862242</td>\n      <td>119.557761</td>\n    </tr>\n    <tr>\n      <th>Mass</th>\n      <td>33.6</td>\n      <td>38.5</td>\n      <td>37.1</td>\n      <td>22.9</td>\n      <td>29.9</td>\n      <td>32.3</td>\n      <td>39.0</td>\n      <td>33.8</td>\n      <td>37.2</td>\n      <td>31.2</td>\n      <td>...</td>\n      <td>57.437393</td>\n      <td>51.654869</td>\n      <td>55.074039</td>\n      <td>47.199762</td>\n      <td>33.737948</td>\n      <td>32.443098</td>\n      <td>58.483266</td>\n      <td>66.47385</td>\n      <td>56.870339</td>\n      <td>54.943017</td>\n    </tr>\n    <tr>\n      <th>Pedi</th>\n      <td>0.212</td>\n      <td>0.52</td>\n      <td>0.153</td>\n      <td>0.678</td>\n      <td>0.268</td>\n      <td>0.66</td>\n      <td>0.727</td>\n      <td>0.97</td>\n      <td>0.652</td>\n      <td>0.539</td>\n      <td>...</td>\n      <td>46.633553</td>\n      <td>91.758471</td>\n      <td>80.407003</td>\n      <td>87.954658</td>\n      <td>18.424215</td>\n      <td>6.498553</td>\n      <td>52.460632</td>\n      <td>9.596741</td>\n      <td>57.462831</td>\n      <td>66.036326</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>38</td>\n      <td>67</td>\n      <td>43</td>\n      <td>23</td>\n      <td>31</td>\n      <td>35</td>\n      <td>41</td>\n      <td>31</td>\n      <td>24</td>\n      <td>61</td>\n      <td>...</td>\n      <td>63.196764</td>\n      <td>96.124171</td>\n      <td>104.31031</td>\n      <td>97.414786</td>\n      <td>44.787717</td>\n      <td>30.594057</td>\n      <td>62.970602</td>\n      <td>28.125401</td>\n      <td>65.282016</td>\n      <td>75.673997</td>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>...</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n      <td>tested_positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>9 rows × 1000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 208
    }
   ],
   "source": [
    "over = Populate(needToGenerate,BSnn,Majnn,Range,P_max,finaldata)\n",
    "alldata = data.T\n",
    "alldata\n",
    "\n",
    "for i in range(len(over)):\n",
    "    alldata[len(data)+i] = over[i]\n",
    "alldata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean ROC AUC: 0.676\n"
     ]
    }
   ],
   "source": [
    "# 一般 SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, finaldata, output, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean ROC AUC: 0.775\n"
     ]
    }
   ],
   "source": [
    "# RCSMOTE\n",
    "X = alldata.T.iloc[:,:8]\n",
    "y = alldata.T.iloc[:,8]\n",
    "model = DecisionTreeClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean ROC AUC: 0.669\n"
     ]
    }
   ],
   "source": [
    "# Borderline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "steps = [('border_line', BorderlineSMOTE(random_state=42,kind=\"borderline-1\")), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, finaldata, output, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}