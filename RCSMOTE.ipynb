{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os;\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 計算每個點鄰近的 k 的點 用 k 個點所在的個數 判別該點(非鄰近的點) 屬於什麼類型的點 (safe noisy border)\n",
    "# 先用一個二分類的資料\n",
    "\n",
    "# 此 function 用來判別是否為 safe danger(border) or noisy\n",
    "\n",
    "def _in_danger_noise(\n",
    "        self, nn_estimator, samples, target_class, y, kind=\"danger\"\n",
    "    ):\n",
    "    '''\n",
    "        Estimate if a set of sample are in danger or noise.\n",
    "        Used by BorderlineSMOTE and SVMSMOTE.\n",
    "        Parameters\n",
    "        ----------\n",
    "        nn_estimator : estimator object\n",
    "            An estimator that inherits from\n",
    "            :class:`~sklearn.neighbors.base.KNeighborsMixin` use to determine if\n",
    "            a sample is in danger/noise.\n",
    "        samples : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            The samples to check if either they are in danger or not.\n",
    "        target_class : int or str\n",
    "            The target corresponding class being over-sampled.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The true label in order to check the neighbour labels.\n",
    "        kind : {'danger', 'noise'}, default='danger'\n",
    "            The type of classification to use. Can be either:\n",
    "            - If 'danger', check if samples are in danger,\n",
    "            - If 'noise', check if samples are noise.\n",
    "        Returns\n",
    "        -------\n",
    "        output : ndarray of shape (n_samples,)\n",
    "            A boolean array where True refer to samples in danger or noise.\n",
    "  \n",
    "\n",
    "        x = nn_estimator.kneighbors(samples, return_distance=False)[:, 1:]\n",
    "        nn_label = (y[x] != target_class).astype(int)\n",
    "        n_maj = np.sum(nn_label, axis=1)\n",
    "\n",
    "        if kind == \"danger\": \n",
    "            # Samples are in danger / border for m/2 <= m' < m\n",
    "            return np.bitwise_and(\n",
    "                n_maj >= (nn_estimator.n_neighbors - 1) / 2,\n",
    "                n_maj < nn_estimator.n_neighbors - 1,\n",
    "            )\n",
    "        elif kind == \"noise\":\n",
    "            # Samples are noise for m = m'\n",
    "            return n_maj == nn_estimator.n_neighbors - 1\n",
    "        else: # safe sample\n",
    "            raise NotImplementedError\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "class Smote:\n",
    "    def __init__(self,samples,N=10,k=5):\n",
    "        self.n_samples,self.n_attrs=samples.shape\n",
    "        self.N=N\n",
    "        self.k=k\n",
    "        self.samples=samples\n",
    "        self.newindex=0\n",
    "       # self.synthetic=np.zeros((self.n_samples*N,self.n_attrs))\n",
    "\n",
    "    def over_sampling(self):\n",
    "        N=int(self.N/100)\n",
    "        self.synthetic = np.zeros((self.n_samples * N, self.n_attrs))\n",
    "        neighbors=NearestNeighbors(n_neighbors=self.k).fit(self.samples)\n",
    "        print 'neighbors',neighbors\n",
    "        for i in range(len(self.samples)):\n",
    "            nnarray=neighbors.kneighbors(self.samples[i].reshape(1,-1),return_distance=False)[0]\n",
    "            #print nnarray\n",
    "            self._populate(N,i,nnarray)\n",
    "        return self.synthetic\n",
    "\n",
    "\n",
    "    # for each minority class samples,choose N of the k nearest neighbors and generate N synthetic samples.\n",
    "    def _populate(self,N,i,nnarray):\n",
    "        for j in range(N):\n",
    "            nn=random.randint(0,self.k-1)\n",
    "            dif=self.samples[nnarray[nn]]-self.samples[i]\n",
    "            gap=random.random()\n",
    "            self.synthetic[self.newindex]=self.samples[i]+gap*dif\n",
    "            self.newindex+=1\n",
    "a=np.array([[1,2,3],[4,5,6],[2,3,1],[2,1,2],[2,3,4],[2,3,4]])\n",
    "s=Smote(a,N=100)\n",
    "print s.over_sampling()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "output = np.array(data.iloc[:,6)\n",
    "finaldata = np.array(data.iloc[:,:6)\n",
    "\n",
    "output = np.array(data.iloc[:,data.shape[1]-1])\n",
    "finaldata = np.array(data.iloc[:,:data.shape[1]-1]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape[1] # 行數    data.shape[0] 列數\n",
    "import os;\n",
    "import numpy as np;\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier;\n",
    "from sklearn.cluster import MiniBatchKMeans;\n",
    "import collections \n",
    "\n",
    "os.chdir(\"/Users/emily/Desktop/Research/oversampling_python/data\");\n",
    "print(os.getcwd());\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_excel(\"pima.xlsx\")\n",
    "data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "data = data.iloc[:,1:]\n",
    "data.shape[1]\n",
    "l = data.shape[1]-1\n",
    "\n",
    "output = np.array(data.iloc[:,l]);\n",
    "finaldata = np.array(data.iloc[:,:l])\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分佈\n",
    "counter = Counter(output)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(output) * 100\n",
    "\tprint(\"class\",k,\" percentage \",per,\"%\")\n",
    "   \n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試 自建\n",
    "\"\"\"\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X, y = make_classification(n_classes=3, class_sep=2,\n",
    "                           weights=[0.3,0.5,0.2], n_informative=3, n_redundant=0, flip_y=0,\n",
    "                           n_features=3, n_clusters_per_class=1, n_samples=100, random_state=9)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出 knn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "def knn(n_nu,sample):\n",
    "     # n_nu 自己設定多少鄰近個點\n",
    "     # input sample 沒有包含 class label\n",
    "        nnarray = []\n",
    "        neighbors=NearestNeighbors(n_neighbors=n_nu+1).fit(sample)\n",
    "        for i in range(len(sample)):\n",
    "            temp = neighbors.kneighbors(sample[i].reshape(1,-1),return_distance=False)[0]\n",
    "            temp = np.delete(temp,0)\n",
    "            # 有 array 存放 各個點的鄰近點 \n",
    "            nnarray.append(temp)\n",
    "        return nnarray # 回傳相近的點 分別是在第幾個 \n",
    "karray = knn(5,finaldata)\n",
    "karray[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出大類\n",
    "import collections \n",
    "from collections import Counter\n",
    "counter = Counter(output);\n",
    "\n",
    "print(counter)\n",
    "def find_maj(sample_class):\n",
    "    counter = Counter(sample_class);\n",
    "    print(counter)\n",
    "    return  list(dict(counter.most_common(1)).keys())\n",
    "\n",
    "find_maj(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# finaldata 是使用 bupa.xlsx 的\n",
    "# 變成 class\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "class RCSMOTE(self,n_nu,sample):\n",
    "    def __init__(self):\n",
    "            \n",
    "    def knn(self,n_nu,sample):\n",
    "        self.n_nu = n_nu;\n",
    "        self.sample = sample;\n",
    "        neighbors=NearestNeighbors(n_neighbors=n_nu+1).fit(sample)\n",
    "\n",
    "        nnarray=neighbors.kneighbors(sample[100].reshape(1,-1),return_distance=False)[0]\n",
    "        return nnarray # 回傳相近的點 分別是在第幾個 \n",
    "te = RCSMOTE();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(finaldata[:, 0], finaldata[:, 1], c=output)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判斷該點為什麼類型的點 如果其\n",
    "# 此 index 是 0 開始 所以對照到 excel 的要\n",
    "# inminority 是否是要求在小類中的 如果是則放 true\n",
    "def check_point_type(n_nu,sample,sample_class,data,inminority):\n",
    "    # 使用 find_maj(find_maj(sample_class)\n",
    "    # 使用 knn 找到鄰近的幾個點 \n",
    "    point_type = [] # 放個點是屬於什麼類型的 border safe noisy\n",
    "    n = 0\n",
    "    b = 0\n",
    "    s = 0\n",
    "    maj = find_maj(sample_class) # 大類\n",
    "    point = knn(n_nu,sample) # 回傳所有點鄰近 n_nu 個點\n",
    "    maj = \"\".join(maj) # maj 原本是 list 轉成 str\n",
    "    for index,i in enumerate(point):\n",
    "        maj_nu =0;\n",
    "        if(data.iloc[index,data.shape[1]-1] == maj and inminority == True): # 如果該點本身是大類則不計算\n",
    "            continue; # 如果使用此 則會跟論文的 data 一樣\n",
    "        for j in point[index]: # 每個點鄰近個點的 loop 例如第一個點是 [1,2,3,4,5] 則 loop 裡面的數值\n",
    "            if(data.iloc[j,data.shape[1]-1] == maj ): \n",
    "                maj_nu = maj_nu + 1 # 計算鄰近點為大類的有多少個\n",
    "        if(maj_nu == n_nu ):\n",
    "            point_type.append(\"noisy\");\n",
    "            n = n+1\n",
    "        elif(n_nu/2 < maj_nu and maj_nu < n_nu ):\n",
    "            point_type.append(\"border\");\n",
    "            b = b+1\n",
    "        else:\n",
    "            point_type.append(\"safe\");\n",
    "            s = s+1\n",
    "    print(\"noisy\",n,\"\\nborder\",b,\"\\nsafe\",s,\"\\nall\",n+b+s)\n",
    "    return point_type;\n",
    "point_type = check_point_type(3,finaldata,output,data,True) # 論文使用 knn 為 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料集變為小類的 border 跟 safe 以及 大類 去除 小類且為 noisy 的\n",
    "\"\"\"\n",
    "find the maximum value that existed for that attribute among\n",
    "the minority samples of the 𝐵𝑆 set, and also, find the minimum value that existed for\n",
    "the given attribute among the majority samples set\n",
    "\"\"\"\n",
    "# 先是小類去掉 noisy 再來是 大類 \n",
    "def split_BS_Majdata(point_type,sample,sample_class):\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # 大類\n",
    "    maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(sample[i])\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(sample[i])\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "    print(BS_sample)\n",
    "    return return_sample\n",
    "\n",
    "print(split_BS_Majdata(point_type,finaldata,output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_split_BS_Majdata(point_type,sample,sample_class): # maj 以及 BS set 在原本 data 的 index\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # 大類\n",
    "    maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(i)\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(i)\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "    \n",
    "    return return_sample\n",
    "\n",
    "index_split_BS_Majdata(point_type,finaldata,output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "noisy 288 \n",
      "border 225 \n",
      "safe 255 \n",
      "all 768\n",
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[175.    , 146.    , 136.    , 169.    , 116.    ,  68.    ,\n",
       "        185.    , 162.    ],\n",
       "       [  0.    ,   0.444 ,   0.997 ,   1.6   ,   0.262 ,   0.318 ,\n",
       "          0.    ,   0.591 ],\n",
       "       [ 87.5   ,  72.778 ,  67.5015,  83.7   ,  57.869 ,  33.841 ,\n",
       "         92.5   ,  80.7045]])"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "\"\"\"\n",
    "The obtained ranges for\n",
    "all features (attributes) are used to control the location of the new synthetic samples in\n",
    "data space.\n",
    "\n",
    "The set of these ranges is denoted by 𝑅𝑎𝑛𝑔𝑒 =\n",
    "(𝑟𝑎𝑛𝑔𝑒1 𝑟𝑎𝑛𝑔𝑒2 𝑟𝑎𝑛𝑔𝑒3 … 𝑟𝑎𝑛𝑔𝑒𝑛𝑎𝑡𝑡𝑟) array where 𝑛𝑎𝑡𝑡𝑟 is the number of\n",
    "attributes in the dataset\n",
    "\n",
    "如何產生 Range array\n",
    "1. we find the maximum value that existed for that attribute among\n",
    "the minority samples of the 𝐵𝑆 set  𝑃 _𝑚𝑎𝑥 = (𝑝𝑚𝑎𝑥1 𝑝𝑚𝑎𝑥2\n",
    "…𝑝𝑚𝑎𝑥𝑛𝑎𝑡𝑡𝑟) array\n",
    "\n",
    "2. find the minimum value that existed for\n",
    "the given attribute among the majority samples set  𝑁 _𝑚𝑖𝑛 = (𝑛𝑚𝑖𝑛1 𝑛𝑚𝑖𝑛2 …𝑛𝑚𝑖𝑛𝑛𝑎𝑡𝑡𝑟)array\n",
    "\n",
    "3. Then, the desired 𝑅𝑎𝑛𝑔𝑒 vector is obtained as the average of 𝑁_𝑚𝑖𝑛 and\n",
    "𝑃 _𝑚𝑎𝑥 arrays\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# dataframe[0] 行數  dataframe[1] 列數\n",
    "# 該屬性中 在 bs set 的最大值 以及 大類中的最小值\n",
    "# range 為兩個相加除以 2\n",
    "# index_split_BS_Majdata 回傳 [0] BS set [1] 回傳 Maj set\n",
    "def range_value(n_nu,sample,sample_class,data):\n",
    "    point_type = check_point_type(n_nu,sample,sample_class,data,False)\n",
    "    index = index_split_BS_Majdata(point_type,sample,sample_class)\n",
    "    BS_max = []\n",
    "    Maj_min = []\n",
    "    all_value = []\n",
    "    for i in range(len(sample[0])): # loop 屬性\n",
    "        for j in range(2): # loop data\n",
    "            if(j==0): # BS set 的 index\n",
    "                BS_index = index[j]\n",
    "                max_value = np.max(sample[BS_index][i]);\n",
    "                BS_max.append(max_value)\n",
    "            else:\n",
    "                Maj_index = index[j]\n",
    "                min_value = np.min(sample[Maj_index][i]);\n",
    "                Maj_min.append(min_value)\n",
    "    # temp = np.array([BS_max,Maj_min]) \n",
    "    range_value = [(BS_max[i] - Maj_min[i])/2 for i in range(len(BS_max))]\n",
    "    all_value = np.array([BS_max,Maj_min,range_value])\n",
    "    return all_value\n",
    "range_value(3,finaldata,output,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b𝑛𝑢𝑚: Number of samples in 𝐵𝑜𝑟𝑑𝑒𝑟 屬於 border 的資料數\n",
    "# compute its(border sample) k nearest neighbors in BS, and save them in BSnn 存放 \n",
    "# compute its(border sample) k nearest neighbors in Maj set, and save them in Majnn\n",
    "def getBSnn_Majnn(n_nu,sample,sample_class,data):     \n",
    "    point_type = check_point_type(n_nu,sample,sample_class,data,False) # 得知所有 sample 中屬於 border 的  \n",
    "    index = index_split_BS_Majdata(point_type,sample,sample_class) \n",
    "    k = knn(n_nu,sample)\n",
    "    BSnn = []\n",
    "    Majnn = []\n",
    "    # 用 border sample 的 index \n",
    "    for i,element in enumerate(point_type):\n",
    "        if(element == \"border\"):\n",
    "            for j in range(2):\n",
    "                for w in index[j]:\n",
    "                    if(j == 0 and i == w ):\n",
    "                        BSnn.append(k[w])\n",
    "                    elif(j==1 and i == w):\n",
    "                        Majnn.append(k[w])\n",
    "        \n",
    "    temp = np.array([BSnn,Majnn]);\n",
    "    print(len(temp[0]+temp[1]))\n",
    "    return temp\n",
    "    \n",
    "len(getBSnn_Majnn(3,finaldata,output,data)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "s1col = random.randint(0,1-1)\n",
    "print(s1col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "noisy 288 \n",
      "border 225 \n",
      "safe 255 \n",
      "all 768\n",
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "225\n",
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "noisy 288 \n",
      "border 225 \n",
      "safe 255 \n",
      "all 768\n",
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "225\n",
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "noisy 288 \n",
      "border 225 \n",
      "safe 255 \n",
      "all 768\n",
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "noisy 288 \n",
      "border 225 \n",
      "safe 255 \n",
      "all 768\n",
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "noisy 288 \n",
      "border 225 \n",
      "safe 255 \n",
      "all 768\n",
      "Counter({'tested_negative': 500, 'tested_positive': 268})\n",
      "diff [172.0, 25.0, 84.0, 169.0, 116.0, 41.0, 184.873, 137.0]\n",
      "gap 0.44142006326253247\n",
      "var [75.92425088115559, 11.035501581563311, 37.079285314052726, 74.59999069136799, 51.204727338453765, 18.098222593763833, 81.60665135553415, 60.474548666966946]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "# 生成資料\n",
    "\n",
    "\n",
    "def Populate(r,BSnn,Majnn,Range,P_max,sample):\n",
    "    # r 代表要產生的資料的數量 論文定義該數量為增加小類至跟大類相同的數量 達成 50% (大類減小類的數量)\n",
    "    Bl = len(BSnn)-1\n",
    "    nn_nu = len(BSnn[0])-1\n",
    "    s1row = random.randint(0,Bl)\n",
    "    s1col = random.randint(0,nn_nu)\n",
    "    s1 = BSnn[s1row][s1col]\n",
    "    s2row = random.randint(0,Bl)\n",
    "    s2col = random.randint(0,nn_nu)\n",
    "    s2 = Majnn[s2row][s2col]\n",
    "    min_attr = []\n",
    "    \n",
    "    for i in range(len(sample[0])):\n",
    "        \n",
    "        if(sample[s1][i] < sample[s2][i]):\n",
    "            min_attr.append(sample[s1][i])\n",
    "        else:\n",
    "            min_attr.append(sample[s2][i])\n",
    "    diff = [(P_max[i] - min_attr[i]) for i in range(len(P_max))]\n",
    "    print(\"diff\",diff)\n",
    "    gap = random.uniform(0,0.5)\n",
    "    var = [(diff[i] * gap ) for i in range(len(diff))]\n",
    "    return 0\n",
    "    \n",
    "needToGenerate = 232\n",
    "BSnn = getBSnn_Majnn(3,finaldata,output,data)[0]\n",
    "Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "Range = range_value(3,finaldata,output,data)\n",
    "P_max = range_value(3,finaldata,output,data)[0]\n",
    "Range = range_value(3,finaldata,output,data)[2]\n",
    "Populate(232,BSnn,Majnn,Range,P_max,finaldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.545"
      ]
     },
     "metadata": {},
     "execution_count": 153
    }
   ],
   "source": [
    "finaldata[34][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}