{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ˆç®—æ¯å€‹é»é„°è¿‘çš„ k çš„é» ç”¨ k å€‹é»æ‰€åœ¨çš„å€‹æ•¸ åˆ¤åˆ¥è©²é»(éé„°è¿‘çš„é») å±¬æ–¼ä»€éº¼é¡å‹çš„é» (safe noisy border)\n",
    "# å…ˆç”¨ä¸€å€‹äºŒåˆ†é¡çš„è³‡æ–™\n",
    "\n",
    "# æ­¤ function ç”¨ä¾†åˆ¤åˆ¥æ˜¯å¦ç‚º safe danger(border) or noisy\n",
    "def _in_danger_noise(\n",
    "        self, nn_estimator, samples, target_class, y, kind=\"danger\"\n",
    "    ):\n",
    "        \"\"\"Estimate if a set of sample are in danger or noise.\n",
    "        Used by BorderlineSMOTE and SVMSMOTE.\n",
    "        Parameters\n",
    "        ----------\n",
    "        nn_estimator : estimator object\n",
    "            An estimator that inherits from\n",
    "            :class:`~sklearn.neighbors.base.KNeighborsMixin` use to determine if\n",
    "            a sample is in danger/noise.\n",
    "        samples : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            The samples to check if either they are in danger or not.\n",
    "        target_class : int or str\n",
    "            The target corresponding class being over-sampled.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The true label in order to check the neighbour labels.\n",
    "        kind : {'danger', 'noise'}, default='danger'\n",
    "            The type of classification to use. Can be either:\n",
    "            - If 'danger', check if samples are in danger,\n",
    "            - If 'noise', check if samples are noise.\n",
    "        Returns\n",
    "        -------\n",
    "        output : ndarray of shape (n_samples,)\n",
    "            A boolean array where True refer to samples in danger or noise.\n",
    "        \"\"\"\n",
    "        x = nn_estimator.kneighbors(samples, return_distance=False)[:, 1:]\n",
    "        nn_label = (y[x] != target_class).astype(int)\n",
    "        n_maj = np.sum(nn_label, axis=1)\n",
    "\n",
    "        if kind == \"danger\": \n",
    "            # Samples are in danger / border for m/2 <= m' < m\n",
    "            return np.bitwise_and(\n",
    "                n_maj >= (nn_estimator.n_neighbors - 1) / 2,\n",
    "                n_maj < nn_estimator.n_neighbors - 1,\n",
    "            )\n",
    "        elif kind == \"noise\":\n",
    "            # Samples are noise for m = m'\n",
    "            return n_maj == nn_estimator.n_neighbors - 1\n",
    "        else: # safe sample\n",
    "            raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "class Smote:\n",
    "    def __init__(self,samples,N=10,k=5):\n",
    "        self.n_samples,self.n_attrs=samples.shape\n",
    "        self.N=N\n",
    "        self.k=k\n",
    "        self.samples=samples\n",
    "        self.newindex=0\n",
    "       # self.synthetic=np.zeros((self.n_samples*N,self.n_attrs))\n",
    "\n",
    "    def over_sampling(self):\n",
    "        N=int(self.N/100)\n",
    "        self.synthetic = np.zeros((self.n_samples * N, self.n_attrs))\n",
    "        neighbors=NearestNeighbors(n_neighbors=self.k).fit(self.samples)\n",
    "        print 'neighbors',neighbors\n",
    "        for i in range(len(self.samples)):\n",
    "            nnarray=neighbors.kneighbors(self.samples[i].reshape(1,-1),return_distance=False)[0]\n",
    "            #print nnarray\n",
    "            self._populate(N,i,nnarray)\n",
    "        return self.synthetic\n",
    "\n",
    "\n",
    "    # for each minority class samples,choose N of the k nearest neighbors and generate N synthetic samples.\n",
    "    def _populate(self,N,i,nnarray):\n",
    "        for j in range(N):\n",
    "            nn=random.randint(0,self.k-1)\n",
    "            dif=self.samples[nnarray[nn]]-self.samples[i]\n",
    "            gap=random.random()\n",
    "            self.synthetic[self.newindex]=self.samples[i]+gap*dif\n",
    "            self.newindex+=1\n",
    "a=np.array([[1,2,3],[4,5,6],[2,3,1],[2,1,2],[2,3,4],[2,3,4]])\n",
    "s=Smote(a,N=100)\n",
    "print s.over_sampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "output = np.array(data.iloc[:,6)\n",
    "finaldata = np.array(data.iloc[:,:6)\n",
    "\n",
    "output = np.array(data.iloc[:,data.shape[1]-1])\n",
    "finaldata = np.array(data.iloc[:,:data.shape[1]-1]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape[1] # è¡Œæ•¸    data.shape[0] åˆ—æ•¸\n",
    "import os;\n",
    "os.chdir(\"/Users/emily/Desktop/Research/\");\n",
    "print(os.getcwd());\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_excel(\"pima.xlsx\")\n",
    "data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "data = data.iloc[:,1:]\n",
    "data.shape[1]\n",
    "l = data.shape[1]-1\n",
    "\n",
    "output = np.array(data.iloc[:,l]);\n",
    "finaldata = np.array(data.iloc[:,:l])\n",
    "\n",
    "finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output\n",
    "counter = Counter(output)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "finaldata=[]\n",
    "output = []\n",
    "c = np.array(c)\n",
    "import numpy as np \n",
    "for i in range(data.shape[0]):\n",
    "    c = data.T.iloc[:6,i]\n",
    "    c = np.array(c)\n",
    "\n",
    "    finaldata.append(c)\n",
    "finaldata\n",
    "output = np.array(data.T.iloc[:7,:])\n",
    "output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ è‡ªå»º\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X, y = make_classification(n_classes=3, class_sep=2,\n",
    "                           weights=[0.3,0.5,0.2], n_informative=3, n_redundant=0, flip_y=0,\n",
    "                           n_features=3, n_clusters_per_class=1, n_samples=100, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter.most_common(1)\n",
    "dict(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors=NearestNeighbors(n_neighbors=6).fit(finaldata)\n",
    "temp = neighbors.kneighbors(finaldata[1].reshape(1,-1),return_distance=False)[0]\n",
    "temp = np.delete(temp,0)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¾å‡º knn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "def knn(n_nu,sample):\n",
    "     # n_nu è‡ªå·±è¨­å®šå¤šå°‘é„°è¿‘å€‹é»\n",
    "     # input sample æ²’æœ‰åŒ…å« class label\n",
    "        nnarray = []\n",
    "        neighbors=NearestNeighbors(n_neighbors=n_nu+1).fit(sample)\n",
    "        for i in range(len(sample)):\n",
    "            temp = neighbors.kneighbors(sample[i].reshape(1,-1),return_distance=False)[0]\n",
    "            temp = np.delete(temp,0)\n",
    "            # æœ‰ array å­˜æ”¾ å„å€‹é»çš„é„°è¿‘é» \n",
    "            nnarray.append(temp)\n",
    "        return nnarray # å›å‚³ç›¸è¿‘çš„é» åˆ†åˆ¥æ˜¯åœ¨ç¬¬å¹¾å€‹ \n",
    "karray = knn(5,finaldata)\n",
    "karray[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¾å‡ºå¤§é¡\n",
    "import collections \n",
    "counter = Counter(output);\n",
    "print(counter)\n",
    "def find_maj(sample_class):\n",
    "    counter = Counter(sample_class);\n",
    "    print(counter)\n",
    "    return  list(dict(counter.most_common(1)).keys())\n",
    "\n",
    "fin_maj(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# finaldata æ˜¯ä½¿ç”¨ bupa.xlsx çš„\n",
    "# è®Šæˆ class\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "class RCSMOTE(self,n_nu,sample):\n",
    "    def __init__(self):\n",
    "            \n",
    "    def knn(self,n_nu,sample):\n",
    "        self.n_nu = n_nu;\n",
    "        self.sample = sample;\n",
    "        neighbors=NearestNeighbors(n_neighbors=n_nu+1).fit(sample)\n",
    "\n",
    "        nnarray=neighbors.kneighbors(sample[100].reshape(1,-1),return_distance=False)[0]\n",
    "        return nnarray # å›å‚³ç›¸è¿‘çš„é» åˆ†åˆ¥æ˜¯åœ¨ç¬¬å¹¾å€‹ \n",
    "te = RCSMOTE();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(finaldata[:, 0], finaldata[:, 1], c=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ¤æ–·è©²é»ç‚ºä»€éº¼é¡å‹çš„é» å¦‚æœå…¶\n",
    "# æ­¤ index æ˜¯ 0 é–‹å§‹ æ‰€ä»¥å°ç…§åˆ° excel çš„è¦\n",
    "def check_point_type(n_nu,sample,sample_class,data):\n",
    "    # ä½¿ç”¨ find_maj(find_maj(sample_class)\n",
    "    # ä½¿ç”¨ knn æ‰¾åˆ°é„°è¿‘çš„å¹¾å€‹é» \n",
    "    point_type = [] # æ”¾å€‹é»æ˜¯å±¬æ–¼ä»€éº¼é¡å‹çš„ border safe noisy\n",
    "    n = 0\n",
    "    b = 0\n",
    "    s = 0\n",
    "    maj = find_maj(sample_class) # å¤§é¡\n",
    "    point = knn(n_nu,sample) # å›å‚³æ‰€æœ‰é»é„°è¿‘ n_nu å€‹é»\n",
    "    maj = \"\".join(maj) # maj åŸæœ¬æ˜¯ list è½‰æˆ str\n",
    "    for index,i in enumerate(point):\n",
    "        maj_nu =0;\n",
    "        #if(data.iloc[index,data.shape[1]-1] == maj): # å¦‚æœè©²é»æœ¬èº«æ˜¯å¤§é¡å‰‡ä¸è¨ˆç®—\n",
    "            #continue;\n",
    "        for j in point[index]: # æ¯å€‹é»é„°è¿‘å€‹é»çš„ loop ä¾‹å¦‚ç¬¬ä¸€å€‹é»æ˜¯ [1,2,3,4,5] å‰‡ loop è£¡é¢çš„æ•¸å€¼\n",
    "            if(data.iloc[j,data.shape[1]-1] == maj ): \n",
    "                maj_nu = maj_nu + 1 # è¨ˆç®—é„°è¿‘é»ç‚ºå¤§é¡çš„æœ‰å¤šå°‘æ¥µ\n",
    "        if(maj_nu == n_nu ):\n",
    "            point_type.append(\"noisy\");\n",
    "            n = n+1\n",
    "        elif(n_nu/2 < maj_nu and maj_nu < n_nu ):\n",
    "            point_type.append(\"borders\");\n",
    "            b = b+1\n",
    "        else:\n",
    "            point_type.append(\"safe\");\n",
    "            s = s+1\n",
    "    print(\"noisy\",n,\"\\nborder\",b,\"\\nsafe\",s,\"\\nall\",n+b+s)\n",
    "    return point_type;\n",
    "point_type = check_point_type(3,finaldata,output,data) # è«–æ–‡ä½¿ç”¨ knn ç‚º 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è³‡æ–™é›†è®Šç‚ºå°é¡çš„ border è·Ÿ safe ä»¥åŠ å¤§é¡ å»é™¤ å°é¡ä¸”ç‚º noisy çš„\n",
    "\"\"\"\n",
    "find the maximum value that existed for that attribute among\n",
    "the minority samples of the ğµğ‘† set, and also, find the minimum value that existed for\n",
    "the given attribute among the majority samples set\n",
    "\"\"\"\n",
    "# å…ˆæ˜¯å°é¡å»æ‰ noisy å†ä¾†æ˜¯ å¤§é¡ \n",
    "def split_BS_Majdata(point_type,sample,sample_class):\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # å¤§é¡\n",
    "    maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(sample[i])\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(sample[i])\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "    print(BS_sample)\n",
    "    return return_sample\n",
    "\n",
    "split_BS_Majdata(point_type,finaldata,output)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_split_BS_Majdata(point_type,sample,sample_class): # maj ä»¥åŠ BS set åœ¨åŸæœ¬ data çš„ index\n",
    "    BS_sample = [\"border_safe\"]\n",
    "    Maj_sample = [\"maj11\"]\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # å¤§é¡\n",
    "    maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(i)\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(i)\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "    \n",
    "    return return_sample\n",
    "\n",
    "index_split_BS_Majdata(point_type,finaldata,output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The obtained ranges for\n",
    "all features (attributes) are used to control the location of the new synthetic samples in\n",
    "data space.\n",
    "\n",
    "The set of these ranges is denoted by ğ‘…ğ‘ğ‘›ğ‘”ğ‘’ =\n",
    "(ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’1 ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’2 ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’3 â€¦ ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ) array where ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ is the number of\n",
    "attributes in the dataset\n",
    "\n",
    "å¦‚ä½•ç”¢ç”Ÿ Range array\n",
    "1. we find the maximum value that existed for that attribute among\n",
    "the minority samples of the ğµğ‘† set  ğ‘ƒ _ğ‘šğ‘ğ‘¥ = (ğ‘ğ‘šğ‘ğ‘¥1 ğ‘ğ‘šğ‘ğ‘¥2\n",
    "â€¦ğ‘ğ‘šğ‘ğ‘¥ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ) array\n",
    "\n",
    "2. find the minimum value that existed for\n",
    "the given attribute among the majority samples set  ğ‘ _ğ‘šğ‘–ğ‘› = (ğ‘›ğ‘šğ‘–ğ‘›1 ğ‘›ğ‘šğ‘–ğ‘›2 â€¦ğ‘›ğ‘šğ‘–ğ‘›ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ)array\n",
    "\n",
    "3. Then, the desired ğ‘…ğ‘ğ‘›ğ‘”ğ‘’ vector is obtained as the average of ğ‘_ğ‘šğ‘–ğ‘› and\n",
    "ğ‘ƒ _ğ‘šğ‘ğ‘¥ arrays\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def range_value(sample):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1 p.16\n",
    "knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}