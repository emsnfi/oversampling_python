{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os;\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape[1] # è¡Œæ•¸    data.shape[0] åˆ—æ•¸\n",
    "os.chdir(\"/Users/emily/Desktop/Research/oversampling_python/data/\");\n",
    "print(os.getcwd());\n",
    "\n",
    "data = pd.read_excel(\"bupa.xlsx\")\n",
    "#data.Class= data.Class.str.replace(\"\\n\", \"\").str.strip()\n",
    "data = data.iloc[:,1:]\n",
    "data.shape[1]\n",
    "l = data.shape[1]-1\n",
    "\n",
    "output = np.array(data.iloc[:,l]);\n",
    "finaldata = np.array(data.iloc[:,:l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†ä½ˆ\n",
    "counter = Counter(output)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(output) * 100\n",
    "\tprint(\"class\",k,\"æ•¸é‡ï¼š\",v,\"percentage\",'%.3f' %per,\"%\")\n",
    "\t#print('Class=%s, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()\n",
    "ir = 500/268;\n",
    "print(\"IR \",ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¾å‡º knn\n",
    "def knn(n_nu,sample):\n",
    "     # n_nu è‡ªå·±è¨­å®šå¤šå°‘é„°è¿‘å€‹é»\n",
    "     # input sample æ²’æœ‰åŒ…å« class label\n",
    "        nnarray = []\n",
    "        neighbors=NearestNeighbors(n_neighbors=n_nu+1).fit(sample)\n",
    "        for i in range(len(sample)):\n",
    "            temp = neighbors.kneighbors(sample[i].reshape(1,-1),return_distance=False)[0]\n",
    "            temp = np.delete(temp,0)\n",
    "            # æœ‰ array å­˜æ”¾ å„å€‹é»çš„é„°è¿‘é» \n",
    "            nnarray.append(temp)\n",
    "     \n",
    "        return nnarray # å›å‚³ç›¸è¿‘çš„é» åˆ†åˆ¥æ˜¯åœ¨ç¬¬å¹¾å€‹ \n",
    "karray = knn(3,finaldata)\n",
    "karray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# æ‰¾å‡ºå¤§é¡\n",
    "def find_maj(sample_class):\n",
    "    counter = Counter(sample_class);\n",
    "    maj = list(dict(counter.most_common(1)).keys())\n",
    "    #maj = \"\".join(maj)\n",
    "    return  maj\n",
    "\n",
    "find_maj(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "noisy 23 \nborder 48 \nsafe 74 \nall 145\n"
     ]
    }
   ],
   "source": [
    "# åˆ¤æ–·è©²é»ç‚ºä»€éº¼é¡å‹çš„é» \n",
    "# æ­¤ index æ˜¯ 0 é–‹å§‹ æ‰€ä»¥å°ç…§åˆ° excel çš„è¦\n",
    "# inminority æ˜¯å¦æ˜¯è¦æ±‚åœ¨å°é¡ä¸­çš„ å¦‚æœæ˜¯å‰‡æ”¾ true\n",
    "def check_point_type(n_nu,sample,sample_class,data,inminority):\n",
    "    # ä½¿ç”¨ find_maj(find_maj(sample_class)\n",
    "    # ä½¿ç”¨ knn æ‰¾åˆ°é„°è¿‘çš„å¹¾å€‹é» \n",
    "    point_type = [] # æ”¾å€‹é»æ˜¯å±¬æ–¼ä»€éº¼é¡å‹çš„ border safe noisy\n",
    "    n = 0\n",
    "    b = 0\n",
    "    s = 0\n",
    "    maj = find_maj(sample_class) # å¤§é¡\n",
    "    point = knn(n_nu,sample) # å›å‚³æ‰€æœ‰é»é„°è¿‘ n_nu å€‹é»\n",
    "    #maj = \"\".join(maj) # maj åŸæœ¬æ˜¯ list è½‰æˆ str\n",
    "    for index,i in enumerate(point):\n",
    "        maj_nu =0;\n",
    "        if(data.iloc[index,data.shape[1]-1] == maj and inminority == True): # å¦‚æœè©²é»æœ¬èº«æ˜¯å¤§é¡å‰‡ä¸è¨ˆç®—\n",
    "            continue; # å¦‚æœä½¿ç”¨æ­¤ å‰‡æœƒè·Ÿè«–æ–‡çš„ data ä¸€æ¨£\n",
    "        for j in point[index]: # æ¯å€‹é»é„°è¿‘å€‹é»çš„ loop ä¾‹å¦‚ç¬¬ä¸€å€‹é»æ˜¯ [1,2,3,4,5] å‰‡ loop è£¡é¢çš„æ•¸å€¼\n",
    "            if(data.iloc[j,data.shape[1]-1] == maj ): \n",
    "                maj_nu = maj_nu + 1 # è¨ˆç®—é„°è¿‘é»ç‚ºå¤§é¡çš„æœ‰å¤šå°‘å€‹\n",
    "        if(maj_nu == n_nu ):\n",
    "            point_type.append(\"noisy\");\n",
    "            n = n+1\n",
    "        elif(n_nu/2 < maj_nu and maj_nu < n_nu ):\n",
    "            point_type.append(\"border\");\n",
    "            b = b+1\n",
    "        else:\n",
    "            point_type.append(\"safe\");\n",
    "            s = s+1\n",
    "    print(\"noisy\",n,\"\\nborder\",b,\"\\nsafe\",s,\"\\nall\",n+b+s)\n",
    "    return point_type;\n",
    "point_type = check_point_type(3,finaldata,output,data,True) # è«–æ–‡ä½¿ç”¨ knn ç‚º 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è³‡æ–™é›†è®Šç‚ºå°é¡çš„ border è·Ÿ safe ä»¥åŠ å¤§é¡ å»é™¤ å°é¡ä¸”ç‚º noisy çš„\n",
    "\"\"\"\n",
    "find the maximum value that existed for that attribute among\n",
    "the minority samples of the ğµğ‘† set, and also, find the minimum value that existed for\n",
    "the given attribute among the majority samples set\n",
    "\"\"\"\n",
    "# å…ˆæ˜¯å°é¡å»æ‰ noisy å†ä¾†æ˜¯ å¤§é¡ \n",
    "def split_BS_Majdata(point_type,sample,sample_class):\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # å¤§é¡\n",
    "    #maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(sample[i])\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(sample[i])\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "  \n",
    "    return return_sample\n",
    "point_type = check_point_type(3,finaldata,output,data,False)\n",
    "split_BS_Majdata(point_type,finaldata,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_split_BS_Majdata(point_type,sample,sample_class): # maj ä»¥åŠ BS set åœ¨åŸæœ¬ data çš„ index\n",
    "    BS_sample = []\n",
    "    Maj_sample = []\n",
    "    return_sample = []\n",
    "    maj = find_maj(sample_class) # å¤§é¡\n",
    "    #maj = \"\".join(maj)\n",
    "    for i in range(len(sample_class)):\n",
    "        #print(sample_class[i])\n",
    "        \n",
    "        if(sample_class[i] == maj):\n",
    "            Maj_sample.append(i)\n",
    "            \n",
    "        elif(sample_class[i] != maj and point_type[i] != \"noisy\"):\n",
    "            BS_sample.append(i)\n",
    "    return_sample = np.array([ BS_sample ,Maj_sample ])\n",
    "    \n",
    "    return return_sample\n",
    "point_type = check_point_type(3,finaldata,output,data,False)\n",
    "index_split_BS_Majdata(point_type,finaldata,output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classprocess(output):\n",
    "    c = Counter(output)\n",
    "    datagap = []\n",
    "    maj = find_maj(output)\n",
    "    maj_num = dict(c)[find_maj(output)]\n",
    "    for className, number in counter.items(): \n",
    "        #print(className,\" \",number)\n",
    "        temp = np.array([className,(maj_num - number)])\n",
    "        datagap.append(temp)\n",
    "    return datagap\n",
    "\n",
    "classprocess(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The obtained ranges for\n",
    "all features (attributes) are used to control the location of the new synthetic samples in\n",
    "data space.\n",
    "\n",
    "The set of these ranges is denoted by ğ‘…ğ‘ğ‘›ğ‘”ğ‘’ =\n",
    "(ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’1 ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’2 ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’3 â€¦ ğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ) array where ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ is the number of\n",
    "attributes in the dataset\n",
    "\n",
    "å¦‚ä½•ç”¢ç”Ÿ Range array\n",
    "1. we find the maximum value that existed for that attribute among\n",
    "the minority samples of the ğµğ‘† set  ğ‘ƒ _ğ‘šğ‘ğ‘¥ = (ğ‘ğ‘šğ‘ğ‘¥1 ğ‘ğ‘šğ‘ğ‘¥2\n",
    "â€¦ğ‘ğ‘šğ‘ğ‘¥ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ) array\n",
    "\n",
    "2. find the minimum value that existed for\n",
    "the given attribute among the majority samples set  ğ‘ _ğ‘šğ‘–ğ‘› = (ğ‘›ğ‘šğ‘–ğ‘›1 ğ‘›ğ‘šğ‘–ğ‘›2 â€¦ğ‘›ğ‘šğ‘–ğ‘›ğ‘›ğ‘ğ‘¡ğ‘¡ğ‘Ÿ)array\n",
    "\n",
    "3. Then, the desired ğ‘…ğ‘ğ‘›ğ‘”ğ‘’ vector is obtained as the average of ğ‘_ğ‘šğ‘–ğ‘› and\n",
    "ğ‘ƒ _ğ‘šğ‘ğ‘¥ arrays\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# dataframe[0] è¡Œæ•¸  dataframe[1] åˆ—æ•¸\n",
    "# è©²å±¬æ€§ä¸­ åœ¨ bs set çš„æœ€å¤§å€¼ ä»¥åŠ å¤§é¡ä¸­çš„æœ€å°å€¼\n",
    "# range ç‚ºå…©å€‹ç›¸åŠ é™¤ä»¥ 2\n",
    "# index_split_BS_Majdata å›å‚³ [0] BS set [1] å›å‚³ Maj set\n",
    "def range_value(n_nu,sample,sample_class,data):\n",
    "    point_type = check_point_type(n_nu,sample,sample_class,data,False)\n",
    "    index = index_split_BS_Majdata(point_type,sample,sample_class)\n",
    "    BS_max = []\n",
    "    Maj_min = []\n",
    "    all_value = []\n",
    "    for i in range(len(sample[0])): # loop å±¬æ€§\n",
    "        for j in range(2): # loop data\n",
    "            if(j==0): # BS set çš„ index\n",
    "                BS_index = index[j]\n",
    "                max_value = np.max(sample[BS_index][i]);\n",
    "                BS_max.append(max_value)\n",
    "            else:\n",
    "                Maj_index = index[j]\n",
    "                min_value = np.min(sample[Maj_index][i]);\n",
    "                Maj_min.append(min_value)\n",
    "    # temp = np.array([BS_max,Maj_min]) \n",
    "    range_value = [(BS_max[i] - Maj_min[i])/2 for i in range(len(BS_max))]\n",
    "    all_value = np.array([BS_max,Maj_min,range_value])\n",
    "    return all_value\n",
    "range_value(3,finaldata,output,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bğ‘›ğ‘¢ğ‘š: Number of samples in ğµğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ å±¬æ–¼ border çš„è³‡æ–™æ•¸\n",
    "# compute its(border sample) k nearest neighbors in BS, and save them in BSnn å­˜æ”¾ \n",
    "# compute its(border sample) k nearest neighbors in Maj set, and save them in Majnn\n",
    "def getBSnn_Majnn(n_nu,sample,sample_class,data):     \n",
    "    point_type = check_point_type(n_nu,sample,sample_class,data,False) # å¾—çŸ¥æ‰€æœ‰ sample ä¸­å±¬æ–¼ border çš„  \n",
    "    index = index_split_BS_Majdata(point_type,sample,sample_class) \n",
    "    k = knn(n_nu,sample)\n",
    "    BSnn = []\n",
    "    Majnn = []\n",
    "    # ç”¨ border sample çš„ index \n",
    "    for i,element in enumerate(point_type):\n",
    "        if(element == \"border\"):\n",
    "            for j in range(2):\n",
    "                for w in index[j]:\n",
    "                    if(j == 0 and i == w ):\n",
    "                        BSnn.append(k[w])\n",
    "                    elif(j==1 and i == w):\n",
    "                        Majnn.append(k[w])\n",
    "        \n",
    "    temp = np.array([BSnn,Majnn]);\n",
    "    print(len(temp[0]+temp[1]))\n",
    "    return temp\n",
    "    \n",
    "len(getBSnn_Majnn(3,finaldata,output,data)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆè³‡æ–™\n",
    "\n",
    "def Populate(r,BSnn,Majnn,Range,P_max,sample,classbelong):\n",
    "    # r ä»£è¡¨è¦ç”¢ç”Ÿçš„è³‡æ–™çš„æ•¸é‡ è«–æ–‡å®šç¾©è©²æ•¸é‡ç‚ºå¢åŠ å°é¡è‡³è·Ÿå¤§é¡ç›¸åŒçš„æ•¸é‡ é”æˆ 50% (å¤§é¡æ¸›å°é¡çš„æ•¸é‡)\n",
    "    Bl = len(BSnn)-1\n",
    "    nn_nu = len(BSnn[0])-1\n",
    "    Ml = len(Majnn)-1\n",
    "    Synthetic = []\n",
    "    while(r > 0):\n",
    "\n",
    "        s1row = random.randint(0,Bl)\n",
    "        s1col = random.randint(0,nn_nu)\n",
    "        s1 = BSnn[s1row][s1col]\n",
    "        s2row = random.randint(0,Ml)\n",
    "        s2col = random.randint(0,nn_nu)\n",
    "        s2 = Majnn[s2row][s2col]\n",
    "        min_attr = []\n",
    "        for i in range(len(sample[0])):\n",
    "        \n",
    "            if(sample[s1][i] < sample[s2][i]):\n",
    "                min_attr.append(sample[s1][i])\n",
    "            else:\n",
    "                min_attr.append(sample[s2][i])\n",
    "        diff = [(P_max[i] - min_attr[i]) for i in range(len(P_max))]\n",
    "        #print(\"diff\",diff)\n",
    "        gap = random.uniform(0,0.5)\n",
    "        var = [(diff[i] * gap ) for i in range(len(diff))]\n",
    "        temp = []\n",
    "        for i in range(len(sample[0])):\n",
    "            if(min_attr[i]+var[i] <= Range[i]):\n",
    "                temp.append(min_attr[i]+var[i])\n",
    "            else:\n",
    "                temp.append(P_max[i]-var[i])\n",
    "        temp.append(classbelong)\n",
    "        Synthetic.append(temp)   \n",
    "        r = r-1\n",
    "    return Synthetic\n",
    "    \n",
    "needToGenerate = 232\n",
    "BSnn = getBSnn_Majnn(3,finaldata,output,data)[0]\n",
    "Majnn = getBSnn_Majnn(3,finaldata,output,data)[1]\n",
    "Range = range_value(3,finaldata,output,data)\n",
    "P_max = range_value(3,finaldata,output,data)[0]\n",
    "Range = range_value(3,finaldata,output,data)[2]\n",
    "#Populate(needToGenerate,BSnn,Majnn,Range,P_max,finaldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¯å€‹é¡åˆ¥éƒ½è¦ é€²è¡Œ populate é‡å°å¤šé¡åˆ¥\n",
    "alldata = data.T\n",
    "classCount = classprocess(output)\n",
    "index = 1\n",
    "for i in range(len(classCount)):\n",
    "    #print(int(classCount[i][1]))\n",
    "    if(int(classCount[i][1]) > 0):\n",
    "        over = Populate(int(classCount[i][1]),BSnn,Majnn,Range,P_max,finaldata,classCount[i][0])\n",
    "        length = alldata.shape[1]\n",
    "        for j in range(len(over)):\n",
    "            alldata[length+j] = over[j]\n",
    "alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = alldata.T.iloc[:,:alldata.shape[0]]\n",
    "y = alldata.T.iloc[:,alldata.shape[0]-1]\n",
    "overc = Counter(y)\n",
    "for i,v in overc.items():\n",
    "    print(\"class\",i,\"number\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸€èˆ¬ SMOTE\n",
    "print(\"SMOTE\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from numpy import mean\n",
    "modelD = DecisionTreeClassifier()\n",
    "modelR = RandomForestClassifier(n_estimators=1000)\n",
    "over = SMOTE()\n",
    "X_smote,y_smote = over.fit_resample(finaldata,output)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scoresRandomForest = cross_val_score(modelR, X_smote,y_smote, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "scoresDecisionTree = cross_val_score(modelD, X_smote,y_smote, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC for RandomForest: %.3f' % mean(scoresRandomForest))\n",
    "print('Mean ROC AUC for DecisionTree: %.3f' % mean(scoresDecisionTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RCSMOTE\n",
    "print(\"RCSMOTE\")\n",
    "X = alldata.T.iloc[:,:alldata.shape[0]-1]\n",
    "y = alldata.T.iloc[:,alldata.shape[0]-1]\n",
    "modelD = DecisionTreeClassifier()\n",
    "modelR = RandomForestClassifier(n_estimators=1000)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scoresRandomForest = cross_val_score(modelR, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "scoresDecisionTree = cross_val_score(modelD, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC for RandomForest: %.3f' % mean(scoresRandomForest))\n",
    "print('Mean ROC AUC for DecisionTree: %.3f' % mean(scoresDecisionTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borderline\n",
    "print(\"Borderline\")\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "stepR = [('border_line', BorderlineSMOTE(random_state=42,kind=\"borderline-1\")), ('model', RandomForestClassifier(n_estimators=1000))] # RandomForestClassifier(n_estimators=1000)\n",
    "stepD = [('border_line', BorderlineSMOTE(random_state=42,kind=\"borderline-1\")), ('model', DecisionTreeClassifier())] \n",
    "pipelineD = Pipeline(steps=stepD)\n",
    "pipelineR = Pipeline(steps=stepR)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scoresDecisionTree = cross_val_score(pipelineD, finaldata, output, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "scoresRandomForest = cross_val_score(pipelineR, finaldata, output, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC for RandomForest: %.3f' % mean(scoresRandomForest))\n",
    "print('Mean ROC AUC for DecisionTree: %.3f' % mean(scoresDecisionTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}