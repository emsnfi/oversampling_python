{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from typing_extensions import final\n",
    "from Py_FS.wrapper.nature_inspired import GA\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# from Py_FS.wrapper.nature_inspired._utilities import Solution, Data, initialize, sort_agents, display, compute_fitness, Conv_plot\n",
    "\n",
    "# from Py_FS.wrapper.nature_inspired._utilities import Solution, Data, initialize, sort_agents, display, compute_fitness, Conv_plot\n",
    "# import ga\n",
    "\n",
    "# data = datasets.load_iris()\n",
    "# d = GA(20, 100, data.data, data.target)\n",
    "'''\n",
    "Py FS.wrapper.nature inspired.GA(num agents, max iter, train data,\n",
    "train label, obj function=compute fitness, trans function shape=‘s’, prob cross=0.4,\n",
    "prob mut=0.3, save conv graph=False)\n",
    "'''\n",
    "# First: oversampling  Second: feature selection\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import smote_variants as sv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import statistics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from collections import Counter\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "import matplotlib.pyplot as pl\n",
    "import random\n",
    "\n",
    "from sklearn import svm, ensemble\n",
    "# package\n",
    "from numpy.core.fromnumeric import mean, size\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font\n",
    "from sklearn import tree\n",
    "\n",
    "from itertools import permutations\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import statistics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm, ensemble\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import statistics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from collections import Counter\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "import matplotlib.pyplot as pl\n",
    "import random\n",
    "\n",
    "from sklearn import svm, ensemble\n",
    "from imblearn.over_sampling._smote.base import SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import smote_variants as sv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car</td>\n",
       "      <td>1.27</td>\n",
       "      <td>91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>231.38</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.47</td>\n",
       "      <td>207.92</td>\n",
       "      <td>241.74</td>\n",
       "      <td>244.48</td>\n",
       "      <td>...</td>\n",
       "      <td>26.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.29</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>56</td>\n",
       "      <td>3806.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.36</td>\n",
       "      <td>241</td>\n",
       "      <td>1.56</td>\n",
       "      <td>216.15</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.51</td>\n",
       "      <td>187.85</td>\n",
       "      <td>229.39</td>\n",
       "      <td>231.20</td>\n",
       "      <td>...</td>\n",
       "      <td>22.29</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.42</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1746</td>\n",
       "      <td>1450.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.12</td>\n",
       "      <td>266</td>\n",
       "      <td>1.47</td>\n",
       "      <td>232.18</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.21</td>\n",
       "      <td>206.54</td>\n",
       "      <td>244.22</td>\n",
       "      <td>245.79</td>\n",
       "      <td>...</td>\n",
       "      <td>15.59</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>566</td>\n",
       "      <td>1094.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.42</td>\n",
       "      <td>399</td>\n",
       "      <td>1.28</td>\n",
       "      <td>230.40</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.73</td>\n",
       "      <td>204.60</td>\n",
       "      <td>243.27</td>\n",
       "      <td>243.32</td>\n",
       "      <td>...</td>\n",
       "      <td>13.51</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.44</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1178</td>\n",
       "      <td>1125.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.15</td>\n",
       "      <td>944</td>\n",
       "      <td>1.73</td>\n",
       "      <td>193.18</td>\n",
       "      <td>2.28</td>\n",
       "      <td>4.10</td>\n",
       "      <td>165.98</td>\n",
       "      <td>205.55</td>\n",
       "      <td>208.00</td>\n",
       "      <td>...</td>\n",
       "      <td>15.65</td>\n",
       "      <td>50.08</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>6232</td>\n",
       "      <td>1146.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>car</td>\n",
       "      <td>1.43</td>\n",
       "      <td>39</td>\n",
       "      <td>1.41</td>\n",
       "      <td>234.03</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.60</td>\n",
       "      <td>206.36</td>\n",
       "      <td>246.05</td>\n",
       "      <td>249.69</td>\n",
       "      <td>...</td>\n",
       "      <td>55.92</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>66</td>\n",
       "      <td>2469.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>soil</td>\n",
       "      <td>1.92</td>\n",
       "      <td>141</td>\n",
       "      <td>1.24</td>\n",
       "      <td>215.19</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>212.28</td>\n",
       "      <td>216.28</td>\n",
       "      <td>217.00</td>\n",
       "      <td>...</td>\n",
       "      <td>18.91</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.06</td>\n",
       "      <td>990</td>\n",
       "      <td>824.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>grass</td>\n",
       "      <td>2.97</td>\n",
       "      <td>252</td>\n",
       "      <td>1.73</td>\n",
       "      <td>164.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.09</td>\n",
       "      <td>184.15</td>\n",
       "      <td>152.03</td>\n",
       "      <td>156.22</td>\n",
       "      <td>...</td>\n",
       "      <td>33.52</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.71</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.06</td>\n",
       "      <td>948</td>\n",
       "      <td>821.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>grass</td>\n",
       "      <td>1.57</td>\n",
       "      <td>216</td>\n",
       "      <td>1.27</td>\n",
       "      <td>164.84</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.97</td>\n",
       "      <td>192.55</td>\n",
       "      <td>148.34</td>\n",
       "      <td>153.62</td>\n",
       "      <td>...</td>\n",
       "      <td>24.49</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.09</td>\n",
       "      <td>254</td>\n",
       "      <td>1580.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.12</td>\n",
       "      <td>836</td>\n",
       "      <td>0.88</td>\n",
       "      <td>232.84</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.52</td>\n",
       "      <td>202.39</td>\n",
       "      <td>247.24</td>\n",
       "      <td>248.89</td>\n",
       "      <td>...</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7.16</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>3020</td>\n",
       "      <td>1611.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         class  BrdIndx  Area  Round  Bright  Compact  ShpIndx  Mean_G  \\\n",
       "0         car      1.27    91   0.97  231.38     1.39     1.47  207.92   \n",
       "1    concrete      2.36   241   1.56  216.15     2.46     2.51  187.85   \n",
       "2    concrete      2.12   266   1.47  232.18     2.07     2.21  206.54   \n",
       "3    concrete      2.42   399   1.28  230.40     2.49     2.73  204.60   \n",
       "4    concrete      2.15   944   1.73  193.18     2.28     4.10  165.98   \n",
       "..         ...      ...   ...    ...     ...      ...      ...     ...   \n",
       "163       car      1.43    39   1.41  234.03     1.54     1.60  206.36   \n",
       "164      soil      1.92   141   1.24  215.19     2.02     2.02  212.28   \n",
       "165     grass      2.97   252   1.73  164.13     3.20     3.09  184.15   \n",
       "166     grass      1.57   216   1.27  164.84     1.71     1.97  192.55   \n",
       "167  concrete      2.12   836   0.88  232.84     1.78     2.52  202.39   \n",
       "\n",
       "     Mean_R  Mean_NIR  ...  SD_NIR_140  LW_140  GLCM1_140  Rect_140  \\\n",
       "0    241.74    244.48  ...       26.18    2.00       0.50      0.85   \n",
       "1    229.39    231.20  ...       22.29    2.25       0.79      0.55   \n",
       "2    244.22    245.79  ...       15.59    2.19       0.76      0.74   \n",
       "3    243.27    243.32  ...       13.51    3.34       0.82      0.74   \n",
       "4    205.55    208.00  ...       15.65   50.08       0.85      0.49   \n",
       "..      ...       ...  ...         ...     ...        ...       ...   \n",
       "163  246.05    249.69  ...       55.92    1.73       0.65      0.81   \n",
       "164  216.28    217.00  ...       18.91    3.49       0.88      0.67   \n",
       "165  152.03    156.22  ...       33.52    2.02       0.86      0.71   \n",
       "166  148.34    153.62  ...       24.49    1.13       0.76      0.85   \n",
       "167  247.24    248.89  ...        7.84    1.52       0.76      0.24   \n",
       "\n",
       "     GLCM2_140  Dens_140  Assym_140  NDVI_140  BordLngth_140  GLCM3_140  \n",
       "0         6.29      1.67       0.70     -0.08             56    3806.36  \n",
       "1         8.42      1.38       0.81     -0.09           1746    1450.14  \n",
       "2         7.24      1.68       0.81     -0.07            566    1094.04  \n",
       "3         7.44      1.36       0.92     -0.09           1178    1125.38  \n",
       "4         8.15      0.23       1.00     -0.08           6232    1146.38  \n",
       "..         ...       ...        ...       ...            ...        ...  \n",
       "163       7.05      1.89       0.42     -0.10             66    2469.69  \n",
       "164       7.88      1.44       0.82      0.06            990     824.01  \n",
       "165       8.50      1.82       0.54      0.06            948     821.84  \n",
       "166       7.75      2.11       0.30      0.09            254    1580.72  \n",
       "167       7.16      0.74       0.49     -0.09           3020    1611.55  \n",
       "\n",
       "[168 rows x 148 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "dfmulti =  pd.read_csv('/Users/emily/Desktop/Urban_land_cover/training.csv') # /Users/emily/Desktop/Urban_land_cover/training.csv' /Users/emily/Desktop/arrhythmia.xlsx /Users/emily/Desktop/meu-mobile-ksd-2016.xlsx \n",
    "dfmulti.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "dfmulti['class'] = labelencoder.fit_transform(dfmulti['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "dfmulti['Classes'] = labelencoder.fit_transform(dfmulti['Classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.27</td>\n",
       "      <td>91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>231.38</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.47</td>\n",
       "      <td>207.92</td>\n",
       "      <td>241.74</td>\n",
       "      <td>244.48</td>\n",
       "      <td>...</td>\n",
       "      <td>26.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.29</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>56</td>\n",
       "      <td>3806.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.36</td>\n",
       "      <td>241</td>\n",
       "      <td>1.56</td>\n",
       "      <td>216.15</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.51</td>\n",
       "      <td>187.85</td>\n",
       "      <td>229.39</td>\n",
       "      <td>231.20</td>\n",
       "      <td>...</td>\n",
       "      <td>22.29</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.42</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1746</td>\n",
       "      <td>1450.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.12</td>\n",
       "      <td>266</td>\n",
       "      <td>1.47</td>\n",
       "      <td>232.18</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.21</td>\n",
       "      <td>206.54</td>\n",
       "      <td>244.22</td>\n",
       "      <td>245.79</td>\n",
       "      <td>...</td>\n",
       "      <td>15.59</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>566</td>\n",
       "      <td>1094.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.42</td>\n",
       "      <td>399</td>\n",
       "      <td>1.28</td>\n",
       "      <td>230.40</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.73</td>\n",
       "      <td>204.60</td>\n",
       "      <td>243.27</td>\n",
       "      <td>243.32</td>\n",
       "      <td>...</td>\n",
       "      <td>13.51</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.44</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1178</td>\n",
       "      <td>1125.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.15</td>\n",
       "      <td>944</td>\n",
       "      <td>1.73</td>\n",
       "      <td>193.18</td>\n",
       "      <td>2.28</td>\n",
       "      <td>4.10</td>\n",
       "      <td>165.98</td>\n",
       "      <td>205.55</td>\n",
       "      <td>208.00</td>\n",
       "      <td>...</td>\n",
       "      <td>15.65</td>\n",
       "      <td>50.08</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>6232</td>\n",
       "      <td>1146.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2</td>\n",
       "      <td>1.43</td>\n",
       "      <td>39</td>\n",
       "      <td>1.41</td>\n",
       "      <td>234.03</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.60</td>\n",
       "      <td>206.36</td>\n",
       "      <td>246.05</td>\n",
       "      <td>249.69</td>\n",
       "      <td>...</td>\n",
       "      <td>55.92</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.81</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>66</td>\n",
       "      <td>2469.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>7</td>\n",
       "      <td>1.92</td>\n",
       "      <td>141</td>\n",
       "      <td>1.24</td>\n",
       "      <td>215.19</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>212.28</td>\n",
       "      <td>216.28</td>\n",
       "      <td>217.00</td>\n",
       "      <td>...</td>\n",
       "      <td>18.91</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.06</td>\n",
       "      <td>990</td>\n",
       "      <td>824.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>4</td>\n",
       "      <td>2.97</td>\n",
       "      <td>252</td>\n",
       "      <td>1.73</td>\n",
       "      <td>164.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.09</td>\n",
       "      <td>184.15</td>\n",
       "      <td>152.03</td>\n",
       "      <td>156.22</td>\n",
       "      <td>...</td>\n",
       "      <td>33.52</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.71</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.06</td>\n",
       "      <td>948</td>\n",
       "      <td>821.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>4</td>\n",
       "      <td>1.57</td>\n",
       "      <td>216</td>\n",
       "      <td>1.27</td>\n",
       "      <td>164.84</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.97</td>\n",
       "      <td>192.55</td>\n",
       "      <td>148.34</td>\n",
       "      <td>153.62</td>\n",
       "      <td>...</td>\n",
       "      <td>24.49</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.09</td>\n",
       "      <td>254</td>\n",
       "      <td>1580.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>3</td>\n",
       "      <td>2.12</td>\n",
       "      <td>836</td>\n",
       "      <td>0.88</td>\n",
       "      <td>232.84</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.52</td>\n",
       "      <td>202.39</td>\n",
       "      <td>247.24</td>\n",
       "      <td>248.89</td>\n",
       "      <td>...</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7.16</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>3020</td>\n",
       "      <td>1611.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  BrdIndx  Area  Round  Bright  Compact  ShpIndx  Mean_G  Mean_R  \\\n",
       "0        2     1.27    91   0.97  231.38     1.39     1.47  207.92  241.74   \n",
       "1        3     2.36   241   1.56  216.15     2.46     2.51  187.85  229.39   \n",
       "2        3     2.12   266   1.47  232.18     2.07     2.21  206.54  244.22   \n",
       "3        3     2.42   399   1.28  230.40     2.49     2.73  204.60  243.27   \n",
       "4        3     2.15   944   1.73  193.18     2.28     4.10  165.98  205.55   \n",
       "..     ...      ...   ...    ...     ...      ...      ...     ...     ...   \n",
       "163      2     1.43    39   1.41  234.03     1.54     1.60  206.36  246.05   \n",
       "164      7     1.92   141   1.24  215.19     2.02     2.02  212.28  216.28   \n",
       "165      4     2.97   252   1.73  164.13     3.20     3.09  184.15  152.03   \n",
       "166      4     1.57   216   1.27  164.84     1.71     1.97  192.55  148.34   \n",
       "167      3     2.12   836   0.88  232.84     1.78     2.52  202.39  247.24   \n",
       "\n",
       "     Mean_NIR  ...  SD_NIR_140  LW_140  GLCM1_140  Rect_140  GLCM2_140  \\\n",
       "0      244.48  ...       26.18    2.00       0.50      0.85       6.29   \n",
       "1      231.20  ...       22.29    2.25       0.79      0.55       8.42   \n",
       "2      245.79  ...       15.59    2.19       0.76      0.74       7.24   \n",
       "3      243.32  ...       13.51    3.34       0.82      0.74       7.44   \n",
       "4      208.00  ...       15.65   50.08       0.85      0.49       8.15   \n",
       "..        ...  ...         ...     ...        ...       ...        ...   \n",
       "163    249.69  ...       55.92    1.73       0.65      0.81       7.05   \n",
       "164    217.00  ...       18.91    3.49       0.88      0.67       7.88   \n",
       "165    156.22  ...       33.52    2.02       0.86      0.71       8.50   \n",
       "166    153.62  ...       24.49    1.13       0.76      0.85       7.75   \n",
       "167    248.89  ...        7.84    1.52       0.76      0.24       7.16   \n",
       "\n",
       "     Dens_140  Assym_140  NDVI_140  BordLngth_140  GLCM3_140  \n",
       "0        1.67       0.70     -0.08             56    3806.36  \n",
       "1        1.38       0.81     -0.09           1746    1450.14  \n",
       "2        1.68       0.81     -0.07            566    1094.04  \n",
       "3        1.36       0.92     -0.09           1178    1125.38  \n",
       "4        0.23       1.00     -0.08           6232    1146.38  \n",
       "..        ...        ...       ...            ...        ...  \n",
       "163      1.89       0.42     -0.10             66    2469.69  \n",
       "164      1.44       0.82      0.06            990     824.01  \n",
       "165      1.82       0.54      0.06            948     821.84  \n",
       "166      2.11       0.30      0.09            254    1580.72  \n",
       "167      0.74       0.49     -0.09           3020    1611.55  \n",
       "\n",
       "[168 rows x 148 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for \n",
    "col = np.array(dfmulti.iloc[3,:])\n",
    "df = dfmulti.iloc[4:,:]\n",
    "df2 = df.set_axis(col, axis=1, inplace=False)\n",
    "# df.set_index(col, inplace = True)\n",
    "df2.reset_index(inplace=True)\n",
    "X,y = df2.iloc[:,2:],df2.iloc[:,1]\n",
    "# # c = Counter(y)\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 29, 1: 7, 3: 12, 6: 16, 0: 2, 4: 3, 2: 1})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = dfmulti.iloc[:,:-1],dfmulti.iloc[:,-1]\n",
    "c = Counter(y)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>d 5100-0</th>\n",
       "      <th>d 5100-1</th>\n",
       "      <th>d 5100-2</th>\n",
       "      <th>d 5100-3</th>\n",
       "      <th>d 5100-4</th>\n",
       "      <th>d 5100-8</th>\n",
       "      <th>d 5100-9</th>\n",
       "      <th>d 5101-0</th>\n",
       "      <th>...</th>\n",
       "      <th>d 57022-4</th>\n",
       "      <th>d 57022-8</th>\n",
       "      <th>d 57022-9</th>\n",
       "      <th>d 571-0</th>\n",
       "      <th>d 571-1</th>\n",
       "      <th>d 571-2</th>\n",
       "      <th>d 571-3</th>\n",
       "      <th>d 571-4</th>\n",
       "      <th>d 571-8</th>\n",
       "      <th>d 571-9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender  Age  d 5100-0  d 5100-1  d 5100-2  d 5100-3  d 5100-4  d 5100-8  \\\n",
       "0        0   18         0         0         0         0         1         0   \n",
       "1        0   22         0         0         0         0         1         0   \n",
       "2        0   18         0         0         0         1         0         0   \n",
       "3        1   18         0         0         0         0         1         0   \n",
       "4        0   19         0         0         0         0         1         0   \n",
       "..     ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "65       1   15         0         0         1         0         0         0   \n",
       "66       0    9         0         0         1         0         0         0   \n",
       "67       1    8         0         0         0         1         0         0   \n",
       "68       1    8         0         0         0         1         0         0   \n",
       "69       1   14         0         0         0         1         0         0   \n",
       "\n",
       "    d 5100-9  d 5101-0  ...  d 57022-4  d 57022-8  d 57022-9  d 571-0  \\\n",
       "0          0         0  ...          0          0          0        0   \n",
       "1          0         0  ...          0          0          0        0   \n",
       "2          0         0  ...          0          0          0        0   \n",
       "3          0         0  ...          0          0          0        0   \n",
       "4          0         0  ...          0          0          0        0   \n",
       "..       ...       ...  ...        ...        ...        ...      ...   \n",
       "65         0         0  ...          0          0          0        0   \n",
       "66         0         0  ...          0          0          0        1   \n",
       "67         0         0  ...          0          0          0        0   \n",
       "68         0         0  ...          0          0          0        0   \n",
       "69         0         0  ...          0          0          0        0   \n",
       "\n",
       "    d 571-1  d 571-2  d 571-3  d 571-4  d 571-8  d 571-9  \n",
       "0         0        0        0        1        0        0  \n",
       "1         0        0        1        0        0        0  \n",
       "2         0        0        1        0        0        0  \n",
       "3         0        1        0        0        0        0  \n",
       "4         0        1        0        0        0        0  \n",
       "..      ...      ...      ...      ...      ...      ...  \n",
       "65        1        0        0        0        0        0  \n",
       "66        0        0        0        0        0        0  \n",
       "67        0        1        0        0        0        0  \n",
       "68        0        0        1        0        0        0  \n",
       "69        0        1        0        0        0        0  \n",
       "\n",
       "[70 rows x 205 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train data cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ nan  nan  nan  nan 0.79]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 200, in __call__\n",
      "    sample_weight=sample_weight)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 288, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\", line 538, in roc_auc_score\n",
      "    multi_class, average, sample_weight)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\", line 632, in _multiclass_roc_auc_score\n",
      "    \"Number of classes in y_true not equal to the number of \"\n",
      "ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "\n",
      "  UserWarning,\n",
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 200, in __call__\n",
      "    sample_weight=sample_weight)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 288, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\", line 538, in roc_auc_score\n",
      "    multi_class, average, sample_weight)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\", line 632, in _multiclass_roc_auc_score\n",
      "    \"Number of classes in y_true not equal to the number of \"\n",
      "ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "\n",
      "  UserWarning,\n",
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 200, in __call__\n",
      "    sample_weight=sample_weight)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 288, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\", line 538, in roc_auc_score\n",
      "    multi_class, average, sample_weight)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\", line 632, in _multiclass_roc_auc_score\n",
      "    \"Number of classes in y_true not equal to the number of \"\n",
      "ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "\n",
      "  UserWarning,\n",
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 200, in __call__\n",
      "    sample_weight=sample_weight)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 288, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\", line 538, in roc_auc_score\n",
      "    multi_class, average, sample_weight)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\", line 632, in _multiclass_roc_auc_score\n",
      "    \"Number of classes in y_true not equal to the number of \"\n",
      "ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "myscore = make_scorer(roc_auc_score, multi_class='ovo',needs_proba=True)\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X, y)\n",
    "\n",
    "s = cross_validate(clf, X, y, cv=5, scoring = myscore)\n",
    "scores = s['test_score']\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def foldval(df):\n",
    "\n",
    "    X = np.array(df.iloc[:, 1:])\n",
    "    y = np.array(df.iloc[:, 0])\n",
    "    # kfold = KFold(n_splits=5)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accuracyDe = []\n",
    "    for train_ix, test_ix in kfold.split(X, y):\n",
    "        # select rows\n",
    "       \n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        clf = DecisionTreeClassifier().fit(train_X, train_y)\n",
    "        \n",
    "        # roc_auc_score(test_y, clf.predict_proba(test_X),multi_class='ovr')\n",
    "        accuracyDe.append(roc_auc_score(test_y, clf.predict_proba(test_X),multi_class=\"ovr\",average='macro'))\n",
    "        \n",
    "    print(accuracyDe)\n",
    "    meanDe = statistics.mean(accuracyDe)\n",
    "    return meanDe\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9333250937255387, 0.8463308732218633, 0.9111539276444728, 0.8504105090311986, 0.7742559503373988]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8630952707920944"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldval(dfmulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 29, 1: 7, 3: 12, 6: 16, 0: 2, 4: 3, 2: 1})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(y)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([ 0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 12, 16, 17, 18, 19, 21, 22,\\n            23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44,\\n            45, 46, 47, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\\n            64, 65, 66, 67, 68],\\n           dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-18112e507c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# c = Counter(test_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3049\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3050\u001b[0m             indexer = self.loc._get_listlike_indexer(\n\u001b[0;32m-> 3051\u001b[0;31m                 key, axis=1, raise_missing=True)[1]\n\u001b[0m\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3053\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([ 0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 12, 16, 17, 18, 19, 21, 22,\\n            23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44,\\n            45, 46, 47, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\\n            64, 65, 66, 67, 68],\\n           dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=40)\n",
    "    accuracyDe = []\n",
    "    for train_ix, test_ix in kfold.split(X, y):\n",
    "        # select rows\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes in y_true not equal to the number of columns in 'y_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-2568d7e97727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfoldval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfmulti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-0b9eaaba1c54>\u001b[0m in \u001b[0;36mfoldval\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# roc_auc_score(test_y, clf.predict_proba(test_X),multi_class='ovr')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0maccuracyDe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ovr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracyDe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[0;32m--> 538\u001b[0;31m                                          multi_class, average, sample_weight)\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             raise ValueError(\n\u001b[0;32m--> 632\u001b[0;31m                 \u001b[0;34m\"Number of classes in y_true not equal to the number of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m                 \"columns in 'y_score'\")\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes in y_true not equal to the number of columns in 'y_score'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [ 7 14 18 19 20 21 22 23 24 25 26 27 29 30 31 32 33 34 35 36 37 38 40 41\n",
      " 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65\n",
      " 66 67 68 69] | test: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 15 16 17 28 39]\n",
      "Train: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 15 16 17 22 28 31 34 35 36 38 39\n",
      " 40 41 42 43 44 45 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64\n",
      " 65 67 68 69] | test: [ 7 14 18 19 20 21 23 24 25 26 27 29 30 32 33 37 46 66]\n",
      "Train: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 23 24\n",
      " 25 26 27 28 29 30 32 33 37 39 44 46 47 49 50 55 56 57 58 59 60 62 63 64\n",
      " 65 66 67 68 69] | test: [22 31 34 35 36 38 40 41 42 43 45 48 51 52 53 54 61]\n",
      "Train: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 45 46 48 51\n",
      " 52 53 54 61 66] | test: [44 47 49 50 55 56 57 58 59 60 62 63 64 65 67 68 69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "sfolder = StratifiedKFold(n_splits=4)\n",
    "for train, test in sfolder.split(X,y):\n",
    "    print('Train: %s | test: %s' % (train, test))\n",
    "    clf = DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 29, 1: 25, 3: 23, 8: 17, 6: 16, 2: 15, 5: 15, 0: 14, 7: 14})\n",
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
      "TRAIN: [  0   1   2   3   5   6   8   9  10  11  14  15  17  18  19  21  22  23\n",
      "  25  27  28  29  32  35  36  37  38  39  40  41  42  45  46  47  48  49\n",
      "  50  51  52  53  55  57  58  59  60  62  64  65  66  67  68  70  71  72\n",
      "  73  74  75  76  79  80  81  82  83  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 110 111 112 115\n",
      " 116 118 119 120 121 122 123 124 125 126 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 145 146 147 148 149 150 151 152 153 154\n",
      " 155 160 161 162 163 165 166 167] TEST: [  4   7  12  13  16  20  24  26  30  31  33  34  43  44  54  56  61  63\n",
      "  69  77  78  84  85 109 113 114 117 127 144 156 157 158 159 164]\n",
      "y_prob  (34, 9)\n",
      "y_test  (34,)\n",
      "X_test  (34, 147)\n",
      "0.9334486878424588\n",
      "TRAIN: [  0   1   2   3   4   6   7   8   9  10  12  13  15  16  17  19  20  21\n",
      "  22  23  24  26  27  29  30  31  32  33  34  35  36  37  38  39  41  42\n",
      "  43  44  45  46  48  49  52  54  55  56  57  59  60  61  62  63  64  65\n",
      "  67  69  71  72  73  75  76  77  78  80  82  83  84  85  86  87  88  90\n",
      "  91  93  95  97  98 100 101 104 105 108 109 111 112 113 114 115 117 118\n",
      " 119 120 121 122 123 125 126 127 128 129 130 132 134 135 136 137 138 139\n",
      " 140 141 142 143 144 145 146 147 148 149 150 152 153 154 155 156 157 158\n",
      " 159 160 161 162 163 164 165 166] TEST: [  5  11  14  18  25  28  40  47  50  51  53  58  66  68  70  74  79  81\n",
      "  89  92  94  96  99 102 103 106 107 110 116 124 131 133 151 167]\n",
      "y_prob  (34, 9)\n",
      "y_test  (34,)\n",
      "X_test  (34, 147)\n",
      "0.8887442543449217\n",
      "TRAIN: [  0   1   4   5   6   7   8   9  10  11  12  13  14  15  16  18  19  20\n",
      "  21  22  24  25  26  27  28  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  46  47  50  51  52  53  54  55  56  57  58  61  62  63\n",
      "  64  65  66  68  69  70  72  74  75  77  78  79  81  83  84  85  86  87\n",
      "  89  90  91  92  93  94  95  96  97  99 100 102 103 104 106 107 109 110\n",
      " 111 112 113 114 116 117 118 120 121 122 124 125 126 127 128 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 143 144 145 148 151 152 154 155 156\n",
      " 157 158 159 161 162 164 166 167] TEST: [  2   3  17  23  29  45  48  49  59  60  67  71  73  76  80  82  88  98\n",
      " 101 105 108 115 119 123 129 142 146 147 149 150 153 160 163 165]\n",
      "y_prob  (34, 9)\n",
      "y_test  (34,)\n",
      "X_test  (34, 147)\n",
      "0.8703406489279683\n",
      "TRAIN: [  1   2   3   4   5   7   8   9  11  12  13  14  15  16  17  18  19  20\n",
      "  23  24  25  26  27  28  29  30  31  33  34  39  40  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  63  65  66  67\n",
      "  68  69  70  71  72  73  74  76  77  78  79  80  81  82  84  85  86  88\n",
      "  89  91  92  93  94  95  96  97  98  99 101 102 103 105 106 107 108 109\n",
      " 110 112 113 114 115 116 117 119 121 122 123 124 125 126 127 129 130 131\n",
      " 132 133 134 135 138 140 142 144 146 147 149 150 151 153 154 155 156 157\n",
      " 158 159 160 161 162 163 164 165 167] TEST: [  0   6  10  21  22  32  35  36  37  38  41  42  62  64  75  83  87  90\n",
      " 100 104 111 118 120 128 136 137 139 141 143 145 148 152 166]\n",
      "y_prob  (33, 9)\n",
      "y_test  (33,)\n",
      "X_test  (33, 147)\n",
      "0.8588715562853495\n",
      "TRAIN: [  0   2   3   4   5   6   7  10  11  12  13  14  16  17  18  20  21  22\n",
      "  23  24  25  26  28  29  30  31  32  33  34  35  36  37  38  40  41  42\n",
      "  43  44  45  47  48  49  50  51  53  54  56  58  59  60  61  62  63  64\n",
      "  66  67  68  69  70  71  73  74  75  76  77  78  79  80  81  82  83  84\n",
      "  85  87  88  89  90  92  94  96  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 113 114 115 116 117 118 119 120 123 124 127 128 129 131\n",
      " 133 136 137 139 141 142 143 144 145 146 147 148 149 150 151 152 153 156\n",
      " 157 158 159 160 163 164 165 166 167] TEST: [  1   8   9  15  19  27  39  46  52  55  57  65  72  86  91  93  95  97\n",
      " 112 121 122 125 126 130 132 134 135 138 140 154 155 161 162]\n",
      "y_prob  (33, 9)\n",
      "y_test  (33,)\n",
      "X_test  (33, 147)\n",
      "0.7677151731069665\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.array(dfmulti.iloc[:, 1:])\n",
    "y = np.array(dfmulti.iloc[:, 0])\n",
    "print(Counter(y))\n",
    "skf = StratifiedKFold(n_splits=5,random_state=42,shuffle=True)\n",
    "skf.get_n_splits(X, y)\n",
    "accuracyDe = []\n",
    "print(skf)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    print('y_prob ', y_prob.shape)\n",
    "    print('y_test ', y_test.shape)\n",
    "    print('X_test ', X_test.shape)\n",
    "    print(roc_auc_score(y_test, clf.predict_proba(X_test),multi_class='ovr'))\n",
    "        # roc_auc_score(test_y, clf.predict_proba(test_X),multi_class='ovr')\n",
    "    # accuracyDe.append(roc_auc_score(y_test, clf.predict_proba(X_test),multi_class=\"ovr\",average='macro'))\n",
    "    # print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='linear', probability=True)\n",
    "model.fit(X, y)\n",
    "y_prob = model.predict_proba(X_test)\n",
    "macro_roc_auc_ovr = roc_auc_score(y_test, y_prob, multi_class=\"ovr\",\n",
    "                              average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945827387558798"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)\n",
    "roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
    "\n",
    "roc_auc_score(y, clf.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data = train_test_split(dfmulti, random_state=777, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_y = train_data.iloc[:,:-1],train_data.iloc[:,-1]\n",
    "test_X,test_y = test_data.iloc[:,:-1],test_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 46,\n",
       "         10: 14,\n",
       "         6: 5,\n",
       "         3: 3,\n",
       "         9: 3,\n",
       "         16: 4,\n",
       "         2: 10,\n",
       "         15: 1,\n",
       "         4: 1,\n",
       "         5: 3,\n",
       "         14: 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(test_y)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8\n",
       "1       6\n",
       "2      10\n",
       "3       1\n",
       "4       7\n",
       "       ..\n",
       "447     1\n",
       "448    10\n",
       "449     2\n",
       "450     1\n",
       "451     1\n",
       "Name: 279, Length: 452, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:687: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 200, in __call__\n",
      "    sample_weight=sample_weight)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\", line 288, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\", line 538, in roc_auc_score\n",
      "    multi_class, average, sample_weight)\n",
      "  File \"/Users/emily/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\", line 632, in _multiclass_roc_auc_score\n",
      "    \"Number of classes in y_true not equal to the number of \"\n",
      "ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03951001, 0.03615499, 0.033252  ]),\n",
       " 'score_time': array([0.06745696, 0.07424808, 0.00417805]),\n",
       " 'test_score': array([0.6420583 , 0.66475246,        nan])}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "myscore = make_scorer(roc_auc_score, multi_class='ovo',needs_proba=True)\n",
    "X,y = dfmulti.iloc[:,:-1],dfmulti.iloc[:,-1]\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X, y)\n",
    "\n",
    "cross_validate(clf, X, y, cv=5, scoring = myscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldval(df):\n",
    "\n",
    "    X = np.array(df.iloc[:, 1:])\n",
    "    y = np.array(df.iloc[:, 0])\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    # enumerate the splits and summarize the distributions\n",
    "    # print(X)\n",
    "    # print(y)\n",
    "    accuracyDe = []\n",
    "    for train_ix, test_ix in kfold.split(X, y):\n",
    "        # select rows\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        clf = DecisionTreeClassifier().fit(train_X, train_y)\n",
    "        # roc_auc_score(test_y, clf.predict_proba(test_X),multi_class='ovr')\n",
    "        accuracyDe.append(roc_auc_score(test_y, clf.predict_proba(test_X),multi_class=\"ovr\"))\n",
    "    print(accuracyDe)\n",
    "    meanDe = statistics.mean(accuracyDe)\n",
    "    return meanDe\n",
    "        # cross_validate(clf, X, y, cv=5, scoring = myscore)\n",
    "        # strat_train_set = df.loc[train_index]\n",
    "        # strat_test_set = df.loc[test_index]\n",
    "\n",
    "        # print('train_set :', train_X, '\\n' , 'test_set :', train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7962031593010458, 0.8478716798794663, 0.9258492681462648, 0.8222359058565955, 0.9052859372782746]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8594891900923294"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldval(dfmulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88333333, 0.81666667, 0.82708333, 0.78020833, 0.79583333])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "myscore = make_scorer(roc_auc_score, multi_class='ovo',needs_proba=True)\n",
    "X,y = dfmulti.iloc[:,1:],dfmulti.iloc[:,0]\n",
    "from sklearn.model_selection import cross_validate\n",
    "clf = DecisionTreeClassifier().fit(X, y)\n",
    "w = cross_validate(clf, X, y, cv=5, scoring = myscore)\n",
    "w['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.iloc[:, :-1])\n",
    "y = np.array(df.iloc[:, -1])\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 53, 10: 11, 16: 2, 3: 2, 2: 12, 15: 1, 6: 4, 4: 3, 5: 2, 9: 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(test_y_predicted)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3ad1cd97a0b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_y_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/oversampling_python/venv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    534\u001b[0m                              \"instead\".format(max_fpr))\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[1;32m    538\u001b[0m                                          multi_class, average, sample_weight)\n",
      "\u001b[0;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier().fit(train_X, train_y)\n",
    "        # clf = svm.SVC(kernel='linear', C=1, gamma='auto').fit(train_X, train_y)\n",
    "        \n",
    "test_y_predicted = clf.predict(test_X)\n",
    "print(roc_auc_score(test_y, clf.predict_proba(test_X)))\n",
    "\n",
    "\n",
    "# clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(train_X, train_y)\n",
    "# roc_auc_score(test_y, clf.predict_proba(test_X),multi_class='ovr')\n",
    "\n",
    "        # accuracyDe.append(roc_auc_score(test_y, test_y_predicted))\n",
    "# accuracyDe.append(roc_auc_score(test_y, test_y_predicted,mmulti_class='ovr'))\n",
    "#     print(accuracyDe)\n",
    "#     meanDe = statistics.mean(accuracyDe)\n",
    "#     return meanDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9913333333333334"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(solver=\"liblinear\").fit(X, y)\n",
    "roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "140ba02d0dd32d113ccd698594a4c9ecefe41d39bf7db07a36a271a926c6d995"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
